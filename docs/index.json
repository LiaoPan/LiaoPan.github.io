[
{
	"uri": "https://LiaoPan.github.io/afni/preprocess/",
	"title": "AFNI 系列教程 #1.Preprocessing",
	"tags": [],
	"description": "",
	"content": " 简介 预处理步骤 1. AFNI命令与uber_subjects.py 运行Uber被试脚本：a. 配置分析脚本 运行Uber被试脚本：b. 运行分析脚本 2. 时间层校正(Slice-Timing Correction) 3. 配准与归一化(Registration and Normalization) 4. 对齐与运动校正(Alignment and Motion Correction) 5. 平滑(Smoothing) 6. 掩膜(or 掩码)与缩放(Masking and Scaling) 7. 检查预处理结果 参考 简介 我们在对fMRI数据进行预处理时，会对每个TR获取的三维图像进行清理。一个fMRI容积(volume)不仅包含我们感兴趣的信号\u0026ndash;含氧血液的变化，还包含我们不感兴趣的波动(fluctuations)，如头部运动(head motion)、随机漂移(random drifts)、呼吸(breathing)和心跳(heartbeats)。我们将这些波动称为噪声(noises)，因为我们希望将它们从我们感兴趣的信号中分离出来。其中一些可以通过建模从数据中回归出来（将在建模拟合一章中讨论），其他的可以通过预处理减少或去除。\n数据前提：请提前准备好Flanker task数据集，我们可以在OpenNeuro网站上找到并免费下载。\n要开始预处理sub-08的数据，请通读以下章节。我们将首先概述如何使用AFNI命令，然后介绍uber_subject.py，它允许编写一个脚本，为我们完成所有预处理。然后，您将了解为什么要进行这些预处理步骤，以及如何在每个步骤之前和之后检查数据质量。\n预处理步骤 不同的软件包会以略微不同的顺序完成这些步骤\u0026ndash;例如，FSL会在模型拟合后对统计图(statistical map)进行归一化处理。还有一些分析省略了某些步骤\u0026ndash;例如，一些做多体素模式分析（multi-voxel pattern analyses）的人不平滑他们的数据。无论如何，下面列出的是在典型数据集上执行的最常见步骤。\n1. AFNI命令与uber_subjects.py 简介\n在所有fMRI分析软件包中，AFNI有最难学的名声。尽管过去可能确实如此，但AFNI的开发人员在过去几年中努力使他们的软件更易学易用：除了查看器，AFNI的最新版本还包含其他图形用户界面，可以通过命令uber_subject.py和uber_ttest.py访问这些图形界面。这些图形用户界面用于创建脚本，自动完成每个被试的预处理和模型设置。\n在讨论这些命令之前，我们先回顾一下典型AFNI命令的基本原理。毕竟，\u0026ldquo;uber\u0026quot;脚本只是将大量命令按照处理数据的顺序编译在一起。您还将使用单个AFNI命令执行更高级的分析，如感兴趣区域（ROI）分析。\nAFNI 命令\nAFNI命令类似于Unix命令： 它们通常需要至少一个参数或输入，而且通常还需要指定命令输出的名称。\n以头骨剥离为例，这是一个常见的预处理步骤，用于将头骨从大脑中剥离出来。执行这一步的AFNI命令称为3dSkullStrip。导航至sub-08/anat目录，然后输入3dSkullStrip并按回车键，我们可以看到该命令的帮助文档信息。\n通常情况下，只键入命令而不输入任何参数将默认打印帮助文档。在这里我们需要指定一个额外的标志-h来打印帮助文件，输入3dSkullStrip -h然后按回车键。你会注意到屏幕上打印了大量的文本，超过了终端可以同时显示的数量。如果想看更容易阅读的帮助文件，键入3dSkullStrip -h | less。竖条表示竖条左边命令的输出，即\u0026quot;3dSkullStrip -h\u0026rdquo;，应该被导入less命令，它允许你上下翻阅帮助文件。在这个 \u0026ldquo;分页窗口\u0026quot;中，输入\u0026quot;d\u0026quot;可以向下翻一页，输入\u0026quot;u\u0026quot;可以向上翻一页，输入上下箭头可以上下翻一行。要搜索帮助文件，键入一个正斜线（/），然后键入要查找的文本，按回车键。要退出分页窗口，请按 \u0026ldquo;q\u0026quot;键。\n**文档和帮助文件是AFNI的最大优势。每条命令的用法都有清晰的概述，并详细解释了使用不同选项的原因。**给出的示例命令涵盖了不同的情况\u0026ndash;例如，如果颅骨去除后在输出图像中留下了太多的颅骨，我们建议使用-push_to_edge这样的选项。\n3dSkullStrip最基本的用法是使用-input标志来指定将要被剥离的解剖数据集。例如\n3dSkullStrip -input sub-08_T1w.nii.gz 大约一分钟后，会生成一个名为skull_strip_out+orig的新文件。这就是头骨切片的解剖图像，我们可以打开AFNI浏览器查看。你可能会注意到在额叶有几个体素的皮质被移除，头骨顶部和后部有一些硬脑膜残留，但总体来说头骨剥离的效果非常好。\n另一种查看条纹质量的方法是加载原始解剖图像sub-08_T1w.nii.gz作为Underlay，加载颅骨去除图像skull_strip_out作为Overlay。我们可以通过点击观察窗口中的任意位置，然后按 \u0026ldquo;o\u0026quot;键来交替查看和隐藏叠加；另一个选项是按 \u0026ldquo;u\u0026quot;键来在每张图像之间切换。这些查看选项将有助于您在预处理步骤前后检查数据。\n查看在原始解剖图像上叠加的头骨剥离图像的示例。图像的不透明度可通过右侧的控制器面板进行切换。\n尽管颅骨剥离效果相当不错，而且对于大多数用途来说可能也没有问题，但让我们看看是否可以通过使用帮助文件中指定的任何选项来改进它。如果你仔细阅读帮助文件，你会注意到一个选项-push_to_edge，它可以帮助我们避免移除皮层的任何部分。一般来说，最好是将小块硬脑膜和其他非脑物质包括在内，而不是去除任何部分的大脑皮层。添加-prefix选项来标记输出结果也是非常有用的。键入以下命令:\n3dSkullStrip -push_to_edge -input sub-08_T1w.nii.gz -prefix anat_ss 其中ss代表 \u0026ldquo;skull-stripped\u0026rdquo;。\n几分钟后，将生成一个名为anat_ss+orig的新文件。在AFNI查看器中查看之前和之后的图像，并与之前生成的骷髅剥离图像进行比较。你发现有什么看起来更好吗？更差？你会选择哪一个头骨剥离图像，为什么？\nuber_subjects.py脚本介绍\n在接下来的章节中，我们将介绍典型的fMRI分析流水线的其他预处理步骤；不过，首先我们应该熟悉一个命令，它可以创建一个脚本来为运行所有这些预处理步骤：AFNI的uber_subject.py。\n从技术上讲，uber_subject.py是一个图形用户界面的封装器，也就是说，它接收用户指定的所有图形用户界面输入，并将其导入另一个名为afni_proc.py的封装器。后一条命令生成一个大脚本，其中包含运行预处理每一步所需的每一条AFNI命令。\n在命令行中输入uber_subject.py并按回车键。您将看到如下内容\n在接下来的章节中，我们将详细研究该图形用户界面的各个部分。现在，请注意第一个复选框 \u0026ldquo;Analysis Initialization\u0026rdquo;。默认情况下，数据分析类型为 \u0026ldquo;task\u0026rdquo;（而不是 \u0026ldquo;rest\u0026rdquo;，因为没有任务需要被试执行），域(domain)为\u0026quot;volume\u0026rdquo;（而不是 \u0026ldquo;surface\u0026rdquo;，我们将在后面关于相关程序SUMA的章节中讨论）。在 \u0026ldquo;preprocessing blocks\u0026quot;后面的字段：tshift、align、tlrc、volreg、blur、mask、scale 和 regress，我们可能看不懂。（如果这是我们第一次使用AFNI，我想它们看起来会很奇怪）。我们的任务是了解这些单词的含义、它们对应的预处理步骤以及为什么要这样做。\n随着您对AFNI的熟练掌握，我们将能够更好地根据自己的需要改变分析的细节；但现在，我们以如何使用uber_subject.py创建一个预处理脚本为例。\n练习\n在3dSkullStrip中使用-no_avoid_eyes或者-use_skull选项。查看帮助文件了解它们的作用，并预测它们将如何影响颅骨去除效果。你的预测是否与你在输出中看到的一致？ 将解剖图像载入AFNI查看器并按下 \u0026ldquo;Graph\u0026quot;按钮。这与您用功能图像查看 \u0026ldquo;Graph\u0026quot;输出有何不同？为什么？ 运行Uber被试脚本：a. 配置分析脚本 现在我们可以使用uber_subject.py图形用户界面运行这些预处理步骤。现在，我们将简单地设置脚本并运行它；当它运行时，我们将阅读以下章节，这些章节描述了每个预处理步骤的作用。最后，我们将查看每个步骤的输出结果，并确定是否需要更改任何步骤。\n首先，打开终端，导航到sub-08目录，输入uber_subject.py \u0026amp;。\n逗号符号（\u0026quot;\u0026amp;\u0026quot;）将在后台执行您指定的命令；也就是说，它将在运行命令的同时保持终端可用，以便键入更多命令。如果执行的命令不带\u0026quot;\u0026amp;\u0026ldquo;符号，则可以通过单击执行命令的终端并键入ctrl+z，将当前正在运行的命令推至后台,但这将暂停当前命令；要将其置于后台（即继续运行该命令，同时保持终端空闲），请在终端中键入bg并按 Enter。\n在\u0026quot;subject ID\u0026quot;字段中输入sub_08，在\u0026quot;group ID\u0026rdquo; 字段中输入Flanker。点击 \u0026ldquo;Analysis Initialization（分析初始化）\u0026ldquo;旁边的方框，删除\u0026quot;regress\u0026quot;块。（稍后当我们为每个受试者运行一般线性模型时，我们会将其包括在内）。然后点击 \u0026ldquo;anatomical dataset（解剖数据集）\u0026ldquo;部分的\u0026quot;browse anat\u0026quot;按钮，导航到anat目录，选择文件sub-08_T1w.nii.gz。点击\u0026quot;EPI datasets\u0026quot;部分的browse EPI按钮选择功能数据集，导航至func目录，按住shift并点击选择文件sub-08_task-flanker_run-1_bold.nii.gz和sub-08_task-flanker_run-2_bold.nii.gz。图形用户界面的前半部分应该如下所示：\n我们将跳过\u0026quot;stimulus timing files\u0026quot;和 \u0026ldquo;symbolic GLTs\u0026quot;部分，因为我们还没有进行回归。\u0026ldquo;expected options\u0026quot;字段中的默认值没有问题\u0026ndash;不会删除任何TR，变异性最小的体块将用作配准的参考图像，4mm的平滑核将应用于数据，任何从TR到TR的合并移动量为0.3mm的体块将在审查文件(censor file)中标记（稍后将在回归过程中使用）。\n运行Uber被试脚本：b. 运行分析脚本 当我们完成分析设置后，可以从左到右点击 GUI 窗口顶部的三个图标来执行分析。第一个图标看起来像一张纸，上面有线条；这将生成afni_proc.py命令，包含您在图形用户界面中指定的所有内容。点击图标，将返回两个窗口：一个窗口列出了每个从默认值修改的选项，并列出了每个输入，另一个窗口显示了afni_proc.py命令的代码。看看afni_proc.py命令中列出的命令和选项是如何与我们在uber_subject.py图形用户界面中输入的选项相对应的：\n您将看到一条警告信息，上面写着 \u0026ldquo;** warning: no stim timing files given (resting state?)\u0026rdquo; 由于我们只是运行预处理，因此可以忽略该信息并点击 \u0026ldquo;OK（确定）\u0026quot;。\n查看完输出窗口后，关闭它们。现在点击下一个图标，即一张纸上的放大镜。这将执行上一个窗口中列出的afni_proc.py代码，并返回我们应该注意的任何警告或错误(本案例子中暂无)。我们还将看到几行代码，指定如何运行该命令的输出，这是一个名为proc.sub_08的文件。\n关闭窗口，回到终端。在sub-08目录中，注意到有一个新的目录结构已经创建。在下一个目录subject_results中，你会看到group.Flanker，下面是subj.sub_08。输入cd subject_results/group.Flanker/subj.sub_08，导航到该目录。该目录下有三个文件：\ncmd.ap.sub_08：这是由uber_subject.py生成的afni_proc.py文件。 output.cmd.ap.sub_08：这是afni_proc.py的输出，其中会生成我们应该注意的警告或错误。 proc.sub_08：将执行实际预处理的原始AFNI命令，由afni_proc.py命令编译。用vi或其他文本工具打开该文件，检查其中的内容。它应该是这样的 现在我们可以运行该脚本了。我们可以键入output.cmd.ap.sub_08中列出的代码，或者直接按uber_subject.py GUI 顶部的绿色图标按钮。如果你按了后者，就会看到另一个窗口打开，显示正在运行的每条命令及其相应的输出：\n如果uber_subject.py不能使用，比如pyqt4老旧安装麻烦等问题，导致脚本不能使用，建议使用下述使用uber_subject.py脚本输出的sub_08_afni_proc.sh脚本。\nsub_08_afni_proc.sh #!/usr/bin/env tcsh # created by uber_subject.py: version 1.2 (April 5, 2018) # creation date: Mon Nov 18 12:30:05 2019 # set subject and group identifiers set subj = sub_08 set gname = Flanker # set data directories set top_dir = ${PWD}/sub-08 set anat_dir = $top_dir/anat set epi_dir = $top_dir/func set stim_dir = $top_dir/func # run afni_proc.py to create a single subject processing script afni_proc.py -subj_id $subj \\ -script proc.$subj -scr_overwrite \\ -blocks tshift align tlrc volreg blur mask scale regress \\ -copy_anat $anat_dir/sub-08_T1w.nii.gz \\ -dsets \\ $epi_dir/sub-08_task-flanker_run-1_bold.nii.gz \\ $epi_dir/sub-08_task-flanker_run-2_bold.nii.gz \\ -tcat_remove_first_trs 0 \\ -align_opts_aea -giant_move \\ -tlrc_base MNI_avg152T1+tlrc \\ -volreg_align_to MIN_OUTLIER \\ -volreg_align_e2a \\ -volreg_tlrc_warp \\ -blur_size 4.0 \\ -regress_stim_times \\ $stim_dir/congruent.1D \\ $stim_dir/incongruent.1D \\ -regress_stim_labels \\ congruent incongruent \\ -regress_basis \u0026#39;GAM\u0026#39; \\ -regress_censor_motion 0.3 \\ -regress_motion_per_run \\ -regress_opts_3dD \\ -jobs 8 \\ -gltsym \u0026#39;SYM: incongruent -congruent\u0026#39; -glt_label 1 \\ incongruent-congruent \\ -gltsym \u0026#39;SYM: congruent -incongruent\u0026#39; -glt_label 2 \\ congruent-incongruent \\ -regress_reml_exec \\ -regress_make_ideal_sum sum_ideal.1D \\ -regress_est_blur_epits \\ -regress_est_blur_errts \\ -regress_run_clustsim no 2. 时间层校正(Slice-Timing Correction) 整个照片是在一瞬间拍摄完成的，而fMRI的volume是分片（slices）获取的。每个切片都需要时间来获取（从几十到几百毫秒）。\n两种最常用的创建volume的方法是顺序和交错的切片采集。顺序切片采集是连续采集每个相邻的切片，从下到上或从上到下。交错式切片采集每一个间隔的切片，然后在第二遍的时候填补空隙。这两种方法在下面的视频中都有说明。 正如在后面看到的，当我们对每个体素的数据进行建模时，我们假设所有的切片（slices）是同时获得的。为了使这一假设有效，每个切片的时间序列需要在时间上向后移动，即获取该切片所需的时间。Sladky等人（2011年）还证明，对于TR较长（如2s或更长）的研究，尤其是大脑背侧区域的研究，切片时间校正可使统计能力显著提高。\n尽管时间层校正似乎是合理的，但也有一些反对意见：\n一般来说，除非需要，否则最好不要对数据进行插值（即编辑）； 对于短的TR（例如，大约1秒或更短），时间层校正似乎不会导致统计能力的任何明显提高； 许多由时间层校正解决的问题可以通过在统计模型中使用时间导数（temporal direivate）来解决（在后面关于模型拟合的章节中讨论）。 现在，我们将以第一个切片为基准进行切片定时校正（由3dTshift命令的-tzero 0选项指定）。（运行时间层校正的代码可在proc脚本的第 97-100行找到：\nforeach run ( $runs ) 3dTshift -tzero 0 -quintic -prefix pb01.$subj.r$run.tshift \\ pb00.$subj.r$run.tcat+orig end 这将以第一个切片为参照，对每次run进行时间层校正。（请记住，在AFNI中，所有内容的索引都是从0开始的，也就是说，在这种情况下，0代表volume的第一个切片）。该命令还使用了一个名为-quintic的选项，它使用五次多项式对每个切片进行重新采样。换句话说，由于我们需要替换一个切片内的体素值，因此可以通过使用更多其他切片的信息来提高精确度。这确实在一定程度上引入了切片之间的相关性，我们稍后将尝试使用3dREMLfit对数据进行预白化（即去相关性）来纠正这种相关性。\n3. 配准与归一化(Registration and Normalization) 虽然大多数人的大脑是相似的\u0026ndash;例如，每个人都有扣带回（cingulate gyrus）和胼胝体(corpus callosum)\u0026ndash;但在大脑的大小和形状上也有差异。因此，如果我们想做一个群体分析(group analysis)，我们需要确保每个受试者的每个体素都对应于大脑的同一部位。例如，如果我们要测量视觉皮层中的一个体素，我们要确保每个受试者的视觉皮层都是一致的。\n这是通过对图像进行配准(Registering)和归一化(Normalizing)来实现的。就像你要折叠衣服以装入行李箱一样，每个大脑都需要被转换为具有相同的大小、形状和尺寸。我们通过归一化（或扭曲）到模板来实现这一目标。模板是一个具有标准尺寸和标准坐标的大脑，因为大多数研究人员都同意在报告他们的结果时使用它们。这样一来，如果你将你的数据归一到该模板，并在坐标X=3、Y=20、Z=42处发现了一个效应，那么其他将他们的数据扭曲到同一模板的人可以将他们的结果与你的结果进行对照。模板大脑的尺寸和坐标也被称为标准化空间（standardized space）。\n一个常用的模板的例子，MNI152脑模板。这是152个健康成人大脑的平均值，代表了大多数研究的人群。如果你正在研究其他人群--例如儿童或老年人--考虑使用从该人群的代表中创建的模板。 仿射变换（Affine Transformations） 为了将图像扭曲成一个模板，我们将使用一个仿射变换(Affine transformation)。这类似于运动校正中描述的刚体变换，但它又增加了两个变换：缩放(zooms)和错切(shear)。平移和旋转对于像笔这样的日常物体来说是很容易做到的，而缩放和错切则更不寻常\u0026ndash;缩放可以缩小或放大图像，而错切则是将图像的对角线相对的角拉开。下面的动画总结了这四种类型的线性变换。 与刚体变换一样，缩放和错切都有三个自由度： 你可以沿x轴、y轴或z轴缩放或错切图像。那么，总的来说，仿生变换有12个自由度（（平移、旋转、缩放、错切）* （x、y、z）= 4 * 3= 12）。这些也被称为线性变换，因为沿轴的一个方向应用的变换会伴随着相反方向的等量变换。例如，向左平移一毫米，意味着图像从右边移动了一毫米。同样地，如果一个图像沿Z轴放大一毫米，它就会沿该轴的两个方向放大一毫米。没有这些约束的变换被称为非线性变换。例如，非线性变换可以在一个方向上放大图像，而在另一个方向上缩小图像，就像挤压海绵时一样。这些类型的变换将在后面讨论。\n配准与归一化（Registration and Normalization） 回顾一下，我们的数据集中既有解剖学图像，也有fMRI图像。我们的目标是将fMRI图像变换到模板上，这样我们就可以对所有的受试者进行组分析。虽然简单地将fMRI图像直接翘曲到模板上似乎是合理的，但在实践中，这样做效果并不好\u0026ndash;图像是低分辨率的，因此不太可能与模板的解剖细节相匹配。解剖图像是一个更好的选择。\n虽然这似乎对我们实现目标没有帮助，但事实上，对解剖图像进行扭曲可以帮助将fMRI图像带入标准化的空间。请记住，解剖和功能扫描通常是在同一时段获得的，而且在两次扫描之间，受试者的头部几乎没有移动。如果我们已经将解剖图像规范化为一个模板，并记录了所做的转换，我们就可以将同样的转换应用于fMRI图像\u0026ndash;只要它们与解剖图像在同一位置开始。\n这种功能图像和解剖图像之间的对位被称为配准。大多数配准算法使用以下步骤：\n假设功能图像和解剖图像处于大致相同的位置。如果它们不在同一位置，则对准图像的轮廓。 利用解剖图像和功能图像具有不同的对比度权重这一事实\u0026ndash;也就是说，在解剖图像上图像较暗的区域（如脑脊液）在功能图像上会显得明亮，反之亦然。这被称为互信息（mutual information）。配准算法移动图像以测试解剖和功能图像的不同重叠，将一个图像上的明亮体素与另一个图像上的黑暗体素相匹配，将黑暗体素与明亮体素相匹配，直到找到一个无法改进的匹配。 一旦找到了最佳匹配，然后将用于将解剖图像与模板进行扭曲的相同转换应用于功能图像。 通过AFNI的align_epi_anat.py来配准\nalign_epi_anat.py命令可以同时完成多个预处理步骤\u0026ndash;配准、将功能图像的体积对齐和时间层校正。但在本例中，我们将只用它进行配准。这一步骤的代码可以在 proc 脚本的第 110-115 行找到：\n源shell脚本 实际使用修改后的shell脚本 align_epi_anat.py -anat2epi -anat sub-08_T1w+orig \\ -save_skullstrip -suffix _al_junk \\ -epi vr_base_min_outlier+orig -epi_base 0 \\ -epi_strip 3dAutomask \\ -giant_move \\ -volreg off -tshift off align_epi_anat.py -anat2epi -anat anat/sub-08_T1w.nii.gz \\ -save_skullstrip -suffix _al_junk \\ -epi func/sub-08_task-flanker_run-1_bold.nii.gz -epi_base 0 \\ -epi_strip 3dAutomask \\ -giant_move \\ -volreg off -tshift off 第一个选项-anat2epi表示解剖图像将与功能图像对齐，反之亦然。一般来说，我们希望尽可能减少对功能数据的改动和插值。因此，如果需要对图像进行移动和轻微变形，我们会选择在解剖图像上进行。\n-suffix命令将_al_junk字符串附加到一些配准的中间阶段，我们稍后将用它来对功能图像进行归一化处理。epi选项（即-epi、-epi_base 和-epi_strip）表示将使用变化最小的功能容积(functional images)作为参考图像，并使用3dAutomask（3dSkullStrip的替代方法）去除非脑组织。-giant_move试图在解剖图像和功能图像之间找到良好的初始配准；最后两个选项表示我们不想在当前命令中包含配准和时间层校正。\n通过AFNI的@auto_tlrc来归一化 对齐解剖和功能图像后，我们首先要将解剖图像归一化为模板。在下一章中将看到，这些扭曲也将应用于功能图像。要对解剖图像进行归一化处理，我们将使用@auto_tlrc命令；该命令和下面的cat_matvec命令位于 proc 脚本的第 118-122 行：\n# warp anatomy to standard space: 将解剖图转到标准空间 $ @auto_tlrc -base MNI_avg152T1+tlrc -input anat/sub-08_T1w_brain.nii.gz - no_ss Copying NIFTI volume to anat/sub-08_T1w_brain_AFN_OYmeqfZ3JqF7n9LNC7gDAA ++ 3dcopy: AFNI version=AFNI_23.1.10 (Jun 29 2023) [64-bit] Error: input dataset must be in the current directory Current path for input dataset is anat Sorry. ++ anat already stripped, re-using *********** Warning ************* Dataset centers are 92.736319 mm apart. If registration fails, or if parts of the original anatomy gets cropped, try adding option -init_xform AUTO_CENTER to your @auto_tlrc command. ********************************* Padding ... ++ 3dZeropad: AFNI version=AFNI_23.1.10 (Jun 29 2023) [64-bit] ++ output dataset: ./__ats_tmp__ref_MNI_avg152T1_15pad+tlrc.BRIK ... ++ Authored by: RW Cox ++ Processing AFNI dataset __ats_tmp___upad15_sub-08_T1w_brain_AFN_OYmeqfZ3JqF7n9LNC7gDAA+tlrc + setting Warp parent ++ 3drefit processed 1 datasets ++ 3dAFNItoNIFTI: AFNI version=AFNI_23.1.10 (Jun 29 2023) [64-bit] Cleanup ... # store forward transformation matrix in a text file:将正向变换矩阵存储到文本文件中 $ cat_matvec sub-08_T1w_ns+tlrc::WARP_DATA -I \u0026gt; warp.anat.Xat.1D 第一条命令表示以图像MNI_avg152T1为模板，以头骨剥离的解剖图像为源图像，或移动图像使其与基础图像或参考图像最匹配。-no_ss选项表示解剖图像已经过头骨切片处理。\n为了使模板和解剖图像对齐，解剖图像需要通过上述变换进行移动和转换。这将产生一系列数字，组成仿射变换矩阵(affine transformation matrix)，并存储在解剖图像的标题中。第二条命令cat_matvec将提取该矩阵并复制到一个名为warp.anat.Xat.1D的文件中。下一节将介绍如何使用该矩阵将功能图像转换到相同的归一化空间。\n练习\n在上述@auto_tlrc命令中，默认模板是MNI_avg152+tlrc，可以在~/abin目录中找到。输入ls ~/abin | grep MNI，查看 MNI 空间中的可用模板。并不是所有模板都能用于 T1 解剖扫描的归一化，但其中有几个模板是可以的，包括MNI152_1mm_uni+tlrc和MNI152_T1_2009c+tlrc。对解剖图像进行颅骨切片后，请尝试使用以下命令： $ 3dcopy sub-01_T1w_ns+orig. T1w_cop @auto_tlrc -base MNI152_T1_2009c+tlrc -input T1w_copy+orig -no_ss 观察输出结果与上述原始命令有何不同。也用MNI152_T1_2009c+tlrc模板试试，在 orig 空间创建原始 T1 加权解剖图像的新副本。你更喜欢使用哪种模板？为什么？另外，为什么你认为默认是MNI_avg152T1+tlrc大脑？ 提示：在 AFNI 查看器中输入afni ~/abin查看每个模板。\n4. 对齐与运动校正(Alignment and Motion Correction) 简介 如果我们尝试过给移动的物体拍照，通常图像会很模糊。相反，如果拍摄时物体保持静止不动，那么就能获得更加清晰、轮廓分明的图像。 移动的目标会导致图像模糊（左图），而静止的目标则会导致图像更加清晰（右图）。 当我们拍摄大脑的三维图像时，概念也是一样的。如果拍摄对象在移动，图像看起来就会模糊；如果拍摄对象静止不动，图像看起来就不会那么模糊，轮廓会更加清晰。但这还不是全部：如果实验对象移动频繁，我们也有可能测量到移动体素的信号。这样，我们就有可能在部分实验中测量到来自该体素的信号，而在实验对象移动后，又测量到来自不同区域或组织类型的信号。\n由于运动会产生信号，这些运动也会给成像数据带来混淆。如果受试者每次都对刺激做出反应而移动\u0026ndash;例如，受试者每次感受到电击时都会扭动头部\u0026ndash;那么就无法确定我们测量的信号是对刺激做出的反应，还是因为移动而产生的。\n刚体变换(Rigid-Body Transformations) \u0026ldquo;撤销\u0026quot;这些运动的方法之一是进行刚体变换。为了说明这一点，请拿起附近的一个物体：例如手机或咖啡杯。把它放在你面前，并在脑海中标出它的位置。这就是参考点。然后将物体向左移动一英寸。这就是所谓的平移(translation)，也就是向左或向右、向前或向后、向上或向下的任何移动。如果想让物体回到起点，只需向右移动一英寸即可。\n同样，如果你将物体向左或向右旋转，也可以通过向相反方向等量旋转来撤销。这些被称为旋转(rotation)，和平移一样，它们有三个自由度，或者说有三种移动方式：绕 x 轴（也称为俯仰，或前后倾斜）、绕 y 轴（也称为滚动，或左右倾斜）和绕 z 轴（或偏航，如摇头说 \u0026ldquo;不\u0026rdquo;）。\n通过移动自己的头部来尝试这些平移和旋转。首先，直视前方时左右移动头部（沿 x 轴平移）。然后，前后（y 轴）上下（z 轴）移动头部。\n我们对volumes进行同样的操作。我们将时间序列中的第一个volume称为reference volume(参考容积)，而不是上面例子中使用的参考点。如果在扫描过程中，被扫描者的头部向右移动了一英寸，我们就可以检测到这一移动，并通过将volume向左移动一英寸来消除这一移动。这样做的目的是检测到任何一个容积的移动，并将这些容积与参考容积重新对齐。\n参考容积可以是时间序列中的任何容积（但通常是第一、中间或最后一个容积）。如果在扫描过程中被摄体向右移动，则可以通过向左的等量反向移动来\"消除\"相对于参照体积的移动。 AFNI的3dvolreg AFNI 中的运动校正是通过3dvolreg命令完成的。在由uber_subject.py生成的典型分析脚本中，会有一个代码块，其标题为 ======volreg======。该代码块中有几个命令，但对我们现在的目的来说，最重要的是以 \u0026ldquo;3dvolreg\u0026quot;开头的一行。\n你会看到该命令使用了几个选项。-base选项指的是参考体；在本例中，参考图像是由之前的3dToutcount命令确定的体素中异常值最少的体。-1Dfile 命令会将运动参数写入一个文本文件，并在文件后附加\u0026quot;1D\u0026rdquo;，而-1Dmatrix_save则会保存一个仿射矩阵，该矩阵会显示为了与参考图像相匹配，每个 TR 在每个仿射维度上需要 \u0026ldquo;warped\u0026quot;的程度。\n# register and warp foreach run ( $runs ) # 将每个volume配准到基准图像 3dvolreg -verbose -zpad 1 -base vr_base_min_outlier+orig \\ -1Dfile dfile.r$run.1D -prefix rm.epi.volreg.r$run \\ -cubic \\ -1Dmatrix_save mat.r$run.vr.aff12.1D \\ pb01.$subj.r$run.tshift+orig 然后，将该仿射变换矩阵与在将解剖数据集扭曲到归一化空间期间以及将解剖数据集与fMRI数据配准时生成的仿射变换矩阵连接起来：\n# catenate volreg/epi2anat/tlrc xforms cat_matvec -ONELINE \\ {$subj}_T1w_ns+tlrc::WARP_DATA -I \\ {$subj}_T1w_al_junk_mat.aff12.1D -I \\ mat.r$run.vr.aff12.1D \u0026gt; mat.r$run.warp.aff12.1D 此连接仿射矩阵与3dAllineate命令一起使用，可在一个步骤中创建运动校正和归一化的 fMRI 数据集（使用1Dmatrix_apply选项）：\n# 对 all-1数据集进行扭曲处理，以进行外延遮蔽（extents masking） 3dAllineate -base {$subj}_T1w_ns+tlrc \\ -input rm.epi.all1+orig （输入 rm.epi.all1+orig -1Dmatrix_apply mat.r$run.warp.aff12.1D \\ -mast_dxyz 3 -final NN -quiet\\ -prefix rm.epi.1.r$run 这些代码块一开始可能很难理解，但请始终牢记 AFNI 命令的基本结构： 命令名称后跟选项，通常还包括一个\u0026rdquo;-prefix\u0026quot;选项，用于标注输出结果。运动校正和归一化命令通常还包括一对\u0026rdquo;-base\u0026quot;和\u0026rdquo;-input\u0026quot;选项，用于标明哪个数据集正在与哪个参考数据集对齐。我们很可能不会编辑uber_subject.py生成的文件中的这些代码行，但了解它们的编写方式仍然很有用；如果我们愿意，可以在本脚本之外使用这些命令对齐其他数据集。\n练习\n在3dvolreg命令中，将-base改为 0，观察输出结果与使用vr_base_min_outlier作为参考体积有何不同。再试一次，使用3dTstat创建该run的平均函数图像，并使用该平均函数图像作为基准；这与SPM12软件包中的做法类似。您更喜欢哪种方法，为什么？ 5. 平滑(Smoothing) 常见的做法是对fMRI数据进行平滑处理，或将每个体素的信号替换为该体素邻近区域的加权平均。这初看起来很奇怪\u0026ndash;为什么我们要使图像比原来更模糊？\n的确，平滑化会降低fMRI数据的空间分辨率，而我们并不希望分辨率降低。但平滑化也有好处，这些好处可以超过缺点。例如，我们知道fMRI数据包含很多噪音，而且噪音经常大于信号。通过对附近的体素进行平均化，我们可以消除噪音并增强信号。\n在这个动画中，两个不同的平滑核（4毫米和10毫米）被应用于一个fMRI扫描。请注意，随着我们使用更大的平滑核，图像变得更加模糊，解剖细节变得不那么明显。还要注意的是，为了简单起见，这个动画使用大脑的二维切片来演示这个预处理步骤。在实际的fMRI数据中，内核将应用于所有三个维度。 平滑处理是通过 AFNI 的 3dmerge 命令完成的，您可以在 proc_Flanker 脚本的 \u0026ldquo;blur \u0026ldquo;标题下找到该命令（第 216-221 行）。在所有预处理步骤中，这个步骤使用的代码行数最少：\n# 模糊每个run的每个volume foreach run ( $runs ) 3dmerge -1blur_fwhm 4.0 -doall -prefix pb03.$subj.r$run.blur \\ pb02.$subj.r$run.volreg+tlrc end -1blur_fwhm选项指定了平滑图像的量，单位为毫米\u0026ndash;在本例中为4毫米。-doall选项会将平滑核应用到图像中的每个卷，而-prefix选项会一如既往地指定输出数据集的名称。\n最后的预处理步骤是将这些平滑图像缩放为平均信号强度为100的图像，这样就可以用信号变化百分比来衡量与平均值的偏差。然后用掩膜去除任何非脑体素，这些图像就可以进行统计分析了。要了解 AFNI 如何完成最后两个预处理步骤，请查看第6小节掩膜与缩放。\n练习\n导航到sub-01/func目录，输入3dmerge -1blur_fwhm 4.0 -doall -prefix test_blur_4mm.nii sub-01_task-flanker_run-1_bold.nii.gz对原始功能数据应用不同的平滑核。在 AFNI GUI 中查看输出文件。然后，用 8mm、12mm 和 20mm 的平滑内核做同样的操作，记住每次平滑时都要更改输出文件的名称。完成后，输入rm test*即可删除所有平滑图像。 6. 掩膜(or 掩码)与缩放(Masking and Scaling) a.什么是掩膜（掩码，or masking）？ 正如在之前的教程中所看到的，一卷fMRI数据既包括大脑，也包括周围的头骨和颈部\u0026ndash;我们对使用AFNI分析这些区域并不感兴趣，尽管它们与大脑体素一样，包含有时间序列数据的体素。此外，尽管乍一看可能并不明显，但我们有大量的体素包含在头部以外的空气中。\n为了减少数据集的大小，从而加快分析速度，我们可以对数据应用掩码。掩码简单地表示哪些体素要进行分析\u0026ndash;掩码内的体素保留其原始值（或赋值为 1），而掩码外的体素赋值为 0。这就好比用描图纸描出一幅画的轮廓，然后沿线剪切，保留线内的部分，舍弃其余部分。应用到fMRI数据中，掩码之外的任何东西都会被我们认为是噪音或不感兴趣的东西。\n掩码使用AFNI的3dAutomask命令创建，它只需要输入和输出数据集的参数（proc_Flanker 脚本第 223-260 行）：\nforeach run ( $runs ) 3dAutomask -prefix rm.mask_r$run pb03.$subj.r$run.blur+tlrc end 掩码块中的其余代码将创建一个掩码集合，代表实验中所有单个fMRI数据集的范围。然后为解剖数据集计算一个掩码，再取fMRI掩码和解剖掩码的交集：\n# create union of inputs, output type is byte 3dmask_tool -inputs rm.mask_r*+tlrc.HEAD -union -prefix full_mask.$subj # ---- create subject anatomy mask, mask_anat.$subj+tlrc ---- # (resampled from tlrc anat) 3dresample -master full_mask.$subj+tlrc -input {$subj}_T1w_ns+tlrc \\ -prefix rm.resam.anat # convert to binary anat mask; fill gaps and holes 3dmask_tool -dilate_input 5 -5 -fill_holes -input rm.resam.anat+tlrc \\ -prefix mask_anat.$subj # compute tighter EPI mask by intersecting with anat mask 3dmask_tool -input full_mask.$subj+tlrc mask_anat.$subj+tlrc \\ -inter -prefix mask_epi_anat.$subj # compute overlaps between anat and EPI masks 3dABoverlap -no_automask full_mask.$subj+tlrc mask_anat.$subj+tlrc \\ |\u0026amp; tee out.mask_ae_overlap.txt # note Dice coefficient of masks, as well 3ddot -dodice full_mask.$subj+tlrc mask_anat.$subj+tlrc \\ |\u0026amp; tee out.mask_ae_dice.txt # ---- create group anatomy mask, mask_group+tlrc ---- # (resampled from tlrc base anat, MNI_avg152T1+tlrc) 3dresample -master full_mask.$subj+tlrc -prefix ./rm.resam.group \\ -input /Users/ajahn/abin/MNI_avg152T1+tlrc # convert to binary group mask; fill gaps and holes 3dmask_tool -dilate_input 5 -5 -fill_holes -input rm.resam.group+tlrc \\ -prefix mask_group 我们将在下一节更详细地了解这段代码的输出结果，即创建一个掩码，用于追踪图像检测到的信号的轮廓：\nmasked图像示例。左侧是原始图像，右侧是掩码。掩码由1和0组成，其中1代表头骨内的体素，0代表其他任何地方。 从上图可以看出，掩码似乎排除了眶额皮层的某些部分。由于这些区域的信号一开始就相对较低（这是由于一种被称为磁感应伪影(magnetic susceptibility artifact)的现象导致信号丢失），掩码假定该区域不包含任何脑体素。这可以通过使用一种叫做场图反扭曲（field map unwarping）的技术来解决。这超出了本教程的范围，但如果您有兴趣，可以在此处了解一种此类方法。\nb.缩放(scaling) fMRI数据的一个问题是，我们收集的数据单位是任意的，本身没有意义。我们收集到的信号强度会因运行的不同而不同，也会因受试者的不同而不同。要在受试者内部或受试者之间进行有用的比较，唯一的方法就是使用贝塔权重(beta weight)（将在稍后的统计一章中讨论）来表示不同条件下的信号强度对比。\n为了使不同研究之间的信号强度对比也有意义，AFNI将每个体素的时间序列单独缩放至平均值100：\n# scale each voxel time series to have a mean of 100 # (be sure no negatives creep in) # (subject to a range of [0,200]) foreach run ( $runs ) 3dTstat -prefix rm.mean_r$run pb03.$subj.r$run.blur+tlrc 3dcalc -a pb03.$subj.r$run.blur+tlrc -b rm.mean_r$run+tlrc \\ -c mask_epi_extents+tlrc \\ -expr \u0026#39;c * min(200, a/b*100)*step(a)*step(b)\u0026#39; \\ -prefix pb04.$subj.r$run.scale end 这些变化将反映在时间序列中；下面第一张图片是缩放前的时间序列，下一张图片显示的是缩放后的时间序列。请注意，第一张图片中的数值相对较高\u0026ndash;在 800左右\u0026ndash;而且这些数值是任意的；在另一个实验对象中，这些数值很可能在500或900左右。通过将每个受试者的数据缩放至相同的平均值（如第二张图片所示），我们可以将每个受试者的每次数据运行置于相同的刻度上。\n现在我们已经完成了预处理步骤，是时候回顾每个步骤并检查数据质量了。在下一节中，我们将介绍如何完成这项工作。\n7. 检查预处理结果 1).导航到已处理的数据目录 uber_subject.py生成的脚本完成后，导航到包含预处理数据的目录。默认情况下，AFNI将按照以下格式创建一个新的目录树：\nsubject_results/group.\u0026lt;GroupName\u0026gt;/subj.\u0026lt;subjName\u0026gt;/\u0026lt;subjName\u0026gt;.results 其中，GroupName和subjName指定在uber_subject.py GUI 的subject ID 和group ID 字段中。在这种情况下，我们可以通过键入以下内容导航到结果目录\n$ cd subject_results/group.Flanker/subj.sub_08/sub_08.results 稍后，当我们讨论分析脚本或对数据集中的所有被试进行自动分析时，我们将通过修剪不必要的子目录来简化目录树。\n该目录包含经过每一步预处理后的不同图像版本。例如，包含字符串pb01（即Processing Block 01）和字符串 tshift 的文件表示这些图像已使用3dTshift命令进行了切片时间校正。\n来自uber_subject.py的输出示例。包含 \"pb\"字符串的文件是每个预处理步骤的预处理功能图像，包含 \"T1w\"字符串的文件是预处理解剖图像。创建辅助功能图像是为了协助特定的预处理步骤，辅助文本文件包含有关转换矩阵和运动参数的信息。 2).查看已处理的功能像数据\na.查看时间层校正结果\n在熟悉预处理数据目录中的内容后，键入afni打开 AFNI 图形用户界面。单击\u0026quot;Underlay\u0026quot;按钮，左键单击文件pb00.sub_08.r01.tcat；然后单击轴向、矢状或冠状视图旁边的 \u0026ldquo;Graph\u0026quot;按钮，查看时间序列。由于在将数据上传到OpenNeuro之前已经丢弃了初始体积，因此所有时间点的相对强度都是相同的。（事实上，本来就不需要3dTcat预处理步骤；不过，除了占用更多电脑内存之外，留着它也没什么不好）。\n同样，pb01图像应该与pb00图像相同。如果检查预处理的输出文本，就会看到3dTshift时打印的一条信息，其中指出数据集\u0026quot;已经在时间上对齐(already aligned in time)\u0026quot;，而且 \u0026ldquo;输出数据集只是输入数据集的副本(output dataset is just a copy of the input dataset)\u0026quot;。至此，这些文件与原始功能数据基本相同。你可以省略3dTcat和3dTshift这两个预处理步骤，重新分析这些数据，结果也是一样的。不过现在，请查看每次运行的这两个处理输出，以确保它们看起来确实相同，而且没有明显的伪影。 底层菜单有两列： 左列是文件名，右列是文件的标题信息。\u0026ldquo;epan\u0026quot;表示该文件是回声平面图像（即功能图像），而 \u0026ldquo;anat\u0026quot;表示该文件是解剖图像。(在 \u0026ldquo;epan\u0026quot;字符串旁边，\u0026ldquo;3D+t:146\u0026quot;表示这是一个三维图像，外加一个时间维度，有 146 个体积或时间点。\nb.查看对齐与配准结果 下一个要查看的文件是pb02 \u0026ldquo;volreg\u0026quot;文件，这些文件已经过\n运动校正\u0026ndash;也就是说，每次运行的时间序列中的每个容积都已与参考容积对齐； 与解剖图像进行了共配准；3. 与标准化空间进行了扭曲(warp)处理，在本例中就是 MNI152 模板。 如果点击pb02图像，会发现视图发生了变化。AFNI GUI 有一部分包含 \u0026ldquo;Original View\u0026rdquo;、\u0026ldquo;AC-PC Aligned\u0026quot;和 \u0026ldquo;Talairach View\u0026quot;字符串。在该图像中，\u0026ldquo;Talairach View\u0026quot;单选按钮被高亮显示，表明这些图像已被归一化(normalized)。当查看其他被试的此处理块时，图像的基本形状和轮廓看起来几乎是一样的，因为它们都是按照相同的模板扭曲的。同样，请在几个不同的位置检查图像和时间序列，以确保没有明显的伪影。\n在AFNI中，+tlrc扩展名（和 \u0026ldquo;Talairach View\u0026rdquo;）仅表示图像已被归一化。但这并不意味着图像一定是在 Talairach 空间中；出于传统目的（即为了确保代码在新版本中仍然有效），Talairach 标签被保留了下来。我们可以在图像上使用3dinfo命令，找到 \u0026ldquo;Template Space（模板空间）\u0026ldquo;字段，检查图像被扭曲到哪个空间\u0026ndash;有三种可能：\u0026ldquo;ORIG\u0026rdquo;（即未被扭曲）、\u0026ldquo;TLRC\u0026rdquo;（归一化为 Talairach 空间）和 \u0026ldquo;MNI\u0026rdquo;（归一化为 MNI 空间）。\nc.查看平滑结果 接下来的预处理步骤是平滑，它将附近体素的信号平均到一起，以增强任何存在的信号，并消除噪音。这些图像看起来会更模糊，这是应用于数据的平滑核大小的函数；在本例中，4毫米的平滑核会使数据略微模糊，但模糊程度不大。如下图所示，查看图像以确保模糊看起来合理。\n打开 \u0026ldquo;Graph\u0026quot;窗口，从 \u0026ldquo;volreg\u0026quot;图像切换到 \u0026ldquo;blur\u0026quot;图像时，确保十字准线位于同一体素上。你注意到时间序列有什么变化？有什么明显的变化吗？你如何描述这种变化，为什么你认为它发生了这种变化？\nd.查看缩放结果 最后一个预处理步骤是生成缩放图像，其中每个体素的平均信号强度为100。这样，我们就可以将相对于平均值的任何变化指定为信号变化的百分比；也就是说，101的值可以解释为1%的信号变化。\n由于图像灰度在脑部体素中更为均匀，而脑部以外的信号变化较大，因此这些图像的解剖学清晰度将低于之前的图像。不过，我们仍然可以看到大脑的轮廓，而且大脑体素的时间序列值应该都接近100： )\ne.查看掩码结果 由于我们只对覆盖大脑的体素感兴趣，因此我们创建了一个掩码，用来排除任何非大脑体素。掩码将是二进制的：确定在头骨内的体素为1，头骨外为0。(还可以创建更严格的掩码，将脑脊液甚至白质排除在外，但我们在这里不考虑这些）。\n有两种掩膜可供选择：full_mask 和mask_group。full_mask是所有单个功能图像掩膜的组合，这些掩膜已根据信号强度确定属于大脑。信号强度非常低的体素不被认为是大脑体素。正如你在full_mask中看到的那样，这也排除了眶额区的体素，而眶额区因容易出现信号丢失而臭名昭著：\n另一个掩码（mask_group）是一个更宽松的掩码，它已被放大，以更紧密地匹配您所扭曲的模板\u0026ndash;在本例中，是MNI152大脑： 关于掩模图像的时间序列，你注意到什么？单击掩码内部和外部。这些数值有意义吗？\n3).查看已处理的结构像数据 在查看解剖预处理的结果时，我们要确保颅骨去除后的图像看起来合理，而且图像的归一化处理得当。\n首先，打开图像anat_w_skull_warped。如果已将MNI152图像复制到aglobal目录中，请将其作为叠加图像加载。(也可以通过终端键入：cp ~/abin/MNI_avg152T1+tlrc* .将其复制到当前目录)。我们可能会注意到，虽然矢状视图看起来不错，但轴向和冠状视图看起来有点糟。特别是，图像看起来好像略微向右偏移。虽然归一化过程中存在一些变异是很常见的，而且解剖图和模板永远不会完全匹配，但这已经超出了我们愿意扩大归一化误差的范围。 应该指出的是，anat_w_skull_warped图像是对原始解剖图像进行扭曲处理的结果。扭曲本身是通过将剥离头骨的解剖图像归一化为模板而计算出来的。如果归一化出现偏差，就会传播到其他图像上。要检查这一点，请作为底层(underlay)载入anat_final图像：\n我们找到了错误的根源： 左侧大脑的一部分在正常化过程中被删除了。但我们该如何修复呢？\n在预处理图像中发现错误时，应检查预处理脚本的输出。如果从uber_subject.py图形用户界面启动脚本，输出结果将打印到 \u0026ldquo;Processing Command\u0026quot;窗口；文本副本也将存储在名为:output.proc.\u0026lt;subjID 的文件中，该文件位于预处理数据的上一级目录。\n该文本将包含 \u0026ldquo;Warnings\u0026quot;和 \u0026ldquo;Errors\u0026rdquo;。错误表示文件丢失或命令无法成功运行。通常，脚本会在遇到错误后退出。而警告则指出可能存在的问题。例如，我们在时间层校正时收到的\u0026quot;数据集已在时间上对齐\u0026quot;通知就是一个警告。\n另一个警告与我们当前的问题有关，发生在归一化步骤中。这个警告出现在输出的中段，即@auto_tlrc命令之后： 显然，解剖图像和模板图像的中心相距甚远。输出结果显示，\u0026ldquo;如果部分原始解剖图被裁剪(if parts of the orignal anatomy gets cropped [sic])\u0026quot;（这正是我们目前的问题所在），\u0026ldquo;请尝试在@auto_tlrc命令中添加选项-init_xform AUTO_CENTER (try adding option -init_xform AUTO_CENTER to your @auto_tlrc command)\u0026quot;。我们可以这样做：导航到预处理目录之上的一个目录（cd ..），删除预处理目录（rm -r sub_08.results），然后编辑proc.sub_08文件，在@auto_tlrc命令后加入-init_xform AUTO_CENTER字符串，这应该是 proc 文件中的第 119 行：\n@auto_tlrc -base MNI_avg152T1+tlrc -input sub-08_T1w_ns+orig -no_ss -init_xform AUTO_CENTER 保存文件，然后输入tcsh proc.sub_08重新运行。等待几分钟让它完成，然后导航到预处理目录，加载与之前相同的图像集。现在你应该看到问题已经解决了。\n练习\n重新运行分析，使用10毫米的平滑核。预处理步骤的哪些部分会受到影响？在运行脚本之前，想一想输出结果会是什么样子。 在归一化解剖图像上叠加完整掩膜图像(full_mask)和掩膜组图像(mask_group)（或将它们叠加到经压缩后的模板上，即MNI152图像）。注意到掩码之间有什么不同？掩膜的覆盖范围在哪里差异最大？为什么？ 参考 https://andysbrainbook.readthedocs.io/en/latest/AFNI/AFNI_Short_Course/AFNI_04_Preprocessing.html#overview AFNI_Scripts by andrewjahn "
},
{
	"uri": "https://LiaoPan.github.io/fsl/installation/",
	"title": "FSL系列教程 #1.FSL安装",
	"tags": [],
	"description": "",
	"content": " 安装方法简述 安装校验 在MATLAB上使用FSL Flanker公开数据下载 通过fsleyes查看结构像数据 通过fsleyes查看功能像数据 参考 安装方法简述 访问网址,填写信息，下载对应版本的软件； 跟着教程指导，安装FSL软件。 打开终端命令行，使用管理员权限运行下述脚本 cd ~/Your_Downloads_DIR sudo python fslinstaller.py 注意: 1. 你的电脑上得有python的运行环境，不然无法执行下述python脚本。 2. 有网络，可以方便脚本自动从网络上下载相关软件包。\n安装校验 打开终端命令行，执行下述脚本:\n$ echo $FSLDIR # 校验环境变量 $ flirt -version # 校验软件是否正常使用，成功会输出:FLIRT version 6.0,版本号会有差异。 $ which imcp # 校验miniconda environment installation /usr/local/fsl/share/fsl/bin/imcp 通过在终端命令行输入fsl,可打开UI界面；\n通过类似\u0026lt;fsl命令\u0026gt;_gui方式，可以打开UI界面。比如Bet_gui,注意fsl命令的首字母需要大写。\n在MATLAB上使用FSL 在 macOS 上，fslinstaller 脚本通常会为您进行设置，因此您不需要这样做。但是，如果安装程序由于某种原因无法配置 MATLAB，您可能需要手动执行此操作。\nMATLAB % FSL Setup setenv( \u0026#39;FSLDIR\u0026#39;, \u0026#39;/usr/local/fsl\u0026#39; ); setenv(\u0026#39;FSLOUTPUTTYPE\u0026#39;, \u0026#39;NIFTI_GZ\u0026#39;); fsldir = getenv(\u0026#39;FSLDIR\u0026#39;); fsldirmpath = sprintf(\u0026#39;%s/etc/matlab\u0026#39;,fsldir); path(path, fsldirmpath); clear fsldir fsldirmpath; Flanker公开数据下载 访问Openeuro官网，下载Flanker task的fMRI数据集。 下载的ds000102数据集使用的是Flanker任务，其目的是为了挖掘一种被称为认知控制的心理过程。在本教程中，我们将把认知控制定义为为了正确完成任务而忽略不相关的刺激的能力。\n在Flanker任务中，箭头要么指向左边，要么指向右边，受试者被要求按下两个按钮中的一个，指示中间箭头的方向。如果它指向左边，受试者就按下 \u0026ldquo;左 \u0026ldquo;字按钮；如果它指向右边，受试者就按下 \u0026ldquo;右 \u0026ldquo;字按钮。中间的箭头两侧有其他的箭头，这些箭头要么与中间的箭头指向同一方向，要么与中间的箭头指向相反的方向。 Flanker任务的两个条件的例子。在不协调(Incongruent condition)条件下，中央的箭头（被试所关注的）与侧面的箭头指向相反的方向；在协调条件(Congruent condition)下，中央的箭头与侧面的箭头指向相同的方向。在这个例子中，不协调条件下的正确反应是按 \"左 \"键，而协调条件下的正确反应是按 \"右 \"键。 我们可以想象，如果中央的箭头与侧面的箭头指向同一方向，任务就比较容易，如果指向相反的方向，就比较困难。我们将前者称为 \u0026ldquo;一致 \u0026ldquo;条件，后者称为 \u0026ldquo;不一致 \u0026ldquo;条件。受试者在 \u0026ldquo;不一致 \u0026ldquo;条件下通常反应较慢，准确性较低，而在 \u0026ldquo;一致 \u0026ldquo;条件下则反应较快，准确性较高。由于反应时间的差异是稳健和可靠的，因此在我们的fMRI数据中，我们应该看到BOLD信号也有明显的差异。 本研究中Flanker任务的图示，改编自Kelly等人（2008）。受试者会看到一个固定的十字架（fixation cross），以便将注意力集中在屏幕中心，然后呈现一个 \"一致 \"或 \"不一致 \"的Flanker试验，持续2000ms。在试验过程中，被试按下左边或右边的按钮。(注意，抖动间隔通常以秒为单位递增；在这种情况下，给定试验的抖动将是以下的随机选择之一： 8,000ms、9,000ms、10,000ms、11,000ms、12,000ms、13,000ms和14,000ms）。另一个固定交叉点被呈现，开始下一个试验。 我们的目标是估计每个条件的BOLD信号的大小，然后对比（即取其差异）两个条件，看它们是否有明显的差异。\n这个任务的描述带来了一个关于设计fMRI研究的良好做法的重要观点： 如果你能设计一个能产生强烈和可靠效应的行为任务，**你将增加在成像数据中发现效应的几率。**fMRI数据是出了名的嘈杂\u0026ndash;如果你在研究中没有看到行为效应，你很可能也不会在成像数据中发现效应。\nFlanker Task Directory Structure ... ├── participants.tsv ├── sub-01 │ ├── anat │ │ └── sub-01_T1w.nii.gz │ └── func │ ├── sub-01_task-flanker_run-1_bold.nii.gz │ ├── sub-01_task-flanker_run-1_events.tsv │ ├── sub-01_task-flanker_run-2_bold.nii.gz │ └── sub-01_task-flanker_run-2_events.tsv ├── sub-02 │ ├── anat │ │ └── sub-02_T1w.nii.gz │ └── func │ ├── sub-02_task-flanker_run-1_bold.nii.gz │ ├── sub-02_task-flanker_run-1_events.tsv │ ├── sub-02_task-flanker_run-2_bold.nii.gz │ └── sub-02_task-flanker_run-2_events.tsv ... 通过fsleyes查看结构像数据 fsleyes anat/sub-01_T1w.nii.gz fsleyes中显示的解剖学图像。灰质和白质之间的对比度似乎很低，但这是因为颈部的血管（用橙色箭头表示）比大脑的其他部分要亮很多。 这可以通过改变对比度框中的数字来解决。在这里，最大值被降低到800，将最亮的信号限定在这个值上。这使得它更容易看到组织之间的对比。 通过点击和拖动鼠标来检查图像。你可以通过点击相应的窗口来切换查看窗格。请注意，当你移动鼠标时，其他窗口会实时更新。这是因为MRI数据是作为三维图像收集的，沿着其中一个维度移动也会改变其他窗口。\n你可能已经注意到，这个被试缺少了他的脸。这是因为来自OpenNeuro.org的数据已经被隐藏了身份：不仅姓名和扫描日期等信息已从头文件中删除，而且人脸也已被抹去。这样做是为了确保受试者的匿名性。\n当我们继续检查图像时，这里有两件事需要注意：\nGibbs Ringing Artigacts:看起来像池塘里的波纹的线条。这些被称为吉布斯伪影，它们可能表明来自扫描仪的MR信号的重建出现了错误。这些波纹也可能是由于受试者在扫描过程中移动太多造成的。在任何一种情况下，如果波纹足够大，它们可能会导致预处理步骤，如脑提取或归一化失败。 Abnormal intensity difference:灰质或白质内的异常强度差异。这可能表明有病变，如动脉瘤（aneurysms）或海绵瘤(cavernomas)，应立即向放射科医生报告；确保你熟悉实验室报告伪影的协议。关于你在MRI图像中可能看到的病变，请点击这里。 通过fsleyes查看功能像数据 当你看完解剖图像后，从屏幕上方的菜单中点击Overlay -\u0026gt; Remove All。然后，点击File -\u0026gt; Add from File，导航到sub-01的func目录，并选择以run-1_bold.nii.gz结尾的图像。这张图片看起来也像一个大脑，但它不像解剖学图片那样清晰。这是因为其分辨率较低。典型的研究是收集高分辨率的T1加权（即解剖学）图像和低分辨率的功能图像，部分原因是我们收集功能图像的速度更快。\n质量检测\n对功能图像的许多质量检查与解剖图像相同：注意灰质或白质中是否有极亮或极暗的斑点，以及图像的扭曲，如不正常的伸展或扭曲。常见的一个地方是在大脑的眶额部(orbitofrontal)，就在眼球上方，会看到一点点的失真。有一些方法可以减少这种失真，但现在我们将忽略它。\n另一个质量检查是确保没有过度的运动。功能性图像通常是以时间序列的形式收集的；也就是说，多个volume被串联成一个数据集。你可以通过点击fsleyes中的电影卷轴图标，像翻书一样快速翻阅所有的volumes（当然，也可以设置图像正下方的Location--\u0026gt;Voxel location中的volume数值，手动翻阅不同的volume）。请注意任何观察窗格中的任何突然的、生硬的动作。在预处理过程中，我们将对运动的程度进行量化，以决定是否保留或丢弃该被试的数据。\n参考 官网安装教程 Using FSL from MATLAB, MAC OS fMRI_DataDownload "
},
{
	"uri": "https://LiaoPan.github.io/dipy/basic/",
	"title": "快速入门",
	"tags": [],
	"description": "",
	"content": "快速入门 本教程知识点：\n导入和保存dMRI的NIfTI数据 绘制与查看dMRI影像数据 读取bval和bvec文件 Jupyter已省略部分内容，请点击这里全屏显示 "
},
{
	"uri": "https://LiaoPan.github.io/freesurfer/installation/",
	"title": "FreeSurfer教程 #1. 安装",
	"tags": [],
	"description": "",
	"content": "安装方法简述 根据自己系统下载对应的安装包（FreeSurfer 7.3.2 ~5G） 通过网址( https://surfer.nmr.mgh.harvard.edu/registration.html ),获取license.txt,将其放置在FreeSurfer的安装目录下(比如/Applications/freesurfer/7.3.2)。 依次执行下述脚本，设置环境变量,注意freesurfer的版本7.3.2需要替换成自己安装的版本。 shell $ export FREESURFER_HOME=/Applications/freesurfer/7.3.2 $ export SUBJECTS_DIR=$FREESURFER_HOME/subjects $ source $FREESURFER_HOME/SetUpFreeSurfer.sh -------- freesurfer-darwin-macOS-7.3.2-20200429-3a03ebd -------- Setting up environment for FreeSurfer/FS-FAST (and FSL) WARNING: /Users/synpro/freesurfer/fsfast does not exist FREESURFER_HOME /Applications/freesurfer/7.3.2 FSFAST_HOME /Users/synpro/freesurfer/fsfast FSF_OUTPUT_FORMAT nii.gz SUBJECTS_DIR /Applications/freesurfer/7.3.2/subjects MNI_DIR /Users/synpro/freesurfer/mni $ which freeview /Applications/freesurfer/7.3.2/bin/freeview 注意上述方式时临时有效，即仅对当前打开的终端有效，关闭该终端后，上述设置都会失效。\n永久设置环境变量方法： 将上述脚本写入~/.bash_profile文件中,操作命令如下： shell $ vi ~/.bash_profile #打开该文本，写入内容(若不熟悉vim，请使用其他工具打开即可); # FREESURFER export FREESURFER_HOME=/Applications/freesurfer/7.3.2 export SUBJECTS_DIR=$FREESURFER_HOME/subjects source $FREESURFER_HOME/SetUpFreeSurfer.sh $ source .bash_profile # 让设置立即生效 需要注意的是，上面的设置默认使用bash，如果你在Mac上使用的是zsh等shell工具，需要再做如下配置，来达到环境变量设置的永久生效。\n1.$ vim ~/.zshrc\n2.在开头添加以下内容：\nif [ -f ~/.bash_profile ]; then source ~/.bash_profile fi 3.使用下面的命令使之立即生效 $ source ~/.zshrc\n之后，每次打开新终端都可以正常使用啦。但每次都输出该信息太丑了，如图:\nLast login: Sat Feb 4 17:38:25 on ttys012 -------- freesurfer-darwin-macOS-7.3.2-20220804-6354275 -------- Setting up environment for FreeSurfer/FS-FAST (and FSL) FREESURFER_HOME /Applications/freesurfer/7.3.2 FSFAST_HOME /Applications/freesurfer/7.3.2/fsfast FSF_OUTPUT_FORMAT nii.gz SUBJECTS_DIR /Applications/freesurfer/7.3.2/subjects MNI_DIR /Applications/freesurfer/7.3.2/mni 那怎么可以隐藏掉，方法如下：打开~/.bash_profile文件，删除或者注释掉 source $FREESURFER_HOME/SetUpFreeSurfer.sh,然后将上述终端输出消息和echo $PATH后的FreeSurfer相关信息，改为如下格式，并写入.bash_profile文件。 ~/.bash_profile # FREESURFER export FREESURFER_HOME=/Applications/freesurfer/7.3.2 export SUBJECTS_DIR=$FREESURFER_HOME/subjects # source $FREESURFER_HOME/SetUpFreeSurfer.sh export PATH=/Applications/freesurfer/7.3.2/bin:/Applications/freesurfer/7.3.2/fsfast/bin:/Applications/freesurfer/7.3.2/mni/bin:$PATH export FSFAST_HOME=/Applications/freesurfer/7.3.2/fsfast export FSF_OUTPUT_FORMAT=nii.gz export SUBJECTS_DIR=/Applications/freesurfer/7.3.2/subjects export MNI_DIR=/Applications/freesurfer/7.3.2/mni 参考 官网安装指导 https://surfer.nmr.mgh.harvard.edu/fswiki//FS7_mac "
},
{
	"uri": "https://LiaoPan.github.io/mrtrix/basic/",
	"title": "MRtrix3教程 #1 快速入门",
	"tags": [],
	"description": "",
	"content": " 相关知识点 基础概念 1. T1像与T2像 2. 白质的结构 3.扩散梯度（Diffusion Gradient）与B值（B-value） 4.B向量（B-vectors） 5.张量建模 6.其他的扩散衡量指标 7.扩散张量成像的缺点：交叉纤维问题 MRtrix Viewer使用 BTC_preop（Brain Tumor Connectomics Data）数据下载 MRtrix数据格式与格式转换 检查Bvals和Bvecs 学习参考 MRtrix是一个用于分析扩散数据的软件包。与张量拟合技术相比，MRtrix的一个显著优势是他们的约束球面反卷积方法，或称CSD(Constrained spherical deconvolution)；该方法将每个体素的扩散信号解卷为一系列重叠的纤维束,这就减少了在拟合张量时可能出现的纤维交叉问题。\n除了MRtrix团队创建的命令库之外，该软件封装了FSL的部分命令：特别是topup和eddy这两个命令。如果你还没有安装FSL软件，请下载并安装fMRI软件包FSL。\n相关知识点 学习使用fixel-based分析方法来量化每个体素的白质纤维密度 学习怎么使用概率纤维束成像创建纤维束图 学习如何创建连接体(connectomes)以及如何可视化连接不同大脑区域的纤维数量 基础概念 1. T1像与T2像 在T1或解剖扫描中，白质比灰质浅，而灰质又比脑脊液浅；在T2或功能扫描中，相对强度被翻转。 典型的T1加权（解剖）和 T2加权（功能）图像。注意从T1加权成像到T2加权成像时组织类型的相对强度是如何反转的。\n然而，还有其他类型的图像可以通过MRI扫描仪获得。在本节中，我们将重点讨论扩散加权核磁共振成像，或称dMRI，它测量大脑不同部位的相对扩散性\u0026ndash;特别是在白质束内。\n2. 白质的结构 为什么dMRI会关注白质束？想象一下剥开一根奶酪条，然后想象一下剥开大脑\u0026ndash;就像奶酪条一样，大脑有首选的撕裂方向。这些方向与底层白质束相对应，白质束是厚厚的有髓神经元束（myelinated neurons），连接着大脑的附近和遥远的部分。例如，下纵束(inferior longitudinal fasciculus)连接大脑的视觉和颞部区域，而钩束(uncinate fasciculus)则连接大脑的颞部和下额部。这些神经束沿着大脑的所有三个维度行进，它们可能相互平行或相互交叉。\nIllustration of several main white matter tracts. Figure taken from Thiebaut et al., 2015. 大脑的白质因其颜色而得名；这些神经元是高度髓鞘化的，这意味着它们有一层厚厚的脂质涂层，既能使它们绝缘，又有助于电脉冲的传输，就像绝缘的电线。相比之下，灰质神经元则相对没有髓鞘，这使得特定区域内的神经元密度更高。\n如果对Diffusion的历史感兴趣，详情请查看\n3.扩散梯度（Diffusion Gradient）与B值（B-value） 扩散梯度由以下参数生成：\nThe magnitude of diffusion gradient (G); The time between gradients (𝚫) ; T duration of diffusion gradient (𝜹). 这些可以组合成一个方程式，即所谓的b值，如下图所示。 请注意，b值与梯度的大小、梯度的持续时间和梯度之间的时间成正比；如果这些参数中的任何一个增加，b值也会随之增加。\n下图所示b值为0的扩散加权图像与典型的T2加权图像几乎相同\u0026ndash;脑脊液（CSF）是亮的，灰质是暗的。当我们增加b值时，我们看到在大脑的特定部位，主要是白质内有更大的信号损失。这是因为这些白质束内的水主要沿着束的方向扩散，生成的图像显示出相应的低信号。(较高的b值也使图像更容易受到图像伪影的影响，如运动和被称为涡流（eddy）的磁流）。 较高的b值将对检测扩散更敏感，但存在更多噪声和更易受振动伪影影响的风险。\n以一个以上的b值获取的扩散图像被称为多壳获取(multi-shell acquisitions)。这可以对扩散的方向进行更精细的区分。因为根据扩散量，图像将在每个 b 值处显示不同量的信号损失。\n4.B向量（B-vectors） 到目前为止，我们已经学会了如何应用扩散梯度，以及如何解释图像中产生的信号。为了完善我们对扩散图像如何产生的理解，我们还需要知道应用梯度的方向。这些方向被称为b-vectors，或简称bvecs。你会注意到，一旦下载了扩散加权扫描的数据，会有两个文本文件\u0026ndash;一个通常有后缀**.bval**，表示b值，另一个有后缀**.bvec**，代表b向量。\n假设收集了40张扩散加权图像，且第一个volume的b值为0，其余volume的b值为1000。bvals文件将有40个条目，每个bval对应于扩散加权图像中的一个独立容积。另一方面，bvecs文件将有40个三元组数字，表示该volume在X、Y和Z方向的扩散梯度方向。如果我们知道梯度的方向和大小，我们可以根据从这些体素获得的信号的变化，对沿梯度的扩散进行有根据的猜测。\nB-values示例 B-vectors示例 0 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 0 0 0.98807364702224 0.01873399689793 0.10248889029026 -0.60841137170791 0.11875726282596 0.83128935098648 0.8792484998703 0.29209038615226 0.97650814056396 -0.45731022953987 -0.26519000530242 -0.34403458237648 0.3694197833538 -0.5363900065422 0.69562232494354 0.79384189844131 -0.8140320777893 -0.15647158026695 -0.05976745858788 -0.8508283495903 0.54968833923339 -0.86733847856521 -0.96609008312225 0.33223336935043 0.17501354217529 -0.22683978080749 -0.78282612562179 -0.01112493406981 -0.23269833624363 0.91476505994796 -0.67205339670181 -0.23402217030525 0.4485667347908 0.18897378444671 0.94987839460372 -0.9148513674736 -0.44173404574394 -0.73895621299743 0.79589116573333 -0.57393205165863 0.60627329349517 0.05053876712918 -0.64032816886901 -0.00203162245452 -0.65047174692153 -0.05030425265431 0.52077239751815 -0.77435040473938 -0.46209508180618 -0.31149512529373 0.72376120090484 0.35057383775711 0.58841001987457 0.30768102407455 0.58442068099975 -0.43342873454093 0.60935580730438 0.21404276788234 -0.14940990507602 -0.08567165583372 -0.44128519296646 -0.42076206207275 0.77442812919616 0.26836225390434 -0.9886794090271 -0.01840304397046 -0.10154163837432 0.60881024599075 -0.11891078948974 -0.83279365301132 -0.87748628854751 -0.2911439538002 -0.97587263584137 0.45687541365623 0.2644036412239 0.34314483404159 -0.37085926532745 0.53519117832183 -0.69378554821014 -0.79480296373367 0.8121600151062 0.15640883147716 0.0600587055087 0.852090716362 -0.54919642210006 0.86885839700698 0.96635591983795 -0.33167579770088 -0.17399430274963 0.22716110944747 0.78298610448837 0.01114399824291 0.23385895788669 -0.91456174850463 0.6740972995758 0.23286212980747 -0.44666454195976 -0.18938872218132 -0.95080780982971 0.91358888149261 0.44201084971427 0.73829895257949 -0.79423487186431 0.5715285539627 -0.60760217905044 -0.05102515220642 0.63832122087478 0.00161422998644 0.65151822566986 0.05034917593002 -0.52154493331909 0.77315002679824 0.46328803896904 0.31260219216346 -0.72411864995956 -0.35144120454788 -0.58741247653961 -0.3066479563713 -0.58275157213211 0.43335115909576 -0.61113619804382 -0.21487313508987 0.15031689405441 0.08529827743768 0.43970343470573 0.42256951332092 -0.77373939752578 -0.26831793785095 0 0 -0.01852251589298 0.99980324506759 0.65190172195434 0.77669501304626 0.51643615961074 0.24059402942657 0.11685247719287 0.9260526895523 0.1235506683588 0.85478085279464 0.85505563020706 0.64182126522064 0.37680619955062 0.68586140871048 0.09719203412532 0.50450026988983 0.05807575210928 0.54915863275528 0.96547383069992 0.4169929921627 0.83072793483734 0.1662128418684 0.24979101121425 0.7805278301239 0.19109116494655 0.95903354883194 0.61787110567092 0.36186653375625 0.73179537057876 0.40054687857627 0.23983028531074 0.15332546830177 0.19694779813289 0.11983390152454 0.24672436714172 0.22436074912548 0.89713984727859 0.64289963245391 0.39663499593734 0.03941979259252 0.51400256156921 0.72016698122024 0.40433484315872 0.82592779397964 0.60496312379837 0.3299603164196 0.7809572815895 0.47501924633979 0.56527525186538 0.39308729767799 0.67895883321762 0.67152732610702 0.68220138549804 0.50802809000015 0.41673135757446 0.81480491161346 0.23104956746101 0.87857925891876 0.07421392202377 0.90127205848693 0.31627905368804 0.14664776623249 0.59513312578201 0.95450747013092 0.01850401610136 -0.99982780218124 -0.64990043640136 -0.7771503329277 -0.51860928535461 -0.24067203700542 -0.11694828420877 -0.92531460523605 -0.12353691458702 -0.85404860973358 -0.85365968942642 -0.6399946808815 -0.37781903147697 -0.68439275026321 -0.0959820151329 -0.50524860620498 -0.05786505714058 -0.5474424958229 -0.96439582109451 -0.41736420989036 -0.83053159713745 -0.16672849655151 -0.24981169402599 -0.77884089946746 -0.18985091149807 -0.95970767736435 -0.61819595098495 -0.36017289757728 -0.7332512140274 -0.40044379234314 -0.24039900302887 -0.15302035212516 -0.19559489190578 -0.12080664187669 -0.24619971215725 -0.22405302524566 -0.89700889587402 -0.64234739542007 -0.39595165848732 -0.03925511986017 -0.51513165235519 -0.72206115722656 -0.40336072444915 -0.82375878095626 -0.60597515106201 -0.33166021108627 -0.78185319900512 -0.47429451346397 -0.56685864925384 -0.39410242438316 -0.67933368682861 -0.67376309633255 -0.68098336458206 -0.50633686780929 -0.41543397307395 -0.81643337011337 -0.23181574046611 -0.87980186939239 -0.07386588305234 -0.9025894999504 -0.31557491421699 -0.14773198962211 -0.59484159946441 -0.95507723093032 0 0 -0.15286396443843 -0.00651476159691 0.75134563446044 -0.16303530335426 -0.84805089235305 -0.50107139348983 0.46180909872055 0.23897625505924 0.17654202878475 0.24539165198803 0.44559413194656 0.68535083532333 -0.849438726902 0.49181297421455 0.71180284023284 -0.33955046534538 0.57790917158126 0.82093930244445 0.25355103611946 -0.31969979405403 0.08794292062521 -0.4691452383995 -0.06537938863039 0.529525578022 0.96584397554397 -0.16970072686672 -0.07361198216676 0.93216359615325 -0.64056777954101 0.05260347947478 -0.7005894780159 0.96006506681442 0.87177950143814 -0.97464287281036 -0.19198505580425 0.33572205901145 -0.00334380893036 0.2015535980463 0.45742538571357 0.81795364618301 -0.60682290792465 -0.69195765256881 0.65306454896926 0.56377238035202 -0.45924523472786 -0.94265359640121 -0.34482169151306 0.41801697015762 -0.68332421779632 -0.86513191461563 -0.12322624027729 -0.65280097723007 0.43402189016342 0.80451220273971 0.69626688957214 -0.38500982522964 -0.75848639011383 -0.42694765329361 -0.98598629236221 -0.42469879984855 0.83978271484375 -0.89523947238922 0.21465709805488 -0.12998943030834 0.14889819920063 0.00240560458041 -0.75320565700531 0.15933430194854 0.84670227766037 0.49852964282035 -0.46512472629547 -0.24295699596405 -0.18003137409687 -0.248728454113 -0.44872692227363 -0.68750166893005 0.84836089611053 -0.49515345692634 -0.71375703811645 0.33617293834686 -0.58055818080902 -0.82209664583206 -0.25755333900451 0.31582978367805 -0.0927395671606 0.46614015102386 0.06124122068285 -0.53235149383544 -0.96627259254455 0.16540592908859 0.06904108822345 -0.93281900882721 0.63847684860229 -0.05675909668207 0.69842767715454 -0.96039575338363 -0.87305974960327 0.97444224357605 0.18801675736904 -0.33934590220451 -0.0012511643581 -0.20568051934242 -0.4608829319477 -0.81964272260665 0.60453200340271 0.68994504213333 -0.65562653541565 -0.56693822145462 0.45641887187957 0.94205439090728 0.34160876274108 -0.42105090618133 0.68120157718658 0.8642703294754 0.11898732185363 0.65002489089965 -0.43727365136146 -0.8059714436531 -0.69843780994415 0.38163256645202 0.75681847333908 0.42400258779525 0.9858745932579 0.42196735739708 -0.84087663888931 0.89420926570892 -0.21792398393154 0.12582926452159 0 你可以控制的一个参数是你想用梯度扫描的方向数量。例如，你可以扫描获取64或128张图像，每张图像的扩散梯度从一个稍微不同的方向应用。更多的方向导致了更高的角度分辨率（angular resolution），这使你可以对扩散的方向做出更精细的空间区分。与任何提高分辨率的东西一样，其代价是更多的扫描需要更多的时间。\n5.张量建模 这种bvals和bvecs的组合使我们能够构建一个称为张量（Tensor）的东西，并将其与扩散加权图像的每个体素相匹配。在本教程中，可以把张量看作是沿x、y和z维度推动的力的模型。例如，流经花园水管的水会对管子的边界产生推力，但主要是沿着水管的长度流动。我们把能量的方向称为eigenvectors，特征向量和能量的大小称为eigenvalues,特征值。\n应用于扩散加权图像，我们使用这些相同的概念，将每个体素观察到的信号建模为特征向量和特征值的组合。特征向量表示扩散的方向，而特征值代表扩散的大小。再举花园水管的例子，水的力量沿着管子的长度会有很高的特征向量和特征值；同样，我们可以把大脑中每个体素的扩散建模为特征向量和特征值的组合。一旦我们计算出最能代表当前体素中观察到的信号的数值组合，我们就可以使用一些不同的方程来计算该体素处的扩散的不同属性。这种弥散张量成像的最流行的方程式被称为分数各向异性（FA，Fractional Anisotropy），或简称为FA。这可以用公式来计算： 各向异性是每个体素的特征值的加权和。FA值越高，说明沿某一方向的扩散越大，FA值越低，说明扩散很少，或者扩散不受约束，随意向各个方向扩散（比如说，在脑室）。如果我们发现沿其中一个维度的扩散较大，我们可以根据方向进行颜色编码。**扩散成像的惯例是用红色表示沿X轴的扩散，绿色表示沿Y轴的扩散，蓝色表示沿Z轴的扩散。**下面的图片总结了这个颜色编码方案。 在每个体素上拟合一个张量，可以生成不同类型的扩散图，如各向异性图。Tract-Based Spatial Statistics (TBSS)是一个流行的FSL扩散分析软件包，可用于创建这些地图；类似于fMRI数据的分析，这些地图可被组合成一个组分析地图，并可从地图中的感兴趣区域提取数据。 FSL的TBSS生成的张量。有关如何使用此包分析主题的概述.\n6.其他的扩散衡量指标 虽然FA是最流行的扩散衡量指标，但我们将简要回顾一下其他一些衡量指标：\n平均扩散率 (Mean Diffusivity,MD)：特征值的平均值，通过将特征值相加并除以3来计算。可用于识别大脑病变，例如水肿。 轴向扩散系数 (Axial Diffusivity,AD)：最大特征值的值。 径向扩散率 (Radial Diffusivity,RD)：两个最小特征值的平均值。通常用于分析朝向相同方向的大纤维束，例如胼胝体。 7.扩散张量成像的缺点：交叉纤维问题 尽管自扩散加权成像开始以来，扩散张量成像一直是最受欢迎的分析方法之一，但它一直受到交叉纤维问题的阻碍。上述张量拟合方法对分析只包含单一方向的白质束的体素很有用。另一方面，如果体素含有相互交叉的纤维，该方法会导致虚假的结果。举个最极端的例子，设想我们获得了一个单一体素的弥散加权图像，这个体素包含相互成直角交叉的白质纤维。由于张量被限制在生成一个单一的解决方案，以估计其所有的特征向量和特征值，它无法单独估计每束纤维的扩散方向和幅度。相反，它将分割差异并得出结论，沿任何方向都没有扩散\u0026ndash;换句话说，两个纤维束的扩散将相互抵消。\n白质纤维以直角相互交叉的示意图 为了解决这个问题，人们开发了一种被称为球面反卷积（Spherical Deconvolution）的技术。球面反卷积不是试图为在每个体素测量的复杂信号找到一个单一的解决方案，而是假设扩散信号是你期望从多个单独的纤维在不同角度相互交叉的信号的平均值。因此，单根纤维被用作基础函数来解卷更复杂的信号。\n扩散加权数据从许多不同的角度获取每个体素的扩散信号，以形成扩散方向和扩散幅度的图像。然后，信号被解构为一组在不同方向上的单个纤维。球面反卷积代替了每个体素的单一扩散数，用于生成纤维取向密度函数，或FOD（Fiber Orientation Density function）。该函数被表示为一个具有卵形轴的形状；尽管加载到主要扩散方向的轴的裂片相对于其他轴变得更长、更大，但关于沿其他轴的扩散方向和强度的信息仍然被保留。 图中是一个扩散加权图像，上面覆盖着FODs。如果我们放大前联合的一个区域，我们可以看到ODFs主要是由左至右（这也由它们的红色编码来表示）。请注意，插图右边的ODFs开始变成更多的绿色，代表着方向从主要的左右轴转为前后轴。 另一部分白质显示的FODs主要遵循前后方向；然而，一些ODFs有在前后方向和下至上方向延伸的裂片（下至上方向的颜色被编码为蓝色）。通过这种方式，FODs可以代表纤维沿多个维度的方向。 MRtrix Viewer使用 安装好mrtrix后，在终端输入命令mrview，即可打开MRtrix Viewer对扩散像数据进行可视化查看，点击UI界面上的File -\u0026gt; Open,选择想要查看的扩散像数据，就可以查看扩散像数据。 另外，我们也可以直接将文件拖拽到UI视窗，直接打开扩散像数据、结构像数据。同时，可以选择View -\u0026gt; Ortho view下的选项，调整为三视图模式。 或者，使用终端方式打开一个文件查看，如下图所示：\n$ mrview \u0026lt;*.mif\u0026gt; $ mrview \u0026lt;*.mif\u0026gt; -overlay.load \u0026lt;*.mif\u0026gt; MRtrix Viewer默认显示的第一个体积，其时间序列索引为0，即看起来像典型的 T2 加权功能图像.（0 表示时间序列中的第一个体积，1 表示第二个体积，依此类推），我们可以选择Image -\u0026gt; Next volume或者Image -\u0026gt; Go to volume跳转到不同的volume（快捷键：通过键盘左右方向键，可以快速切换volume）；视窗的左下角voxel index中最后一位，展示了当前所在的volume是哪个。 如果你发现强度的下降使图像太暗而看不清，你可以通过点击Tool -\u0026gt; View options选项来增加亮度，然后为Intensity scaling栏输入一个较低的最大值。 BTC_preop（Brain Tumor Connectomics Data）数据下载 我们将分析来自openneuro.org的一个名为BTC preop 的数据集。 请点击前往相关网站进行数据下载。 数据集中包括11名神经胶质瘤患者、14名脑膜瘤患者和11名对照受试者的术前数据在论文\u0026quot;Modeling brain dynamics in brain tumor patients using The Virtual Brain\u0026quot;使用。\nMRtrix数据格式与格式转换 MRtrix使用它自己的格式(.mif)来存储和显示成像数据。如果你已经使用过流行的fMRI软件包的教程，如SPM、FSL和AFNI，你可能记得它们都可以读取和写入NIFTI格式的图像。(AFNI默认会以它自己的BRIK/HEAD格式写文件，除非你指定你的输出应该有一个.nii扩展名，但它是唯一的例外)。MRtrix也能读取NIFTI格式的原始数据，但会以MRtrix格式输出文件，标有.mif扩展名。\n要看这是如何工作的，请导航到包含dwi数据的文件夹下，其中包含你的扩散数据。预处理数据的第一步是将扩散数据转换为MRtrix能理解的格式；我们将使用mrconvert命令将原始扩散数据与相应的.bval和.bvec文件结合起来，这样我们就可以将合并的文件用于未来的预处理步骤。\n# mrconvert -h 查看使用说明 # 注意mrconvert可以将mif与nii之间互相转换。 $ mrconvert -h MRtrix 3.0.4 mrconvert Dec 14 2022 mrconvert: part of the MRtrix3 package SYNOPSIS Perform conversion between different file types and optionally extract a subset of the input image USAGE mrconvert [ options ] input output input the input image. output the output image. ... -fslgrad bvecs bvals Provide the diffusion-weighted gradient scheme used in the acquisition in FSL bvecs/bvals format files. If a diffusion gradient scheme is present in the input image header, the data provided with this option will be instead used. ... # 将原始扩散数据与相应的`.bval`和`.bvec`文件结合起来 # mrconvert \u0026lt;input nifti\u0026gt; \u0026lt;output mif\u0026gt; -fslgrad \u0026lt;bvecs\u0026gt; \u0026lt;bvals\u0026gt; $ mrconvert sub-CON02_ses-preop_acq-AP_dwi.nii.gz sub-CON02_ses-preop_acq-AP_dwi.mif -fslgrad sub-CON02_ses-preop_acq-AP_dwi.bvec sub-CON02_ses-preop_acq-AP_dwi.bval # mrinfo \u0026lt;mif file\u0026gt; # 快速查看mif数据的信息 # 输出包含例如数据集的维度和体素大小，以及用于生成当前文件的命令； $ mrinfo sub-CON02_ses-preop_acq-AP_dwi.mif ************************************************ Image name: \u0026#34;sub-CON02_ses-preop_acq-AP_dwi.mif\u0026#34; ************************************************ Dimensions: 96 x 96 x 60 x 102 Voxel size: 2.5 x 2.5 x 2.5 x 8.7 Data strides: [ -1 2 3 4 ] Format: MRtrix Data type: signed 16 bit integer (little endian) Intensity scaling: offset = 0, multiplier = 1 Transform: 0.9988 -0.01395 0.04747 -111 0.02082 0.9888 -0.1476 -85.88 -0.04488 0.1484 0.9879 -56.76 command_history: mrconvert sub-CON02_ses-preop_acq-AP_dwi.nii.gz sub-CON02_ses-preop_acq-AP_dwi.mif -fslgrad sub-CON02_ses-preop_acq-AP_dwi.bvec sub-CON02_ses-preop_acq-AP_dwi.bval (version=3.0.4) comments: TE=1.1e+02;Time=125448.950;phase=1;dwell=0.380 dw_scheme: 0,0,0,0 [102 entries] 0,0,0,0 ... 0.9082055818,0.3669468842,-0.201277434,2800 0,0,0,0 mrtrix_version: 3.0.4 请注意，由于这是一个四维数据集(96 x 96 x 60 x 102)，最后一个维度是时间；换句话说，这个文件包含102个体积(volumes)，每个体积的尺寸是96 x 96 x 60体素。体素大小(Voxel size)字段的最后一个维度值为8.7,表示获取每个体素的时间。这个时间也被称为重复时间(repetition time)，或TR。\n检查Bvals和Bvecs 我们需要检查的其他文件是bvals和bvecs文件。(简而言之，bvals文件包含了每个容积的一个数字，表明应用于数据的扩散梯度有多大；bvecs文件包含了每个容积的三组数字，表明应用梯度的方向是什么。一般来说，具有较大b值的体积对扩散变化更敏感，但图像也更容易受到运动和生理伪影的影响，如下图所示。 三个具有不同b值的容积。b值为0相当于T2加权功能扫描，而较高的b值会导致图像质量下降（但对弥散的敏感性更高）。 其中，最重要的检查是确保bvals的数量和bvecs的数量与数据集中的卷数相同。\n$ mrinfo -size sub-CON02_ses-preop_acq-AP_dwi.mif 96 96 60 102 # 输出mif的信息，使用awk命令，提取输出文本的第4列内容； $ mrinfo -size sub-CON02_ses-preop_acq-AP_dwi.mif | awk \u0026#39;{print $4}\u0026#39; 102 从上述命令，我们得到mif文件中的volumes的数量为102，然后我们再来检查一下bvals和bvecs文件的数量是否一致。\n$ awk \u0026#39;{print NF;exit}\u0026#39; sub-CON02_ses-preop_acq-AP_dwi.bvec 102 $ awk \u0026#39;{print NF}\u0026#39; sub-CON02_ses-preop_acq-AP_dwi.bval 102 AWK中NF用法\n\u0026gt; $NF表示一行数据最后一列的那个值；NF表的是一行数据的列数; \u0026gt; 比如有个文本内容为： \u0026gt; a b c d e \u0026gt; 那么awk \u0026#39;print $NF\u0026#39;会打印出e \u0026gt; awk \u0026#39;print NF\u0026#39;会打印出5，也就是列数； 如果你的数据集中的卷数与bvals和bvecs的数量不一致，你应该向你的扫描技术员检查这个差异；文件可能没有正确上传到服务器，或者可能没有正确获得扩散加权图像。\n学习参考 官网文档 https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Introduction.html https://osf.io/ht7zv https://andysbrainbook.readthedocs.io/en/latest/TBSS/TBSS_Overview.html https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/TBSS/UserGuide "
},
{
	"uri": "https://LiaoPan.github.io/basics/",
	"title": "基础知识",
	"tags": [],
	"description": "",
	"content": "Chapter 1 Basics Discover what this Hugo theme is all about and the core-concepts behind it.\n"
},
{
	"uri": "https://LiaoPan.github.io/afni/stats/",
	"title": "AFNI 系列教程 #2.统计与建模",
	"tags": [],
	"description": "",
	"content": " 简介 运行一级分析（First-Level Analysis） uber_subject.py 脚本的再次使用 刺激时序文件（Stimulus Timing Files） 广义线性测试（Symbolic GLTs） 额外的回归选项(Extra Regress Options) 理想时间序列与广义线性模型 检查输出结果 查看统计文件 参考资料 简介 现在，经过预处理后，我们可以对数据进行模型拟合。为了理解模型拟合的原理，我们需要回顾一些基本原理，如一般线性模型（GLM）、BOLD反应和什么是时间序列。这些主题在下面章节中都有讨论。\n在你回顾了这些概念之后，你就可以使用FEAT进行一级分析了。下图说明了我们将如何对数据进行模型拟合。\n在构建了一个表明BOLD反应应该是什么样子的模型（A）后，该模型被拟合到每个体素的时间序列上（B）。模型的拟合程度（也称为拟合度）可以用统计图在大脑上表示出来，强度越高表示模型拟合度越高。然后，这些统计图可以被阈值化，只显示具有统计学意义的模型拟合的体素（C）。 关于时间序列、BOLD信号、HRF、广义线性模型相关基础知识，可参阅FSL教程。\n运行一级分析（First-Level Analysis） uber_subject.py 脚本的再次使用 之前，我们使用uber_subject.py命令为单个研究对象设置了预处理脚本。你可能还记得，我们删除了其中一个名为\u0026quot;regress\u0026quot;的处理块，因为我们当时并不关注回归。但现在，我们将把回归块添加回uber_subject.py脚本中，并将预处理和一级分析合并到一个脚本中。\n让我们为同一个被试sub-08创建一个新脚本。首先，导航到sub-08目录，输入rm -r subject_results，删除预处理目录。在包含所有被试的目录下，在命令行中输入uber_subject.py。这一次，在\u0026quot;analysis initialization\u0026quot;部分，我们将保留所有数据块的原样（不过，由于本示例数据集中的数据已经进行了切片时间校正，因此可以删除\u0026quot;tshift \u0026ldquo;数据块而不影响结果，这一点在前面的章节中已经讨论过）。\n按照预处理的方法填写解剖和功能图像，并对 \u0026ldquo;extra align options\u0026quot;和 \u0026ldquo;extra tlrc options\u0026quot;进行同样的修改。本章我们将重点讨论图形用户界面的以下部分：\nstimulus timing files; symbolic GLTs; extra regress options. 如果uber_subject.py不能使用，比如pyqt4老旧安装麻烦等问题，导致脚本不能使用，建议使用下述使用uber_subject.py脚本输出的sub_08_afni_proc.sh脚本。\nsub_08_afni_proc.sh #!/usr/bin/env tcsh # created by uber_subject.py: version 1.2 (April 5, 2018) # creation date: Mon Nov 18 12:30:05 2019 # set subject and group identifiers set subj = sub_08 set gname = Flanker # set data directories set top_dir = ${PWD}/sub-08 set anat_dir = $top_dir/anat set epi_dir = $top_dir/func set stim_dir = $top_dir/func # run afni_proc.py to create a single subject processing script afni_proc.py -subj_id $subj \\ -script proc.$subj -scr_overwrite \\ -blocks tshift align tlrc volreg blur mask scale regress \\ -copy_anat $anat_dir/sub-08_T1w.nii.gz \\ -dsets \\ $epi_dir/sub-08_task-flanker_run-1_bold.nii.gz \\ $epi_dir/sub-08_task-flanker_run-2_bold.nii.gz \\ -tcat_remove_first_trs 0 \\ -align_opts_aea -giant_move \\ -tlrc_base MNI_avg152T1+tlrc \\ -volreg_align_to MIN_OUTLIER \\ -volreg_align_e2a \\ -volreg_tlrc_warp \\ -blur_size 4.0 \\ -regress_stim_times \\ $stim_dir/congruent.1D \\ $stim_dir/incongruent.1D \\ -regress_stim_labels \\ congruent incongruent \\ -regress_basis \u0026#39;GAM\u0026#39; \\ -regress_censor_motion 0.3 \\ -regress_motion_per_run \\ -regress_opts_3dD \\ -jobs 8 \\ -gltsym \u0026#39;SYM: incongruent -congruent\u0026#39; -glt_label 1 \\ incongruent-congruent \\ -gltsym \u0026#39;SYM: congruent -incongruent\u0026#39; -glt_label 2 \\ congruent-incongruent \\ -regress_reml_exec \\ -regress_make_ideal_sum sum_ideal.1D \\ -regress_est_blur_epits \\ -regress_est_blur_errts \\ -regress_run_clustsim no 刺激时序文件（Stimulus Timing Files） 创建理想时间序列\n我们的目标是创建拟合的时间序列，以便在组级分析中使用估计的贝塔权重。但要做到这一点，我们首先需要创建理想的时间序列。\n让我们来看看Flanker数据集。在每个受试者的func目录中都有标为events.tsv的文件。这些文件包含我们创建timing files（也称为onset files）所需的三项信息：\n条件名称；\n相对于扫描开始，每次试验发生的时间（以秒为单位）；\n每次试验的持续时间。 这些信息需要从events.tsv文件中提取，并以AFNI软件可以读取的方式格式化。在这种情况下，我们将为每个条件创建一个时序文件，然后根据条件所处的运行情况分割该文件。这样，我们总共将创建四个时序文件：\n第一次运行中出现的不一致试验的时序（我们称之为 incongruent_run1.txt）；\n第二次运行中出现的不一致试验的时序（incongruent_run2.txt）；\n在第一次运行过程中进行的一致试验的时序（congruent_run1.txt）；\n第二次运行中出现的一致试验的时序（congruent_run2.txt）。\n每个时序文件的格式都相同，由三列组成，顺序如下：\n开始时间，以秒为单位，相对于扫描开始时间； 试验持续时间，以秒为单位； 参数调制（Parametric modulation）。 每次run的时序文件将浓缩为每个条件的单个时序文件，分别称为incongruent.1D和congruent.1D。1D扩展名是 AFNI 特有的，表示文件包含按行和列排列的文本。\nOpenNeuro.org上的Run-1_events.tsv文件 (A)。当我们下载该文件并在终端中查看时，它看起来就像窗口中的文本 (B)。然后，我们重新格式化事件文件，为每次run创建一个时序文件，其中包含三列： 开始时间（onset time）、持续时间(duration)和参数调制(parametric modulation)（C），然后使用 AFNI 的timing_tool.py将其转换为 AFNI 可以理解的时序格式（D）。 要格式化时序文件，请下载此脚本。（点击 Raw 按钮，然后在新打开的窗口中右击并选择 \u0026ldquo;另存为\u0026quot;即可下载）或者直接复制下述make_Timings.sh脚本。我们不会详细介绍它的工作原理，但你只需将其放在包含实验对象的实验文件夹中，然后输入bash make_Timings.sh。这将为每个实验对象的每次run创建时序文件，并将其存储在每个实验对象对应的func目录中。要检查输出，请键入 cat sub-08/func/incongruent.1D。你应该会看到与上图类似的数字。\nmake_Timings.sh #!/bin/bash #Check whether the file subjList.txt exists; if not, create it if [ ! -f subjList.txt ]; then ls | grep ^sub- \u0026gt; subjList.txt fi #Loop over all subjects and format timing files into FSL format for subj in `cat subjList.txt`; do cd $subj/func cat ${subj}_task-flanker_run-1_events.tsv | awk \u0026#39;{if ($3==\u0026#34;incongruent_correct\u0026#34;) {print $1, $2, 1}}\u0026#39; \u0026gt; incongruent_run1.txt cat ${subj}_task-flanker_run-1_events.tsv | awk \u0026#39;{if ($3==\u0026#34;congruent_correct\u0026#34;) {print $1, $2, 1}}\u0026#39; \u0026gt; congruent_run1.txt cat ${subj}_task-flanker_run-2_events.tsv | awk \u0026#39;{if ($3==\u0026#34;incongruent_correct\u0026#34;) {print $1, $2, 1}}\u0026#39; \u0026gt; incongruent_run2.txt cat ${subj}_task-flanker_run-2_events.tsv | awk \u0026#39;{if ($3==\u0026#34;congruent_correct\u0026#34;) {print $1, $2, 1}}\u0026#39; \u0026gt; congruent_run2.txt #Now convert to AFNI format timing_tool.py -fsl_timing_files congruent*.txt -write_timing congruent.1D timing_tool.py -fsl_timing_files incongruent*.txt -write_timing incongruent.1D cd ../.. done 在上文创建了时序文件后，点击 \u0026ldquo;browse stim（浏览刺激）\u0026ldquo;按钮，选择位于sub-01/func 中的congruent.1D和incongruent.1D文件。（你可以按住命令键并点击单个文件来选择多个文件）。\n单击 \u0026ldquo;OK（确定）\u0026ldquo;后，你将看到一个表格，其中包含你选择的时序文件。除了显示所选时序文件的名称外，还有另外三列，分别名为 \u0026ldquo;label\u0026rdquo;、\u0026ldquo;basis\u0026quot;和 \u0026ldquo;type\u0026rdquo;。\u0026ldquo;Label\u0026quot;是时序文件在进行模型拟合的命令（即3dDeconvolve）中的引用方式，而 \u0026ldquo;basis\u0026quot;和 \u0026ldquo;type\u0026quot;则指定了应用于时序文件的基础函数。\nGAM的默认基函数规定，起始时间应与典型 HRF 进行卷积。这种基函数只需要估计一个参数，即HRF的高度，它大致相当于神经活动对该条件的反应量。你可以应用的其他基函数包括 BLOCK 函数（即 HRF 章节中讨论过的boxcar regressor）、TENT函数用于估计条件开始后指时序间点的活动和SPMG2包括时间导数。\n下面的\u0026quot;init file types\u0026quot;字段允许你指定希望使用的卷积类型。默认的times表示对时序文件中指定的所有时间点进行卷积，并为 HRF 生成平均最适合所有发生情况的参数估计；而IM则会为每次试验估算单独的贝塔权重（可用于更高级的分析，如贝塔序列分析）。AM1和AM2选项用于参数调制分析（不在本教程范围内），而files则表示不应用卷积\u0026ndash;这对运动等干扰回归因子很有用。\n完成文件加载后，图形用户界面的这一部分应该如下所示：\n广义线性测试（Symbolic GLTs） \u0026ldquo;symbolic GLT \u0026ldquo;允许你指定广义线性检验，这些检验将在根据上述条件估算出上述贝塔权重后进行计算。这里的符号有点奇怪，最简单的方法可能是点击\u0026quot;init with examples\u0026quot;按钮来显示设置检验的示例语法。点击后，你将看到两个对比： C-I 和 mean.CI。\n让我们来看看第一个对比： 它使用对比度权重来指定如何计算不同条件之间的对比度，并在\u0026quot;刺激时序文件\u0026quot;部分指定的标签前加上对比度权重。**无符号意味着对比度权重为+1，而负号意味着对比度权重为-1。因此，\u0026ldquo;一致-不一致(congruent -incongruent)\u0026ldquo;这一行意味着 \u0026ldquo;一致\u0026quot;条件下的参数估计值权重为+1，而\u0026quot;不一致\u0026quot;条件下的参数估计值权重为-1，然后取两者之差。**使用不同的计算方法，第二个对比取两个条件的平均值，即两个条件都乘以0.5。\n一般来说，计算不同条件间差异的对比权重总和应为0，而计算不同条件间平均值的对比权重总和应为1。\n让我们修改这个表格来练习 GLT 语法，并设置我们想要的对比。在第一行中，将 \u0026ldquo;label\u0026quot;列改为 \u0026ldquo;不一致-一致(incongruent-congruent)\u0026quot;，在 \u0026ldquo;symbolic GLT \u0026ldquo;列中输入\u0026quot;不一致-一致(incongruent-congruent)\u0026quot;。同样，在第二行中指定congruent -incongruent对比。完成后，该部分应如下所示：\n额外的回归选项(Extra Regress Options) 最后，我们将说明对3dDeconvolve命令的偏好。\n第一个字段是 \u0026ldquo;离群值删减限制(outlier censor limit)\u0026quot;，它将从分析中移除离群值删减分数大于右侧字段指定值的任何TR。（这些离群值是由3dToutcount检测到的，它会标记出 TR 中信号强度与脑掩膜中其他体素相比超过3个标准差的任何体素）。如果将该值设为 0.0，则不会根据3dToutcount的输出结果对任何 TR 进行删减。由于运动量大的体块会被剔除，因此我们暂时不做调整。\n下一个字段 \u0026ldquo;用于回归的工作（CPU 数量）,jobs for regression (num CPUs)\u0026ldquo;指定了用于回归分析的处理器数量。由于该步骤对计算要求较高，因此请使用最大 CPU 数量。在本例中，我将其设置为8。\n\u0026ldquo;GOFORIT 级别（覆盖 3dD 警告）,GOFORIT level (override 3dD warnings)\u0026ldquo;将忽略3dDeconvolve检测到的任何有关设计矩阵的警告。一般来说，除非确定矩阵误差可以忽略不计，否则不应使用 GOFORIT。一般情况下，当3dDeconvolve检测到两个或多个回归因子之间存在异常高的共线性时，就会发出警告并停止运行。\n\u0026ldquo;bandpass in regression\u0026quot;字段通常用于静息态分析，以去除低频和高频波动。 但对于任务数据，低通滤波（即去除高频信号）有可能会去除与任务相关的实际信号。此项留空。\n此外还有四个复选框。\u0026ldquo;回归运动导数(Regress motion derivatives)\u0026ldquo;将对运动回归器的高阶导数进行建模，从而捕捉到更复杂的头部运动。这对于运动频繁的人群非常有用，例如儿童或某些临床受试者；而且只要你的数据时间序列较长（例如一次运行中超过 200 个 TR），估计这些额外参数的自由度可能不会用完。在本教程中，我将不选中该选项，但你也可以自行决定。\n我也没有选中\u0026quot;run cluster simulation\u0026quot;复选框，因为它会在你改变阈值滑块时实时计算聚类是否具有统计意义。由于我一般不对单个受试者进行推断\u0026ndash;我们稍后会在群体水平上进行推断\u0026ndash;所以我省略了这个选项。不过，我还是选中了 \u0026ldquo;execute REMLfit \u0026ldquo;选项，因为这将创建一个单独的统计数据集，与传统的3dDeconvolve方法相比，能更好地考虑时间自相关性。稍后，我们可以使用3dREMLfit的输出来使用受试者参数估计的可变性信息，以创建更精确的组级推断图。\n完成后，这一部分应该是这样的：\n现在，依次点击最上面的三个图标（纸片、放大镜和绿色的 \u0026ldquo;开始\u0026quot;按钮）来运行预处理和回归。总共大约需要 5-10 分钟。\n理想时间序列与广义线性模型 在等待分析完成的同时，让我们来看看刚刚创建的模型与 GLM 的关系。请记住，每个体素都有一个 BOLD 时间序列（我们的结果测量），我们用 Y 表示。这些回归因子构成了我们的设计矩阵，我们用一个大的 X 来表示。\n到目前为止，所有这些变量都是已知的\u0026ndash;Y 是通过数据测得的，而 x1 和 x2 则是通过卷积 HRF 和时序起始值得到的。由于矩阵代数用于设置设计矩阵和估算贝塔权重，因此方向要转 90 度： 通常，我们认为时间轴是从左至右，但现在我们将其描述为从上到下。换句话说，运行的起始点位于时间轴的顶端。\nGLM 方程的下一部分是贝塔权重，我们用 B1 和 B2 表示。这表示我们对每个回归因子需要缩放的 HRF 的估计值，以便与 Y 中的原始数据最匹配\u0026ndash;因此称为 \u0026ldquo;贝塔权重\u0026rdquo;。等式中的最后一项是 E，表示残差，即我们理想的时间序列模型与估计贝塔权重后的数据之间的差异。如果模型拟合得好，残差就会减少，而且一个或多个贝塔权重更有可能具有统计意义。\n检查输出结果 当脚本完成后，导航到文件夹sub-08/subject_results/group.Flanker/subj.sub08/sub08.results。除了之前看到的预处理块，你还将看到统计数据集： 标有stats.sub_08+tlrc的数据集已使用传统的3dDeconvolve方法进行了分析；数据集stats.sub_08_REML+tlrc已考虑了时间自相关性。\n你还会看到一些以 \u0026ldquo;X \u0026ldquo;开头的文件，如X.xmat.1D。这些文件代表设计矩阵的不同部分。例如，你可以输入aiv X.jpg查看设计矩阵： 如果要查看不同的视图，在单独的行中查看所有回归因子，请键入1dplot -sepscl X.xmat.1D：\n如果将此图旋转90度，就会发现它是上图同一设计矩阵的不同表示形式。 确保设计矩阵看起来合理。低频漂移的建模是否符合你的预期？每个条件下试验的起始时间是否与你在上一章中创建的定时文件一致？\n查看统计文件 现在我们可以查看数据的对比图了。输入afni打开图形用户界面，选择anat_file.sub_08作为底图。（如果你已将 MNI152 模板复制到当前目录，或将其放在 aglobal 目录中，也可以使用该模板）。选择stats.sub_08作为覆盖层。你应该会看到如下内容\n虽然 AFNI 查看器看起来有太多的选项，但一旦你对它们越来越熟悉，就可以自定义查看结果的方式。如果这是你第一次在 AFNI 中查看统计数据，那么 \u0026ldquo;Define Overlay\u0026quot;面板中最引人注目的功能将是滑块栏(slider bar)（允许你对图像进行阈值设置，使其只显示高于某一数值的值），以及 \u0026ldquo;ULay\u0026rdquo;、\u0026ldquo;OLay\u0026quot;和 \u0026ldquo;Thr\u0026quot;菜单，它们分别与 \u0026ldquo;Underlay\u0026rdquo;、\u0026ldquo;Overlay \u0026ldquo;和 \u0026ldquo;Threshold \u0026ldquo;子框相对应。\n让我们从滑动条开始。如果上下移动它，你会看到体素要么消失，要么重新出现。这是因为我们正在阈值化或移除低于滑动条左侧阈值数字的体素。这个数字将基于在 \u0026ldquo;Thr\u0026quot;菜单中选择的子块；在本例中，我们打开查看器时选择的子块是第2个volume，即 \u0026ldquo;一致性\u0026quot;条件下贝塔权重的 T 统计图。当你将滑块移动到例如 1.9753 的值时，你还会注意到滑块条下方的数字p=也发生了变化，变成了0.493。这表示当前所选阈值图的未校正 p 值阈值；换句话说，任何彩色体素都通过了 0.493 的单个 p 值阈值。\n如果你想设置特定的未校正 p 值阈值，请右键单击p= 文本，选择 \u0026ldquo;set p-threshold\u0026rdquo;，然后键入你想要的阈值（例如 0.001）。\n当我们还没有多重比较校正时，因此我们无法判断任何一个体素是否具有统计学意义。不过，在未经校正的 p 值阈值下查看数据，可以让你对统计数据的空间布局有一个大致的了解，并表明结果的趋势是否与你预测的方向一致，或者是否出现了一些问题。例如，高度相关的回归因子会有非常大的参数估计值和相应的高变异性。你还应该确保，在相对较高的未校正 p 值阈值（例如 p=0.01 或更高）下，激活一般位于灰质内。例如，如果在脑室中发现大量 \u0026ldquo;活跃 \u0026ldquo;体素，则可能表明数据质量有问题。\n现在，将 OLay 子项改为incongruent-congruent#0_Coef，将 Thr 子项改为incongruent-congruent#0_Tstat，并将未校正 p 值阈值设为 0.05。在大脑中点击，观察哪些地方的统计数据为正值，哪些地方为负值。你发现哪些地方有明显的激活体素 \u0026ldquo;集群\u0026rdquo;？它们在你预期的位置吗？\n稍后，你将学习到一种名为簇校正(cluster correction)的多重校正技术。这种方法可以寻找由通过给定未校正阈值的体素组成的簇，然后确定该簇是否重要。在本章中，我们将不讨论如何计算聚类需要多大，但现在可以点击 \u0026ldquo;*Clusterize\u0026quot;按钮，将体素数目改为 45。这样，你将只看到那些由 45 个或更多体素组成的聚类，且每个体素都通过了 0.05 的未校正 p 值阈值。你可以点击 \u0026ldquo;Rpt（报告）\u0026ldquo;按钮，查看通过该阈值的每个群集的报告，其中列出了体素大小、群集峰值体素的位置，以及将十字准线移动到群集并使其闪烁的选项。\n练习\n在 \u0026ldquo;Define Overlay\u0026quot;面板的右下角，你会看到写有 OLay = 和 Thr = 的文字，以及等号右侧的一些数字。这些数字表示交叉线所在体素的叠加和阈值数据集的值；换句话说，就是参数（或对比度）估计值以及相关的 t 统计量。选择 4 号子区间（incongruent#0_Coef）作为叠加，并写下 OLay = 字段中显示的相应数字。对子区间 #1（全等#0_Coef）做同样的操作。现在选择 7 号子模块（incongruent-congruent_GLT#0_Coef），但在此之前，请想一想你期望的值是什么。现在选择子项。它与你预测的相符吗？为什么或为什么不一致？\n执行练习 1 中的相同步骤，查看子边框 #7 和 #10 的对比。你发现叠加值有什么变化？从对比度权重来看，这合理吗？\n你可以使用图像计算器计算贝塔权重之间的差值。每个主要软件包都有一个；AFNI 的计算器称为3dcalc。在 sub-08.results 中输入 3dcalc -a stats.sub-08+tlrc'[4]'-b stats.sub-08+tlrc'[1]'-expr'a-b'-prefix Inc-Con+tlrc，即可计算出 sub-08 的不一致和一致贝塔权重之差。阅读这条命令的方法是，它将统计数据集的第 4 个子数据集分配给变量 \u0026ldquo;a\u0026rdquo;，将统计数据集的第 1 个子数据集分配给变量 \u0026ldquo;b\u0026rdquo;。我们知道这两个变量分别对应于不一致和一致的贝塔权重，然后通过在 -expr 选项中输入数学表达式 \u0026ldquo;a-b\u0026quot;来进行对比。然后，我们选择一个前缀，在本例中为 \u0026ldquo;Inc-Con\u0026rdquo;。结果输出应该与使用 Inc-Con 作为叠加时在结果查看器中看到的结果相同。现在用同样的方法创建一个名为 \u0026ldquo;Con-Inc \u0026ldquo;的输出文件，将第 1 个子条带与第 4 个子条带进行对比。\n虽然默认的配色方案和显示效果足以满足大多数用途，但你可能还是想根据自己的喜好和审美进行更改。例如，一旦你设置好统计叠加的阈值，请单击 AFNI GUI 中的 \u0026ldquo;Define Datamode\u0026quot;按钮，单击 \u0026ldquo;Warp Olay on Demand\u0026rdquo;，并为 OLay Resam mode选择 Cu 重采样方法（\u0026ldquo;Cubic\u0026quot;插值）。这将平滑在你使用的阈值下存活的体素边缘。回到 \u0026ldquo;Define Overlay\u0026quot;面板，右键单击颜色栏，选择不同的调色板，看看哪种最合适。\n参考资料 https://andysbrainbook.readthedocs.io/en/latest/AFNI/AFNI_Short_Course/AFNI_Statistics/AFNI_06_Stats_Running_1stLevel_Analysis.html "
},
{
	"uri": "https://LiaoPan.github.io/fsl/preprocess/",
	"title": "FSL系列教程 #2. 预处理",
	"tags": [],
	"description": "",
	"content": " 简介 步骤一： Brain Extraction(颅骨去除，skullstripping) 步骤一：如何使用bet命令行的方式去除颅骨 如何修复效果差的颅骨去除 步骤二：基于FEAT的预处理(汇总) 运动校正（Motion Correction） 时间层校正，Slice-Timing Correction 平滑，Smoothing 配准和归一化： 仿射变换（Affine Transformations） 配准与归一化（Registration and Normalization） 预处理检查 检查配准与归一化 检查运动伪迹 参考 许多示例都是从Flanker/sub-08目录运行的,所以推荐使用sub-08数据进行分析计算。\n简介 对fMRI数据进行预处理时发现，一个fMRI volume不仅包含我们感兴趣的信号\u0026ndash;含氧血液的变化，还包含我们不感兴趣的波动，如头部运动（head motion）、随机漂移(random drifts)、呼吸(breathing)和心跳(heartbeats)。我们把这些其他波动称为噪声，因为我们想把它们与我们感兴趣的信号分开。其中一些可以通过建模从数据中回归出来，另一些可以通过预处理减少或去除。\n接下来，我们开始对sub-08’s的数据进行预处理。\n步骤一： Brain Extraction(颅骨去除，skullstripping) 由于fMRI研究的重点是大脑组织，我们的第一步是将头骨和非大脑区域从图像中移除。FSL有一个名为bet的工具，即大脑提取工具。它是FSL图形用户界面上列出的第一个按钮（BET brain extraction,在下图中用 \u0026ldquo;A \u0026ldquo;表示）。如果你点击这个按钮，就会打开另一个窗口，允许你指定输入图像来进行头骨剥离，以及对已进行头骨剥离的输出图像进行标注（B），还有一个可扩展的子窗口，允许你指定高级选项（C）。\n对于BET和许多其他FSL工具，你需要指定一个输入图像和一个输出图像的标签： 在输入图像上进行一些操作（例如头骨剥离），输出图像是该操作的结果。通常情况下，其他选项被设置为默认值，对大多数数据集都很有效，但如果你想的话，你可以覆盖它们。\n从sub-08目录下打开FSL GUI(比如，进入该目录后，打开终端，输入fsl命令，启动FSL GUI)，点击输入图像栏旁边的文件夹图标，并导航到anat目录。选择文件sub-08_T1w.nii.gz并点击确定按钮。请注意，输出图像字段是自动填写的，在你的输入图像上附加了大脑这个词，这是FSL的默认值。如果你愿意，你可以改变这个名字，但在本教程中我们将保持原样。\n现在点击窗口底部的 \u0026ldquo;Go\u0026quot;按钮。你会看到一些文本被写入你的终端，显示哪些命令被用来运行一个叫做bet2的命令。花点时间看看GUI是如何与终端对应的\u0026ndash;稍后我们将利用这一点，通过GUI创建一个模板，然后在终端中对其进行修改，以自动预处理我们数据集中的所有对象。\n当终端显示 \u0026ldquo;Finished \u0026ldquo;时，bet2就完成了。由于你已经创建了一个新的图像，我们应该看一下数据。在之后的每个预处理步骤之后，都建议看一下处理完成的数据，检查一下数据被处理后的质量。\nsub-08被试的结构像数据展示 sub-08被试的结构像数据被去除颅骨后的展示 sub-08被试的结构像数据叠加去除颅骨后的数据（红黄色）展示 BET整体操作录屏 示范如何使用BET来检查剥离头骨前后的解剖图像。 点击GUI底部的FSLeyes按钮。当它打开时，点击FILE -\u0026gt; Add from File，并按住shift键选择原始的解剖图像和你刚刚创建的头骨去除图像。正如你在前一章中所看到的，你要改变对比度以清楚地区分灰质和白质。\n通过加载这两幅图像，你可以比较头骨被移除之前和之后的图像。在FSLeyes左下角的叠加列表面板中，点击 \u0026ldquo;眼睛\u0026quot;图标来隐藏相应的图像。例如，如果你点击sub-08_T1w旁边的眼睛图标，原来的T1解剖图像将变得不可见，而你将只看到被头骨剥离的大脑。如果你再次点击眼睛，你将看到原始的T1。为了使大脑之间的差异更加明显，在叠加列表面板中突出显示头骨剥离的图像，然后将对比度从灰度改为蓝光蓝（或者其他想要呈现的颜色）。上面的动画告诉你如何做到这一点。\n在2019年11月发布的fsleyes中，一些用户在试图加载由任何FSL命令生成的图像时，会遇到以下错误信息： \u0026ldquo;Error loading overlay: Does not look like a BIDS file.\u0026quot;。如果你得到这个错误信息，请尝试将anat和func目录中的.json文件移到一个单独的文件夹中，然后再次尝试加载图像。\n用鼠标点击图像周围，观察哪里有太多的大脑或太少的头骨被移除。请记住，我们正试图创建一个头骨和脸部被剥离干净的图像，只剩下大脑（如皮质（cortex）、皮质下结构（subcortical structures）、脑干(brainstem)和小脑(cerebellum)）。\n步骤一：如何使用bet命令行的方式去除颅骨 # 可以实现和GUI一致的效果，其中-f即表示fractional intensity threshold; $ bet2 sub-08_T1w.nii.gz sub-08_T1w_brain -f 0.5 -g 0 【参数自动补全\u0026amp;提示】我们在使用fsl命令时，命令参数过多、过长，不容易记住，建议可以自己完善一份zsh-completion或者bash-completion，可以在写fsl命令时，使用tab键，自动补全参数以及提示参数含义。 如何修复效果差的颅骨去除 如果对上述颅骨去除不满意，我们能做什么？回顾一下，BET窗口包含了一些选项，如果我们喜欢的话，可以改变这些选项。其中一个字段，标记为分数强度阈值（Fractional intensity threshold），默认设置为0.5。旁边的文字解释说，较小的值会给出较大的大脑轮廓估计值,反之，较大的值会给出较小的大脑轮廓估计值。换句话说，如果我们认为有太多的大脑被移除，我们应该把这个值设置为一个较小的数字，反之亦然，如果我们认为有太多的头骨被移除。\n假如BET已经删除了太多的大脑，所以我们尝试将分数强度阈值降低到0.2（即Fractional intensity threshold）。还要确保将输出名称改为有助于记住你所做的事情的名称\u0026ndash;例如，sub-08_T1w_brain_f02。点击 \u0026ldquo;Go\u0026quot;按钮，重新运行头骨剥离。\n当它完成后，在FSLeyes中加载最新的去除颅骨后的图像。点击原始解剖图像旁边的眼睛图标，同时点击我们刚刚创建的最新的头骨剥离图像旁边的眼睛图标。注意哪些地方保留了更多的皮层，特别是在额叶皮层和顶叶皮层。你可能还注意到，在这幅图像中保留了更多的硬脑膜（dura）和头骨碎片。一般来说，最好是保留过多的头骨，而不是去除过多的皮质\u0026ndash;这里和那里的头骨碎片不会导致未来的预处理步骤失败（如normalization），但一旦皮质被去除，就无法恢复它。\n步骤二：基于FEAT的预处理(汇总) 在FEAT使用前，需要使用BET对结构像数据进行颅骨去除，以便作为配准中的\u0026quot;高分辨率 \u0026ldquo;图像使用。\ngraph LR subgraph 预处理 2(运动校正)--\u0026gt;3(时间层校正)--\u0026gt;4(平滑)--\u0026gt;5(配准\u0026amp;归一化) end 其余的预处理步骤（通过normalization进行运动校正(motion correction)）将在FEAT GUI中进行。FEAT按钮位于FSL GUI菜单的中间，点击它将打开一个有几个标签的窗口。 点击FEAT FMRI分析按钮（A）可以打开FEAT GUI。现在，我们将重点关注Data、Pre-stats和Registration选项卡，它们对数据进行预处理。从右上角的下拉菜单（B），选择Preprocessing。这将使 \u0026ldquo;Stats\u0026quot;和 \u0026ldquo;Post-stats\u0026quot;标签变灰，让我们只关注预处理。点击Select 4D data,选择4D数据按钮（C），加载影像数据（在这个例子中，使用sub-08_task-flanker_run-1_bold.nii.gz，它在func目录下）。这将打开一个新的窗口（D），其中有一个文件夹图标，允许你选择一个功能成像数据运行（E）。\n当加载一个功能图像时，FSL会从该图像的头部读取信息。可以把图像本身看作是一个三维的数字矩阵，高的数字比低的数字更亮。这种对比使我们能够区分图像中的不同结构。另一方面，header（影像数据的头文件信息）包含了你在图像中没有直接看到的信息，但为了显示它，这些信息是必要的，例如，方向。四维数据（即包含多个volumes的单一数据集）的header也包含表示TR和volumes的数量。\n在加载输入数据后，这些字段将被自动输入到FEAT GUI的相应字段中，如以下视频所示： 请确保检查TR和Volumes数量是否与扫描仪上获得的数据相符。如果对所使用的参数有任何疑问，请询问相关扫描技术员。 Delete volumes：控制在任何进一步处理之前要删除的初始功能像volume的数量。\nTR:重复时间(单位：秒)，表示扫描一个volume后到下一个volume之间的间隔时间。\nHigh pass filter cutoff:（单位：秒）控制你将允许的最长时间段。\n详见fsl官网\nFEAT产生的HTML报告 接下来的两个选项卡，Pre-stats和Registration，将在后续讨论。\n运动校正（Motion Correction） 如果受试者在移动，图像会看起来很模糊；如果受试者是静止的，图像会看起来更清晰。但这还不是全部：如果被试者经常移动，我们也有可能从移动的体素上测量信号。这样，我们就有可能在实验的一部分时间里测量来自该体素的信号，而在受试者移动后，则测量来自不同区域或组织类型的信号。\n最后，运动会给成像数据带来干扰，因为运动会产生信号。如果受试者每次对刺激做出反应时都会移动\u0026ndash;例如，如果他每次感觉到电击时都会扭头，那么就不可能确定我们测量的信号是对刺激的反应，还是因为运动。\n\u0026ldquo;撤销\u0026quot;这些运动的一种方法是通过刚体转换(rigid-body transformations)。为了说明这一点，拿起附近的一个物体：例如，一个电话或一个咖啡杯。把它放在你面前，并在心里标记它的位置，这就是参考点（reference point）。然后将该物体向左移动一英寸，这被称为平移（translation），这意味着向左或向右、向前或向后、向上或向下的任何移动。如果你想让物体回到它开始的地方，你只需将它向右移动一英寸。\n同样，如果你把物体向左或向右旋转，你可以通过向相反的方向等量旋转来撤销。这些被称为旋转(rotations)，和平移一样，它们有三个自由度，或者说它们可以移动的方式：围绕X轴（也称为俯仰，或向前和向后倾斜），围绕Y轴（也称为滚动，或向左和向右倾斜），以及围绕Z轴（或偏航，如摇头 \u0026ldquo;不\u0026rdquo;）。\n我们对功能像数据的volumes做同样的操作，把我们时间序列中的第一个volume称为reference volume（参考点）。如果在扫描过程中，我们的受试者将他的头向右移动了一英寸，我们可以检测到这种移动，并通过将该volume向左移动一英寸来消除它。我们的目标是检测任何一个volume的移动，并将这些volume与参考volume重新对齐（realgin）。\nreference volume可以是时间序列中的任何volume（尽管它通常是第一、中间或最后一个volume）。如果在扫描过程中，受试者向右移动，该运动可以通过参考reference volume做相反的运动来 \u0026ldquo;消除 \u0026ldquo;。\n在FEAT的图形用户界面中，运动校正是在Pre-stats标签中指定的。FEAT默认使用FSL的MCFLIRT工具，你可以在下拉菜单中看到它。你可以选择关闭运动校正，但除非你有理由这样做，否则请保持原样。\n时间层校正，Slice-Timing Correction 整个照片是在一瞬间拍摄完成的，而fMRI的volume是分片（slices）获取的。每个切片都需要时间来获取（从几十到几百毫秒）。\n两种最常用的创建volume的方法是顺序和交错的切片采集。顺序切片采集是连续采集每个相邻的切片，从下到上或从上到下。交错式切片采集每一个间隔的切片，然后在第二遍的时候填补空隙。这两种方法在下面的视频中都有说明。 正如在后面看到的，当我们对每个体素的数据进行建模时，我们假设所有的切片（slices）是同时获得的。为了使这一假设有效，每个切片的时间序列需要在时间上向后移动，即获取该切片所需的时间。Sladky等人（2011年）还证明，对于TR较长（如2s或更长）的研究，尤其是大脑背侧区域的研究，切片时间校正可使统计能力显著提高。\n尽管时间层校正似乎是合理的，但也有一些反对意见：\n一般来说，除非需要，否则最好不要对数据进行插值（即编辑）； 对于短的TR（例如，大约1秒或更短），时间层校正似乎不会导致统计能力的任何明显提高； 许多由时间层校正解决的问题可以通过在统计模型中使用时间导数（temporal direivate）来解决（在后面关于模型拟合的章节中讨论）。 FSL的默认设置是不做时间层校正，而是包含一个时间导数。稍后，我们将做一个练习，比较有无切片时间层校正的数据，以观察它的差别有多大。\n平滑，Smoothing 常见的做法是对fMRI数据进行平滑处理，或将每个体素的信号替换为该体素邻近区域的加权平均。这初看起来很奇怪\u0026ndash;为什么我们要使图像比原来更模糊？\n的确，平滑化会降低fMRI数据的空间分辨率，而我们并不希望分辨率降低。但平滑化也有好处，这些好处可以超过缺点。例如，我们知道fMRI数据包含很多噪音，而且噪音经常大于信号。通过对附近的体素进行平均化，我们可以消除噪音并增强信号。\n在这个动画中，两个不同的平滑核（4毫米和10毫米）被应用于一个fMRI扫描。请注意，随着我们使用更大的平滑核，图像变得更加模糊，解剖细节变得不那么明显。还要注意的是，为了简单起见，这个动画使用大脑的二维切片来演示这个预处理步骤。在实际的fMRI数据中，内核将应用于所有三个维度。 平滑化还有一个好处。正如你将在下一节看到的，我们的目标是将每个受试者的大脑归一化到一个具有标准化坐标的模板大脑上。\n配准和归一化： 虽然大多数人的大脑是相似的\u0026ndash;例如，每个人都有扣带回（cingulate gyrus）和胼胝体(corpus callosum)\u0026ndash;但在大脑的大小和形状上也有差异。因此，如果我们想做一个群体分析(group analysis)，我们需要确保每个受试者的每个体素都对应于大脑的同一部位。例如，如果我们要测量视觉皮层中的一个体素，我们要确保每个受试者的视觉皮层都是一致的。\n这是通过对图像进行配准(Registering)和归一化(Normalizing)来实现的。就像你要折叠衣服以装入行李箱一样，每个大脑都需要被转换为具有相同的大小、形状和尺寸。我们通过归一化（或扭曲）到模板来实现这一目标。模板是一个具有标准尺寸和标准坐标的大脑，因为大多数研究人员都同意在报告他们的结果时使用它们。这样一来，如果你将你的数据归一到该模板，并在坐标X=3、Y=20、Z=42处发现了一个效应，那么其他将他们的数据扭曲到同一模板的人可以将他们的结果与你的结果进行对照。模板大脑的尺寸和坐标也被称为标准化空间（standardized space）。\n一个常用的模板的例子，MNI152脑模板。这是152个健康成人大脑的平均值，代表了大多数研究的人群。如果你正在研究其他人群--例如儿童或老年人--考虑使用从该人群的代表中创建的模板。 仿射变换（Affine Transformations） 为了将图像扭曲成一个模板，我们将使用一个仿射变换(Affine transformation)。这类似于上面运动校正中描述的刚体变换，但它又增加了两个变换：缩放(zooms)和错切(shear)。平移和旋转对于像笔这样的日常物体来说是很容易做到的，而缩放和错切则更不寻常\u0026ndash;缩放可以缩小或放大图像，而错切则是将图像的对角线相对的角拉开。下面的动画总结了这四种类型的线性变换。 与刚体变换一样，缩放和错切都有三个自由度： 你可以沿x轴、y轴或z轴缩放或错切图像。那么，总的来说，仿生变换有12个自由度（（平移、旋转、缩放、错切）* （x、y、z）= 4 * 3= 12）。这些也被称为线性变换，因为沿轴的一个方向应用的变换会伴随着相反方向的等量变换。例如，向左平移一毫米，意味着图像从右边移动了一毫米。同样地，如果一个图像沿Z轴放大一毫米，它就会沿该轴的两个方向放大一毫米。没有这些约束的变换被称为非线性变换。例如，非线性变换可以在一个方向上放大图像，而在另一个方向上缩小图像，就像挤压海绵时一样。这些类型的变换将在后面讨论。\n配准与归一化（Registration and Normalization） 回顾一下，我们的数据集中既有解剖学图像，也有fMRI图像。我们的目标是将fMRI图像变换到模板上，这样我们就可以对所有的受试者进行组分析。虽然简单地将fMRI图像直接翘曲到模板上似乎是合理的，但在实践中，这样做效果并不好\u0026ndash;图像是低分辨率的，因此不太可能与模板的解剖细节相匹配。解剖图像是一个更好的选择。\n虽然这似乎对我们实现目标没有帮助，但事实上，对解剖图像进行扭曲可以帮助将fMRI图像带入标准化的空间。请记住，解剖和功能扫描通常是在同一时段获得的，而且在两次扫描之间，受试者的头部几乎没有移动。如果我们已经将解剖图像规范化为一个模板，并记录了所做的转换，我们就可以将同样的转换应用于fMRI图像\u0026ndash;只要它们与解剖图像在同一位置开始。\n这种功能图像和解剖图像之间的对位被称为配准。大多数配准算法使用以下步骤：\n假设功能图像和解剖图像处于大致相同的位置。如果它们不在同一位置，则对准图像的轮廓。 利用解剖图像和功能图像具有不同的对比度权重这一事实\u0026ndash;也就是说，在解剖图像上图像较暗的区域（如脑脊液）在功能图像上会显得明亮，反之亦然。这被称为互信息（mutual information）。配准算法移动图像以测试解剖和功能图像的不同重叠，将一个图像上的明亮体素与另一个图像上的黑暗体素相匹配，将黑暗体素与明亮体素相匹配，直到找到一个无法改进的匹配。 一旦找到了最佳匹配，然后将用于将解剖图像与模板进行扭曲的相同转换应用于功能图像。 归一化、平滑、统计功效(Normalization,Smoothing, and Statistical Power)\n正如在上一页讲述的那样，平滑处理倾向于消除噪音和增强信号。这也适用于群体分析，在这种情况下，所有受试者的图像都被规范化为一个模板。尽管每个受试者的功能图像将被转换为与模板的一般形状和大的解剖学特征相匹配，但较小的解剖学区域在归一化的功能图像中的排列方式会有差异。如果图像被平滑化，信号簇之间会有更多的重叠，因此更有可能检测到一个显著的影响。\n基于FEAT GUI的配准操作 配准（Registration）和归一化(Normalization)虽然不同，但在FEAT GUI的配准标签中被打包成一个步骤。一旦你选择了这个选项卡，点击主结构图像(Main structual image)旁边的框选按钮来扩展输入区域。然后选择受试者的头骨剥离图像。\n我们会注意到，在主结构图像（Main structual image）和标准空间(Standard space)字段下面都有下拉菜单。\n主结构图像字段下的菜单对应于将功能配准到解剖图像上的选项。 标准空间字段下的菜单是将解剖图像与模板图像标准化的选项。 在这几组菜单中，左边的下拉菜单是搜索窗口，右边的下拉菜单是自由度窗口。 在 \u0026ldquo;Search\u0026quot;窗口中，有三个选项： 1）不搜索(No Search)；2）正常搜索(Normal search)；和3）全面搜索(Full search)。这意味着FSL要在功能图像和解剖图像之间（用于配准）以及解剖图像和模板图像之间（用于归一化）进行多少搜索以获得良好的初始配准。完全搜索选项需要更长的时间，但更彻底，因此更可能产生更好的配准和规范化。\n在自由度窗口，您可以使用3、6或12个自由度来转换图像。配准有一个额外的选项，BBR，代表脑边界配准(Brain-Boundary Registration)。这是一种更先进的配准技术，使用组织边界来微调功能图像和解剖图像之间的排列。与上面的全面搜索选项类似，它需要更长的时间，但往往能得到更好的配准。\n现在，将两个搜索选项都设置为完全搜索，两个自由度选项都设置为12自由度。如果你已经在 \u0026ldquo;Data\u0026quot;选项卡中加载了你的功能图像，点击 \u0026ldquo;Go\u0026quot;按钮来运行所有的预处理步骤。\n配准和归一化是单个被试预处理Pipeline的最后一步。\n预处理检查 就像我们在处理颅骨去除（skull-stripped）图像时一样，我们将在使用FEAT GUI在处理它们之前和之后检查我们的数据。在你点击 \u0026ldquo;Go\u0026quot;按钮后，会自动弹出浏览器页面，展现像下面这样的HTML页面，会展示出每一步的进展。 检查配准与归一化 由于我们只做预处理，我们将只有配准（Registration）和预统计(Pre-stats)标签的结果。点击 \u0026ldquo;Registration\u0026quot;选项卡，检查每个配准和归一化步骤的结果。如果你向下滚动页面，你应该看到看起来像这样的图像： 每张图片都是将一个大脑的红色轮廓（结构像数据）叠加到另一个大脑的灰度图像（功能像数据）上。第一幅图，\u0026ldquo;Summary Registration\u0026rdquo;，显示了一个有代表性的功能像图像\u0026ndash;在这种情况下，fMRI时间序列中的中值图像\u0026ndash;作为底层，而模板大脑作为红线。报告首先显示的是这幅图像，因为如果之前的配准或归一化步骤有任何问题，这幅图像就会出现明显的错误，比如图像偏斜或大部分在红色轮廓之外。\n寻找红色轮廓是否近似于追踪灰度图像的轮廓。还要检查图像的一些内部结构，如脑室（ventricle），是否对齐。对其他排列进行同样的质量检查，如功能图像的例子与高分辨率图像（即解剖图像）的配准，以及高分辨率图像（highres image）与标准空间模板的标准化。\n检查运动伪迹 当你看完配准页面后，点击\u0026quot;Pre-stats\u0026quot;链接。如果你向下滚动，你会看到该运行的时间序列中的运动图，X轴上标明体积，Y轴上标明运动量（以毫米为单位）。\n检查运动图中的峰值是否大于体素分辨率的一半，以及漂移是否大于整个体素的大小。如果有超过半个体素的相对运动或超过一个体素的绝对运动，你可能要考虑更高级的校正技术，如scrubbing，或从分析中完全删除这个run。因此，如果我们获得了一个3×3×3毫米体素分辨率的体积，将标记任何体积与体积之间相对运动超过1.5毫米，或整个run中绝对运动超过3毫米的run。这些只是参考，我们可以根据自己所研究的人群来决定改变这些。\n不同的软件会以稍微不同的顺序进行这些步骤\u0026ndash;例如，FSL会在模型拟合后对统计图(statistical maps)进行归一化。还有一些分析省略了某些步骤\u0026ndash;例如，一些做多体素模式分析(multi-voxel pattern analyses)的人不平滑他们的数据。在任何情况下，上面的清单代表了在一个典型的数据集上所进行的最常见的步骤。\n相关的fmri的预处理操作，也可以采取开源的fmriprep工具箱，完成对功能像数据的预处理操作。\n参考 https://andysbrainbook.readthedocs.io/en/latest/fMRI_Short_Course/fMRI_04_Preprocessing.html https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FEAT/UserGuide "
},
{
	"uri": "https://LiaoPan.github.io/mrtrix/preprocessing/",
	"title": "MRtrix3教程 #2 预处理",
	"tags": [],
	"description": "",
	"content": " 简介 dwi_denoise命令使用 mrcalc命令使用 mri_degibbs命令使用 提取反相编码图像(dwiextract、mrcat、mrmath) 将它们放在一起：使用dwipreproc进行预处理(Eddy处理，去除涡流) 检查损坏的切片 生成Mask(dwibiascorrect、dwi2mask) 参考资料 简介 就像其他神经影像学数据一样，扩散数据在分析前应进行预处理。预处理可以去除图像中的噪声源，如运动伪影和其他失真。扩散数据尤其容易受到相位编码方向的影响而产生扭曲的伪影： 一般来说，主要的编码方向\u0026ndash;如前向后(Anterior to Posterior, AP)\u0026ndash;会使大脑的前部看起来更 \u0026ldquo;压扁\u0026rdquo;，就像从前部方向吹来的强风。后至前(Posterior to Anterior,PA)，相位编码方向的情况则相反。有时这些扭曲是非常微妙的，但其他时候它们是明显的。 以下是使用 MRtrix 完成的常见预处理步骤:\ndwi_denoise命令使用 我们要做的第一个预处理步骤是通过使用MRtrix的dwidenoise命令对数据进行去噪。这需要一个输入和一个输出参数，你也可以选择用-noise选项来输出噪声图。比如说：\n# 查看使用说明 $ dwidenoise -h MRtrix 3.0.4 dwidenoise Dec 14 2022 dwidenoise: part of the MRtrix3 package SYNOPSIS dMRI noise level estimation and denoising using Marchenko-Pastur PCA USAGE dwidenoise [ options ] dwi out dwi the input diffusion-weighted image. out the output denoised DWI image. ...... # 运行此命令需要几分钟时间。 $ dwidenoise sub-CON02_ses-preop_acq-AP_dwi.mif sub-CON02_ses-preop_acq-AP_dwi_denoise.mif -noise noise.mif dwidenoise: [100%] preloading data for \u0026#34;sub-CON02_ses-preop_acq-AP_dwi.mif\u0026#34; dwidenoise: [100%] running MP-PCA denoising mrcalc命令使用 一个质量检查是看残差(residuals)是否加载到解剖结构的任何部分。如果是这样，这可能表明大脑区域受到某种伪影或扭曲的影响不成比例。为了计算这个残差，我们将使用另一个MRtrix命令，叫做mrcalc\n$ mrcalc -h MRtrix 3.0.4 mrcalc Dec 14 2022 mrcalc: part of the MRtrix3 package SYNOPSIS Apply generic voxel-wise mathematical operations to images USAGE mrcalc [ options ] operand [ operand ... ] operand an input image, intensity value, or the special keywords \u0026#39;rand\u0026#39; (random number between 0 and 1) or \u0026#39;randn\u0026#39; (random number from unit std.dev. normal distribution) or the mathematical constants \u0026#39;e\u0026#39; and \u0026#39;pi\u0026#39;. ... EXAMPLE USAGES Double the value stored in every voxel: $ mrcalc a.mif 2 -mult r.mif This performs the operation: r = 2*a for every voxel a,r in images a.mif and r.mif respectively. A more complex example: $ mrcalc a.mif -neg b.mif -div -exp 9.3 -mult r.mif This performs the operation: r = 9.3*exp(-a/b) Another complex example: $ mrcalc a.mif b.mif -add c.mif d.mif -mult 4.2 -add -div r.mif This performs: r = (a+b)/(c*d+4.2). ... basic operations -abs (multiple uses permitted) |%1| : return absolute value (magnitude) of real or complex number -neg (multiple uses permitted) -%1 : negative value -add (multiple uses permitted) (%1 + %2) : add values -subtract (multiple uses permitted) (%1 - %2) : subtract nth operand from (n-1)th ... # 使用原始扩散数据减去经过dwidenoise降噪后的数据，会得到相关的残差数据； $ mrcalc sub-CON02_ses-preop_acq-AP_dwi.mif sub-CON02_ses-preop_acq-AP_dwi_denoise.mif -subtract residual.mif mrcalc: [100%] computing: (sub-CON02_ses-preop_acq-AP_dwi.mif - sub-CON02_ses-preop_acq-AP_dwi_denoise.mif) 然后使用mriview软件来查看这个残差图(residual map)。\nmrview residual.mif 常见的是看到大脑的灰色轮廓，如上图所示。然而，灰质和白质内的一切都应该是相对均匀和模糊的；如果你看到任何清晰的解剖标志，如个别的脑回或脑沟，这可能表明大脑的这些部分已经被噪声所破坏(如下图所示)。 如果发生这种情况，你可以将去噪过滤器的范围从默认的5增加到一个更大的数字，如7；\n$ dwidenoise your_data.mif your_data_denoised_7extent.mif -extent 7 -noise noise.mif mri_degibbs命令使用 一个可选的预处理步骤是运行mri_degibbs，它可以从数据中去除吉布斯伪影,Gibbs\u0026rsquo; ringing artifacts。这些伪影看起来像池塘里的涟漪，在b值为0的图像中最为明显,通常表现为紧邻高对比度界面的多条精细平行线。 首先用mrview查看你的扩散数据，确定是否有任何吉布斯伪影；如果有，那么你可以通过指定输入文件和输出文件来运行mrdegibbs，例如:\n$ mrdegibbs -h MRtrix 3.0.4 mrdegibbs Dec 14 2022 mrdegibbs: part of the MRtrix3 package SYNOPSIS Remove Gibbs Ringing Artifacts USAGE mrdegibbs [ options ] in out in the input image. out the output image. DESCRIPTION This application attempts to remove Gibbs ringing artefacts from MRI images using the method of local subvoxel-shifts proposed by Kellner et al. (see reference below for details). .... $ mrdegibbs sub-CON02_ses-preop_acq-AP_dwi_denoise.mif sub-CON02_ses-preop_acq-AP_dwi_den_unr.mif mrdegibbs: [100%] performing Gibbs ringing removal 像往常一样，用mrview检查前后的数据，以确定预处理步骤是否使数据变得更好、更差，或者没有影响。 如果你在你的数据中没有看到任何吉布斯伪影，那么我建议省略这一步骤。\n提取反相编码图像(dwiextract、mrcat、mrmath) 大多数扩散数据是由两个独立的成像文件组成的：一个是以主相位编码方向（primary phase-encoding direction）获取的，一个是以反向相位编码方向获取的。主相位编码方向用于获取不同b值的大部分扩散图像。另一方面，反向相位编码文件用于消除主相位编码文件中存在的任何失真现象。\n为了理解这一点，想象一下，你正在用吹风机吹头发。假设你把吹风机对准你的后脑勺，它把你的头发向前吹，吹到你的脸前；让我们把这称为后部到前部（PA）的相位编码方向。现在你的头发看起来很乱，你想消除空气从后脑勺吹到前脑勺的影响。所以你把吹风机对准你的脸的前面，它把你的头发吹向后面。如果你取其中两次吹风的平均值，你的头发应该回到正常位置。\n同样，我们使用两种相位编码方向，在两者之间创造一种平均值。我们知道这两种相位编码方式都会给数据带来两种独立的、相反的扭曲，但我们可以用消除扭曲来抵消它们。\n我们的第一步是将反向相位编码的NIFTI文件转换为.mif格式。我们还将其b值和b向量添加到mif头文件中。\n$ mrconvert sub-CON02_ses-preop_acq-PA_dwi.nii.gz - -fslgrad sub-CON02_ses-preop_acq-PA_dwi.bvec sub-CON02_ses-preop_acq-PA_dwi.bval | mrmath - mean mean_b0_PA.mif -axis 3 mrconvert: [100%] uncompressing image \u0026#34;sub-CON02_ses-preop_acq-PA_dwi.nii.gz\u0026#34; mrconvert: [100%] copying from \u0026#34;sub-CON02_ses-preop_acq-PA_dwi.nii.gz\u0026#34; to \u0026#34;/var/folde...0gn/T/mrtrix-tmp-XwJdp7.mif\u0026#34; mrmath: [100%] preloading data for \u0026#34;/var/folders/39/93zn2fy95cd9b_b38zvmvgjc0000gn/T/mrtrix-tmp-XwJdp7.mif\u0026#34; mrmath: [100%] computing mean along axis 3... 注意这里的-为临时文件命名方式，我们就可以在|后的shell命令下直接继续使用它。 原PA文件sub-CON02_ses-preop_acq-PA_dwi.nii.gz数据维度为96*96*60*2 ,得到的文件mean_b0_PA.mif的数据维度变成了96*96*60，即指定了axis=3，将在时间维度（或者说volumes）层面上进行了平均（mean）。\n接下来，我们从初级相位编码图像中提取b值，然后将两者与mrcat结合：\n$ dwiextract -h MRtrix 3.0.4 dwiextract Dec 14 2022 dwiextract: part of the MRtrix3 package SYNOPSIS Extract diffusion-weighted volumes, b=0 volumes, or certain shells from a DWI dataset USAGE dwiextract [ options ] input output input the input DW image. output the output image (diffusion-weighted volumes by default). EXAMPLE USAGES Calculate the mean b=0 image from a 4D DWI series: $ dwiextract dwi.mif - -bzero | mrmath - mean mean_bzero.mif -axis 3 The dwiextract command extracts all volumes for which the b-value is (approximately) zero; the resulting 4D image can then be provided to the ... OPTIONS -bzero Output b=0 volumes (instead of the diffusion weighted volumes, if -singleshell is not specified). -no_bzero Output only non b=0 volumes (default, if -singleshell is not specified). ... $ mrcat -h MRtrix 3.0.4 mrcat Dec 14 2022 mrcat: part of the MRtrix3 package SYNOPSIS Concatenate several images into one USAGE mrcat [ options ] image1 image2 [ image2 ... ] output image1 the first input image. image2 additional input image(s). output the output image. EXAMPLE USAGES Concatenate individual 3D volumes into a single 4D image series: $ mrcat volume*.mif series.mif The wildcard characters will find all images in the current working # 使用dwiextract提取AP方向b值为0的所有volumes，并获取其均值mif文件； $ dwiextract sub-CON02_ses-preop_acq-AP_dwi_denoise.mif - -bzero | mrmath - mean mean_b0_AP.mif -axis 3 # 使用mrcat命令合并两个图像文件,这将创建一个新图像“b0_pair.mif”，其中包含两个相位编码图像的平均b=0图像。 $ mrcat mean_b0_AP.mif mean_b0_PA.mif -axis 3 b0_pair.mif mrcat: [100%] concatenating \u0026#34;mean_b0_AP.mif\u0026#34; mrcat: [100%] concatenating \u0026#34;mean_b0_PA.mif\u0026#34; 将它们放在一起：使用dwipreproc进行预处理(Eddy处理，去除涡流) 现在我们有了运行主要预处理步骤所需的一切，该步骤由dwipreproc调用。在大多数情况下，这个命令是一个包装器，它使用FSL的命令，如topup和eddy，来解除数据的扭曲并去除涡流。在本教程中，我们将使用下面这行代码：\n$ dwifslpreproc -h MRtrix 3.0.4 dwifslpreproc dwifslpreproc: part of the MRtrix3 package SYNOPSIS Perform diffusion image pre-processing using FSL\u0026#39;s eddy tool; including inhomogeneity distortion correction using FSL\u0026#39;s topup tool if possible USAGE dwifslpreproc [ options ] input output input The input DWI series to be corrected output The output corrected image series DESCRIPTION This script is intended to provide convenience of use of the FSL software tools topup and eddy for performing DWI pre-processing, by encapsulating some of the surrounding image data and metadata processing steps. It is intended to simply these processing steps for most commonly-used DWI acquisition strategies, whilst also providing support for some more exotic ... OPTIONS -pe_dir PE Manually specify the phase encoding direction of the input series; can be a signed axis number (e.g. -0, 1, +2), an axis designator (e.g. RL, PA, IS), or NIfTI axis codes (e.g. i-, j, k) -eddy_options \u0026#34; EddyOptions\u0026#34; Manually provide additional command-line options to the eddy command (provide a string within quotation marks that contains at least one space, even if only passing a single command-line option to eddy) -se_epi image Provide an additional image series consisting of spin-echo EPI images, which is to be used exclusively by topup for estimating the inhomogeneity field (i.e. it will not form part of the output image series) ... Options for specifying the acquisition phase-encoding design; note that one of the -rpe_* option s MUST be provided -rpe_none Specify that no reversed phase-encoding image data is being provided; eddy will perform eddy current and motion correction only -rpe_pair Specify that a set of images (typically b=0 volumes) will be provided for use in inhomogeneity field estimation only (using the -se_epi option) -rpe_all Specify that ALL DWIs have been acquired with opposing phase-encoding 第一个参数是输入和输出；第二个选项，-nocleanup将保留临时处理文件夹，其中包含一些我们以后要检查的文件。 -pe_dir AP表示主相位编码方向是从前到后，而-rpe_pair与-se_epi选项相结合，表示下面的输入文件（即 \u0026ldquo;b0_pair.mif\u0026rdquo;）是一对自旋回波图像，是用反向相位编码方向获取的。最后，-eddy_options指定了FSL命令eddy的特定选项。你可以访问eddy用户指南，了解更多的选项和它们的详细作用。现在，我们只使用选项--slm=linear（这对获取的数据少于60个方向的数据很有用）和--data_is_shelled（这表明扩散数据是用多个b值获取的）。\n# dwifslpreproc \u0026lt;input.mif\u0026gt; \u0026lt;output.mif\u0026gt; -nocleanup -pe_dir AP -rpe_pair -se_epi b0_pair.mif -eddy_options \u0026#34; --slm=linear --data_is_shelled\u0026#34; $ dwifslpreproc sub-CON02_ses-preop_acq-AP_dwi_denoise.mif sub-02_den_preproc.mif -nocleanup -pe_dir AP -rpe_pair -se_epi b0_pair.mif -eddy_options \u0026#34; --slm=linear --data_is_shelled\u0026#34; dwifslpreproc: dwifslpreproc: Note that this script makes use of commands / algorithms that have relevant articles for citation; INCLUDING FROM EXTERNAL SOFTWARE PACKAGES. Please consult the help page (-help option) for more information. dwifslpreproc: dwifslpreproc: Generated scratch directory: /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/dwifslpreproc-tmp-RUWVON/ Command: mrconvert /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/sub-CON02_ses-preop_acq-AP_dwi_denoise.mif /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/dwifslpreproc-tmp-RUWVON/dwi.mif -json_export /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/dwifslpreproc-tmp-RUWVON/dwi.json Command: mrconvert /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/b0_pair.mif /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/dwifslpreproc-tmp-RUWVON/se_epi.mif dwifslpreproc: Changing to scratch directory (/Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/dwifslpreproc-tmp-RUWVON/) dwifslpreproc: Total readout time not provided at command-line; assuming sane default of 0.1 Command: mrinfo dwi.mif -export_grad_mrtrix grad.b Command: mrconvert se_epi.mif topup_in.nii -import_pe_table se_epi_manual_pe_scheme.txt -strides -1,+2,+3,+4 -export_pe_table topup_datain.txt Command: topup --imain=topup_in.nii --datain=topup_datain.txt --out=field --fout=field_map.nii.gz --config=/Applications/fsl/etc/flirtsch/b02b0.cnf --verbose ... 这个命令可能需要几个小时来运行，这取决于你的计算机速度。对于一台拥有8个处理核心的iMac来说，大约需要2个小时。当它完成后，检查输出，看看涡流校正和取消扭曲如何改变了数据；理想情况下，你应该看到在诸如眶额皮层等区域恢复了更多的信号，这些区域特别容易受到信号丢失的影响。\n然后，我们可以使用mrview命令加载原始数据以及经过处理后的数据，对比查看其预处理效果。\n# mrview \u0026lt;经过预处理后数据\u0026gt; -overlay.load \u0026lt;原始数据\u0026gt; $ mrview sub-02_den_preproc.mif -overlay.load sub-CON02_ses-preop_acq-AP_dwi_denoise.mif 检查损坏的切片 dwifslpreproc命令中的一个选项，\u0026quot;-nocleanup\u0026quot;，保留了一个标题为 \u0026ldquo;tmp \u0026ldquo;的目录。在这个目录中，有一个名为dwi_post_eddy.eddy_outlier_map的文件，它包含了0和1的字符串。每一个1代表一个切片是一个离群点，可能是因为运动量太大、涡流或其他原因。\n下面的代码，从dwi目录下运行，将导航到 \u0026ldquo;tmp \u0026ldquo;文件夹，并计算出离群片的百分比： shell dwi_post_eddy.eddy_outlier_map #/bin/bash set -e # 进入dwifslpreproc-tmp-*临时目录 cd dwifslpreproc-tmp-* # 统计slices数量：找到dwi.mif文件的维度(Dimensions: 96 x 96 x 60 x 102)，,并得到第6列值为60，第8列值为102，相乘计算整体的slices数量； totalSlices=`mrinfo dwi.mif | grep Dimensions | awk \u0026#39;{print $6 * $8}\u0026#39;` # 统计离群点的个数：从前到后累加dwi_post_eddy.eddy_outlier_map文件的数值，然后输出； # 注意这里相对原教程新增了NR\u0026gt;1,原因为目前输出dwi_post_eddy.eddy_outlier_map文件的第一行为说明文字，需要去除第一行，避免统计。 totalOutliers=`awk \u0026#39;NR\u0026gt;1{ for(i=1;i\u0026lt;=NF;i++)sum+=$i } END { print sum }\u0026#39; dwi_post_eddy.eddy_outlier_map` # 如果离群点数量超过10，则建议不要使用该数据； echo \u0026#34;If the following number is greater than 10, you may have to discard this subject because of too much motion or corrupted slices\u0026#34; # 计算离群点的百分比比例： 离群点数量/Slices总数）* 100 echo -n \u0026#34;the percentage of outlier slices:\u0026#34; | tee percentageOutliers.txt echo \u0026#34;scale=5; ($totalOutliers / $totalSlices * 100)/1\u0026#34; | bc | tee -a percentageOutliers.txt cd .. One row per scan, one column per slice. Outlier: 1, Non-outlier: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 生成Mask(dwibiascorrect、dwi2mask) 与fMRI分析一样，创建一个掩膜（mask）来限制你的分析只限于大脑体素是很有用的，这将加速我们的分析速度。\n要做到这一点，事先运行一个叫做dwibiascorrect的命令是很有用的。这可以去除数据中检测到的不均匀性(inhomogeneities)，从而获得更好的掩膜估计。然而，在某些情况下，它可能导致更坏的估计；与所有的预处理步骤一样，你应该在每个步骤前后检查它：\n$ dwibiascorrect -h MRtrix 3.0.4 dwibiascorrect dwibiascorrect: part of the MRtrix3 package SYNOPSIS Perform B1 field inhomogeneity correction for a DWI volume series USAGE dwibiascorrect algorithm [ options ] ... algorithm Select the algorithm to be used to complete the script operation; additional details and options become available once an algorithm is nominated. Options are: ants, fsl Options for importing the diffusion gradient table -grad GRAD Provide the diffusion gradient table in MRtrix format -fslgrad bvecs bvals Provide the diffusion gradient table in FSL bvecs/bvals format ... # 使用dwibiascorrect来消除数据中检测到的不均匀性 $ dwibiascorrect ants sub-02_den_preproc.mif sub-02_den_preproc_unbiased.mif -bias bias.mif dwibiascorrect: dwibiascorrect: Note that this script makes use of commands / algorithms that have relevant articles for citation; INCLUDING FROM EXTERNAL SOFTWARE PACKAGES. Please consult the help page (-help option) for more information. dwibiascorrect: dwibiascorrect: Generated scratch directory: /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/dwibiascorrect-tmp-PRRP4X/ Command: mrconvert /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/sub-02_den_preproc.mif /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/dwibiascorrect-tmp-PRRP4X/in.mif dwibiascorrect: Changing to scratch directory (/Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/dwibiascorrect-tmp-PRRP4X/) Command: dwi2mask in.mif mask.mif Command: dwiextract in.mif - -bzero | mrmath - mean mean_bzero.mif -axis 3 Command: mrconvert mean_bzero.mif mean_bzero.nii -strides +1,+2,+3 Command: mrconvert mask.mif mask.nii -strides +1,+2,+3 Command: N4BiasFieldCorrection -d 3 -i mean_bzero.nii -w mask.nii -o [corrected.nii,init_bias.nii] -s 4 -b [100,3] -c [1000,0.0] Command: mrcalc mean_bzero.mif mask.mif -mult - | mrmath - sum - -axis 0 | mrmath - sum - -axis 1 | mrmath - sum - -axis 2 | mrdump - Command: mrcalc corrected.nii mask.mif -mult - | mrmath - sum - -axis 0 | mrmath - sum - -axis 1 | mrmath - sum - -axis 2 | mrdump - Command: mrcalc init_bias.nii 0.7908883751651254 -mult bias.mif Command: mrcalc in.mif bias.mif -div result.mif Command: mrconvert result.mif /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/sub-02_den_preproc_unbiased.mif Command: mrconvert bias.mif /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/bias.mif dwibiascorrect: Changing back to original directory (/Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi) dwibiascorrect: Deleting scratch directory (/Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/dwi/dwibiascorrect-tmp-PRRP4X/) 上面的命令使用了-ants选项，这需要在你的系统上安装ANTs。我推荐这个程序，但万一你无法安装它，你可以用-fsl选项代替它。\n# 如下展示了未安装ants，造成的dwibiascorrect运行报错信息。 ... dwibiascorrect: [ERROR] Could not find ANTS program N4BiasFieldCorrection; please check installation ... 然后，我们就可以使用dwi2mask创建掩膜，这会将把我们的分析限制在我们想位于大脑内的体素。\n$ MRtrix 3.0.4 dwi2mask Dec 14 2022 dwi2mask: part of the MRtrix3 package SYNOPSIS Generates a whole brain mask from a DWI image USAGE dwi2mask [ options ] input output input the input DWI image containing volumes that are both diffusion weighted and b=0 output the output whole-brain mask image DESCRIPTION All diffusion weighted and b=0 volumes are used to obtain a mask that includes both brain tissue and CSF. In a second step peninsula-like extensions, where the peninsula itself is ... $ dwi2mask sub-02_den_preproc_unbiased.mif mask.mif dwi2mask: [100%] preloading data for \u0026#34;sub-02_den_preproc_unbiased.mif\u0026#34; dwi2mask: [done] computing dwi brain mask dwi2mask: [done] applying mask cleaning filter 使用mrview命令查看mask数据\n$ mrview mask.mif MRtrix的dwi2mask命令在大多数情况下工作得很好。然而，你可以从上面的图片中看到，在脑干和小脑内的掩膜上有几个洞。你可能对这些区域不感兴趣，但建议确保掩膜在任何地方都没有洞。\n为此，你可以使用FSL的bet2这样的命令。例如，你可以使用以下代码将无偏的扩散加权图像转换成NIFTI格式，用bet2创建一个掩膜，然后将掩膜转换成.mif格式：\n$ mrconvert sub-02_den_preproc_unbiased.mif sub-02_unbiased.nii # 注意：在实践中，-f指定为0.2达到了最好的掩膜效果，与原教程0.7有所不同。 $ bet2 sub-02_unbiased.nii sub-02_masked -m -f 0.2 # 注意：在nifti转换为mif文件时，可能存在转换数据类型的报警信息 $ mrconvert sub-02_masked_mask.nii.gz mask.mif 你可能必须对分数强度阈值(fractional intensity threshold)（由-f指定）进行试验，以便产生一个你满意的掩膜。根据我的经验，对大多数大脑来说，这个阈值可以在0.2和0.7之间变化，以便生成一个足够的掩膜。 另外，我们可以使用MRIcron软件的Draw \u0026gt; Open VOI功能，去打开nifti格式的掩膜文件，去逐帧修改，确保掩膜文件不存在漏洞。 参考资料 https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Course/MRtrix_04_Preprocessing.html "
},
{
	"uri": "https://LiaoPan.github.io/dipy/tracking_basic/",
	"title": "纤维束追踪入门",
	"tags": [],
	"description": "",
	"content": "Basic Tracking(Local fiber tracking) 本教程知识点：\n如何使用扩散像数据集来实现纤维束重建 1)从扩散数据集获取方向(directions)的方法。 2)识别追踪何时必须停止的方法。 3)设置追踪种子(seed)。 如何保存trk文件 使用StatefulTractogram()和save_trk()函数保存trk文件 局部纤维跟踪(Local fiber tracking)是一种通过从局部方向信息创建流线(streamlines)来模拟白质纤维的方法。其思想如下:如果一个区域/路径段的局部方向是已知的，可以沿着这些方向进行集成，以构建该结构的完整表示。局部纤维束追踪因其简单、鲁棒性好而被广泛应用于扩散MRI领域。\n步骤一. 从扩散数据集获取方向(directions)的方法\n基于 Constant Solid Angle ODF模型来拟合数据，该模型会评估每个voxel的取向分布函数(ODF,Orientation Distribution Function)。OODF 是作为方向函数的水扩散分布。ODF的峰值是图像中某一点上束段(tract segments)方向的良好估计。在这里，我们使用peaks_from_model来拟合数据，并计算白质所有体素中的纤维方向。\n步骤二. 识别追踪何时必须停止的方法\n接下来，我们需要用某种方法将纤维追踪限制在具有良好方向性信息的区域。我们已经创建了白质掩码(white mask)，但我们可以更进一步，通过对广义分数各向异性（GFA,generalized fractional anisotropy）进行阈值处理，将纤维追踪限制在那些ODF显示出明显限制性扩散的区域。\n步骤三. 设置追踪种子(seed)\n在我们开始追踪之前，我们需要指定在哪里 \u0026ldquo;seed\u0026rdquo;（开始）纤维追踪。一般来说，选择的种子将取决于人们感兴趣的建模路径。在这个例子中，我们将在胼胝体的矢状切面上使用一个每个体素的2x2x2的网格种子。从这个区域进行追踪将给我们一个胼胝体束的模型。这个切片在标签的图像中具有标签值2。\n使用EuDX算法构建一个确定性的纤维束流线(streamlines)。 所谓的确定性(deterministic)表示如果你重复纤维跟踪（保持所有输入相同），你将得到完全相同的一组纤维束流线。\nJupyter已省略部分内容，请点击这里全屏显示 使用csdeconv.mask_for_response_ssst()函数来获取每个体素的各向异性配置（very anisotropic configurations）的信息，该函数会返回所选体素的mask。 通过这个mask，我们就可以通过csdeconv.response_from_mask_ssst()函数计算响应函数。\nload_nifti_data()和load_nifti()函数的区别:\nload_nifti_data()只加载nifti内的data array。\nload_nifti()除了加载data array,还要把其他信息也加载进来（data, img.affine, img, vox_size, nib.aff2axcodes(img.affine)）。\n方向场（Direction Field）图如何看？\nx - Red - 方向场图中为红色标识\ny - Green - 方向场图中为绿色标识\nz - Blue- 方向场图中为蓝色标识\n"
},
{
	"uri": "https://LiaoPan.github.io/datasets/",
	"title": "脑相关数据集",
	"tags": [],
	"description": "",
	"content": "数据集 在我们学习相关软件的过程中，官网本身会提供一些用于实践的数据集，这些数据集用来给大家尝试、学习使用。 本文会记录总结常用的相关数据集，供大家方便下载使用，方便后续大家跟着教程一起实践。\nSPM相关数据集下载地址: www.fil.ion.ucl.ac.uk/spm/data/\n简介： 提供在学习SPM教程过程的数据集\nOpeneuro(推荐): openneuro.org\n简介： 提供包括MEG、EEG、PET、MRI、fMRI等模态的开源数据集下载。\nOpenfmri: openfmri.org\n简介： 提供fMRI的开源数据集下载。\nDIPY: dipy.org\n简介： 提供纤维束相关的开源数据集下载。\n"
},
{
	"uri": "https://LiaoPan.github.io/freesurfer/basic/",
	"title": "FreeSurfer教程 #2. FreeSurfer输出结果与FreeView可视化",
	"tags": [],
	"description": "",
	"content": " 0. 本文知识点汇总 1. 教程数据准备 FreeSurfer 的输出结果 使用FreeView来图片查看Volumes 使用FreeView来3D查看Surfaces 参考资料 0. 本文知识点汇总 FreeSurfer输出结果的简单理解 使用FreeView对FreeSurfer的结果（Volumes、Surfaces）进行可视化查看 1. 教程数据准备 在FsTutorial_Data下载相关教程的测试数据，大概8GB。\n使用命令行下载相关教程数据，也可以直接访问网址下载，然后解压。\ncurl https://surfer.nmr.mgh.harvard.edu/pub/data/tutorial_data.tar.gz -o tutorial_data.tar.gz tar -xzvf tutorial_data.tar.gz rm tutorial_data.tar.gz export TUTORIAL_DATA=/path/to/your/tutorial/dir # 定义环境变量TUTORIAL_DATA ls $TUTORIAL_DATA buckner_data fsfast-functional diffusion_recons fsfast-tutorial.subjects diffusion_tutorial long-tutorial FreeSurfer 的输出结果 surf 文件夹下生成 . white、. sphere、. inflated 等网格点文件，每一个文件里面都存储了大脑皮质表面网格点的三维坐标及相邻顶点构成的三角面片信息。\nsurf 文件夹下生成基于曲面的形态特征数据，不同的特征采用不同的文件后缀名，\n皮质厚度（ . thickness ） 雅可比度量（. jacobian. white） 脑沟（ . sulc ） 曲率（. curv） 外表面积（. area） 体积（. volume）等面数据文件，其坐标索引号与 Mesh 网格序号一致。 **stats **文件夹下，对于每个脑图谱(atlas)都有一个分区结果(parcellations)。比如，\nlh.aparc.annot，使用Desikan-Killiany图谱的左半球的分区结果；\nlh.aparc.a2009s.annot,使用Destrieux图谱的左半球分区结果；\naseg.stats包含了所有图谱的分割结果。如果想知道怎么提取这些信息，请跳转。\nDesikan-Killiany图谱与Destrieux图谱的区别在于，Destrieux图谱包含更多的分区，可以适用于更加精细化的分析。 使用FreeView来图片查看Volumes freeview -v \\ good_output/mri/T1.mgz \\ good_output/mri/wm.mgz \\ good_output/mri/brainmask.mgz \\ good_output/mri/aseg.mgz:colormap=lut:opacity=0.2 \\ -f good_output/surf/lh.white:edgecolor=blue \\ good_output/surf/lh.pial:edgecolor=red \\ good_output/surf/rh.white:edgecolor=blue \\ good_output/surf/rh.pial:edgecolor=red -v 用于加载volumes; -f 用于加载surfaces; 更多详细了解，请参考官网教程\n使用FreeView来3D查看Surfaces 下述Surfaces都可以使用FreeView进行查看。\npial(软膜), white(白质) and inflated surface(膨胀表面) sulcal(脑沟) and curvature maps(曲率图) thickness maps(厚度图) cortical parcellation(皮质分割) freeview -f good_output/surf/lh.pial:annot=aparc.annot:name=pial_aparc:visible=0 \\ good_output/surf/lh.pial:annot=aparc.a2009s.annot:name=pial_aparc_des:visible=0 \\ good_output/surf/lh.inflated:overlay=lh.thickness:overlay_threshold=0.1,3::name=inflated_thickness:visible=0 \\ good_output/surf/lh.inflated:visible=0 \\ good_output/surf/lh.white:visible=0 \\ good_output/surf/lh.pial \\ --viewport 3d 参数以:+\u0026lt;cmd\u0026gt;=进行间隔区分,比如:annot=、:name=、:overlay=、:overlay_threshold=；\nlh.pial:annot=aparc.annot表示在pial表面上加载Desikan-Killiany皮质分区； lh.pial:annot=aparc.a2009s.annot表示在pial表面加载Destrieux皮质分区； :name=pial_aparc:visible=0 表示更改显示名称并关闭该层显示； lh.inflated:overlay=lh.thickness:overlay_threshold=0.1,3表示加载膨胀表面顶部的厚度叠加层并设置要显示的最小和最大阈值；\n绿色区域是脑回，红色区域是脑沟 上图为Desikan-Killiany Cortical Parcellation 上图为Destrieux Cortical Parcellation 上述皮质分割可通过recon-all来生成，对应命令为： ?h.aparc.annot:\nDesikan-Killiany atlas ?h.aparc.a2009s.annot:\nDestrieux atlas FreeView的简单使用方法，不需要每次在终端命令行输入命令来指定打开什么文件以及展示属性，而是仅输入freeview打开UI界面，点击操作即可，方便又快捷！\n更多细节参考和练习，请访问FreeviewGuide\nFreeSurfer 采用的是 RAS 坐标系，其意义为 R：right，X 轴正方向；A：anterior，Y 轴正方向；S：superior，Z 轴正方向。\n参考资料 官网 Freesurfer源码 官网使用手册 中文使用手册 FreeSurfer官网教程 FreeSurfer Ouputs "
},
{
	"uri": "https://LiaoPan.github.io/dipy/",
	"title": "DIPY系列教程",
	"tags": [],
	"description": "",
	"content": "DIPY简介 DIPY是Python中标准的3D/4D成像库，包含空间归一化、信号处理、机器学习、统计分析和医学图像可视化的通用方法。此外，它还包含计算解剖学的专门方法，包括扩散、灌注和结构成像。\nDIPY功能 命令行接口 所有算法都可以使用命令行的方式调用 创建自己的命令行 统计分析 BUAN AFQ K折交叉验证 重构 Single Shell:DTI, CSA, SFM, SDT, Q-Ball, CSD, \u0026hellip; Multi-Shell:GQI, DTI, DKI, SHORE, MAPMRI, MSMT-CSD, \u0026hellip; 配准 仿射变换 2D/3D微分同胚配准（Diffeomorphic 2D/3D Registration） 纤维束成像 概率性纤维束追踪 确定性纤维束追踪 PFT纤维束追踪 去噪 Patch2self Gibbs Unringing LPCA - MPPCA Non Local Means 可视化 ODFs可视化 交互式的纤维束可视化 预处理 Brain extraction SNR estimation Reslice Datasets 安装方式 $ pip install nibabel # 用于读写神经影像数据 $ pip install dipy $ pip install fury # 某些可视化依赖库 当然，也可以使用conda方式进行安装。\n更多安装教程，请参考官网\n如果看到这不知道什么是pip或者conda，可以去学习一下python相关基础。\n教程数据下载 使用python代码下载，数据集默认会下载在主目录下的.dipy目录内。 Jupyter已省略部分内容，请点击这里全屏显示 尽量不要使用jupyter来执行上述命令下载数据，因为目前jupyter的下载进度支持不好，无法查看下载是否已完成且容易僵住。\n使用命令行工具下载,选择特定目录，执行下面命令即可(推荐) $ dipy_fetch list # 查看所有可使用的数据集 INFO:Please, select between the following data names: bundle_atlas_hcp842, bundle_fa_hcp, bundles_2_subjects, cenir_multib, cfin_multib, file_formats, fury_surface, gold_standard_io, isbi2013_2shell, ivim, mni_template, qtdMRI_test_retest_2subjects, qte_lte_pte, resdnn_weights, scil_b0, sherbrooke_3shell, stanford_hardi, stanford_labels, stanford_pve_maps, stanford_t1, syn_data, taiwan_ntu_dsi, target_tractogram_hcp, tissue_data $ dipy_fetch {specific_dataset} --out_dir {specific_data_out_folder} # 选择特定数据集，下载到特定目录，注意{}内内容需要替换。 $ dipy_fetch sherbrooke_3shell --out_dir . # 举例，将sherbrooke_3shell数据集下载到当前目录。 使用dipy_fetch时，\u0026ndash;out_dir不写，即下载到默认目录下(~/.dipy)\n注意 1: 不需要马上下载上述所有数据集，在后续教程中，会陆续使用命令下载教程相关数据。 注意 2: 在下载过程中，经常会碰到报500错误(HTTP Error 500: Internal Server Error)的情况，重新开始即可。\n"
},
{
	"uri": "https://LiaoPan.github.io/mrtrix/",
	"title": "MRtrix3系列教程",
	"tags": [],
	"description": "",
	"content": " 简介 下载安装 校验是否安装成功 简介 MRtrix3提供了一套工具来进行各种类型的弥散MRI分析，从各种形式的纤维束成像到下一代的组水平分析。它的设计考虑到了一致性、性能和稳定性，并以开源许可的方式免费提供。它是由该领域的专家团队开发和维护的，培养了一个由不同背景的用户组成的活跃社区。\n与主要图像格式无缝交互 FOD-based（Fiber Orientation Distributions，FOD） DEC maps and panchromatic sharpening 下载安装 访问MRtrix的下载地址,选择不同平台进行安装即可。\nmacOS Linux sudo bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/MRtrix3/macos-installer/master/install)\u0026#34; 该脚本会自动下载MRtrix3软件的最新的二进制发布版本，解压到/usr/local/mrtrix3目录下。\n$ conda install -c mrtrix3 mrtrix3 前提，需要先安装anaconda (or miniconda)。\n如果碰到macOS安装时，无法正常下载install脚本，可以通过网页访问raw.githubusercontent.com/MRtrix3/macos-installer/master/install，然后自己创建文件进行安装。下面是我安装时的install脚本内容。\n#!/bin/bash -e tag=$(basename $(/usr/bin/curl -Ls -o /dev/null -w %{url_effective} https://github.com/MRtrix3/mrtrix3/releases/latest)) if [ -z \u0026#34;${tag}\u0026#34; ]; then echo \u0026#34;ERROR: could not find tag name for latest release ...\u0026#34; exit fi if [ \u0026#34;$1\u0026#34; != \u0026#34;-f\u0026#34; ]; then echo \u0026#34;This installer will download MRtrix ${tag} and install it to /usr/local/mrtrix3.\u0026#34; echo \u0026#34;In addition it will:\u0026#34; echo \u0026#34;* create symbolic links in /usr/local/bin to the binaries in /usr/local/mrtrix3/bin\u0026#34; echo \u0026#34;* create symbolic links in /Applications to the app bundles in /usr/local/mrtrix3/bin\u0026#34; fi if [ $EUID != 0 ]; then echo \u0026#34;ERROR: This script requires root privileges, please run as: sudo \u0026#34;$0\u0026#34; \u0026#34;$@\u0026#34;\u0026#34; exit fi if [ -d \u0026#34;/usr/local/mrtrix3\u0026#34; ] || [ -L \u0026#34;/usr/local/mrtrix3\u0026#34; ] ; then echo \u0026#34;WARNING: /usr/local/mrtrix3 already exists and will be replaced during installation.\u0026#34; fi if [ \u0026#34;$1\u0026#34; != \u0026#34;-f\u0026#34; ]; then while true; do read -p \u0026#34;Are you sure you want to continue? [y/n] \u0026#34; yn case $yn in [Yy]* ) break;; [Nn]* ) exit;; esac done fi if [ ! -d \u0026#34;/usr/local/bin\u0026#34; ]; then if [ -e \u0026#34;/usr/local/bin\u0026#34; ]; then echo \u0026#34;WARNING: /usr/local/bin is not a directory, cannot create symlinks\u0026#34; else echo \u0026#34;WARNING: /usr/local/bin does not exist, creating it for you.\u0026#34; mkdir -p -m 755 /usr/local/bin fi fi url=https://github.com/MRtrix3/mrtrix3/releases/download/${tag}/mrtrix3-macos-${tag}.tar.gz if [ -z \u0026#34;${url}\u0026#34; ]; then echo \u0026#34;ERROR: Could not find tarball of latest release ...\u0026#34; exit fi echo \u0026#34;Downloading \u0026#34;${url}\u0026#34; ...\u0026#34; /usr/bin/curl -sL \u0026#34;${url}\u0026#34; -O tarball=$(basename \u0026#34;${url}\u0026#34;) if [ ! -f \u0026#34;${tarball}\u0026#34; ]; then echo \u0026#34;ERROR: Download not sucessful ...\u0026#34; exit fi if [ -f /usr/local/mrtrix3/symlinks ]; then echo \u0026#34;Removing symbolic links of previous installation ...\u0026#34; for l in $(cat /usr/local/mrtrix3/symlinks); do if [ -L \u0026#34;${l}\u0026#34; ]; then unlink \u0026#34;${l}\u0026#34; fi done fi if [ -d \u0026#34;/usr/local/mrtrix3\u0026#34; ] || [ -L \u0026#34;/usr/local/mrtrix3\u0026#34; ] ; then echo \u0026#34;Removing previous installation in /usr/local/mrtrix3 ...\u0026#34; rm -rf \u0026#34;/usr/local/mrtrix3\u0026#34; fi for l in /usr/local/bin/*; do if [ -L \u0026#34;${l}\u0026#34; ]; then t=\u0026#34;$(readlink \u0026#34;${l}\u0026#34;)\u0026#34; if [[ \u0026#34;${t}\u0026#34; == *\u0026#34;mrtrix3\u0026#34;* ]]; then echo \u0026#34;WARNING: Removing symbolic link \u0026#34;${l}\u0026#34; to \u0026#34;${t}\u0026#34; (conflicting homebrew installation?) ...\u0026#34; unlink \u0026#34;${l}\u0026#34; fi fi done echo \u0026#34;Unpacking \u0026#34;${tarball}\u0026#34; to /usr/local/mrtrix3 ...\u0026#34; tar oxf \u0026#34;${tarball}\u0026#34; -C /usr/local rm \u0026#34;${tarball}\u0026#34; echo \u0026#34;Fixing python shebang ...\u0026#34; cd /usr/local/mrtrix3/bin for f in $(grep -lr \u0026#39;^#!/usr/bin/env python\u0026#39;); do sed -i \u0026#39;\u0026#39; \u0026#39;s|^#!/usr/bin/env python$|#!/usr/bin/python3|\u0026#39; ${f} done echo \u0026#34;Applying patch to show correct version numbers in scripts ...\u0026#34; cd /usr/local/mrtrix3 curl -s https://github.com/MRtrix3/mrtrix3/commit/4a293d30e1c0686037ae637f67932d497eb71ee6.patch | patch -s -p1 echo \u0026#34;Creating symlinks in /usr/local/bin ...\u0026#34; cd /usr/local/bin touch /usr/local/mrtrix3/symlinks for target in $(find ../mrtrix3/bin -maxdepth 1 -type f ! -name \u0026#34;*.*\u0026#34;); do ln -sf \u0026#34;${target}\u0026#34; echo /usr/local/bin/\u0026#34;$(basename \u0026#34;${target}\u0026#34;)\u0026#34; \u0026gt;\u0026gt; /usr/local/mrtrix3/symlinks done echo \u0026#34;Creating symlinks in /Applications ...\u0026#34; cd /Applications for target in /usr/local/mrtrix3/bin/*.app; do ln -sf \u0026#34;${target}\u0026#34; echo /Applications/\u0026#34;$(basename \u0026#34;${target}\u0026#34;)\u0026#34; \u0026gt;\u0026gt; /usr/local/mrtrix3/symlinks done if [[ $SHELL = \u0026#34;/bin/zsh\u0026#34; ]]; then profile=~/.zprofile; else profile=~/.bash_profile; fi echo \u0026#34;$PATH\u0026#34; | grep -q \u0026#39;/usr/local/bin:\u0026#39; || printf \u0026#34;WARNING: /usr/local/bin is not in PATH. You can add it to the PATH with:\\necho \u0026#39;export PATH=/usr/local/bin:\\$PATH\u0026#39; \u0026gt;\u0026gt; ${profile}\\n\u0026#34; echo \u0026#34;Installation complete!\u0026#34; $ touch install #创建脚本文件，然后粘贴上述脚本内容。 $ chmod +x install $ sudo ./install # 执行安装,若因为github的原因导致无法下载，建议在terminal内配置github代理，或者手动下载软件包，修改install脚本,让其读取本地已下载的软件包安装即可。 校验是否安装成功 新起一个terminal，随意选择MRtrix的命令，输入部分命令，比如dwi2,然后按tab键，输入dwi2mask -h,如果可以正常显示命令,那么就应该安装成功了。\n$ dwi2mask -h dwi2mask: part of the MRtrix3 package SYNOPSIS Generates a whole brain mask from a DWI image USAGE dwi2mask [ options ] input output input the input DWI image containing volumes that are both diffusion weighted and b=0 output the output whole-brain mask image DESCRIPTION All diffusion weighted and b=0 volumes are used to obtain a mask that includes both brain tissue and CSF. 官网地址 - GitHub源码地址 - MRtrix官网文档地址\n"
},
{
	"uri": "https://LiaoPan.github.io/fsl/statistics_analysis/",
	"title": "FSL系列教程 #3. 统计与建模 ",
	"tags": [],
	"description": "",
	"content": " 简介 第一级分析(First Level Analysis) 1.时间序列(Time-Series) 2.BOLD（血氧水平依赖，Blood Oxygen Level Dependent）信号发展历史 3.血流动力学反应函数(HRF,Hemodynamic Response Function) 4.广义线性模型(General Linear Model) 5.创建Timing Files 6.第一级分析(First-Level Analysis)操作实践 第二级分析，2nd-Level Analysis 第三级分析，3nd-Level Analysis 参考资料 简介 现在，经过预处理后，我们可以对数据进行模型拟合。为了理解模型拟合的原理，我们需要回顾一些基本原理，如一般线性模型（GLM）、BOLD反应和什么是时间序列。这些主题在下面章节中都有讨论。\n在你回顾了这些概念之后，你就可以使用FEAT进行一级分析了。下图说明了我们将如何对数据进行模型拟合。\n在构建了一个表明BOLD反应应该是什么样子的模型（A）后，该模型被拟合到每个体素的时间序列上（B）。模型的拟合程度（也称为拟合度）可以用统计图在大脑上表示出来，强度越高表示模型拟合度越高。然后，这些统计图可以被阈值化，只显示具有统计学意义的模型拟合的体素（C）。 第一级分析(First Level Analysis) 1.时间序列(Time-Series) 为了理解模型拟合的工作原理，首先我们需要回顾一下fMRI数据的构成。请记住，fMRI数据集包含几个volumes，像串珠子一样串在一起\u0026ndash;我们把这串volumes的串联称为数据run。在整个run过程中，在每个体素测量的信号被称为时间序列。\n在SPM中，一个run被称为一个session。有些术语在不同的分析包中没有标准化。在本课程中将继续使用上述run的定义。\n为了说明这看起来像什么，打开fsleyes浏览器，加载数据集filtered_func_data.nii.gz。在右下角有一个标记为 \u0026ldquo;Location\u0026quot;的窗口，有一个名为 \u0026ldquo;Volume\u0026quot;的字段。这表明在观察窗口中显示的时间序列的当前volume。点击该字段旁边的向上箭头，显示时间序列中的下一卷，注意从一卷到下一卷有微小但明显的变化。\n要看到时间序列以更快的速度连续更新，请点击电影卷轴模样的图标\u0026quot;Movie Reel\u0026quot;。可以通过点击扳手图标(\u0026ldquo;Wrench\u0026rdquo;)来改变更新速度。\n然后，点击屏幕上方的View菜单，选择时间序列（Time series）。这就打开了另一个窗口，显示整个时间序列的信号变化，X轴上是volume序号。y轴是扫描仪以任意单位来衡量采集的fMRI信号；在对每个扫描进行归一化处理后，我们可以解释这些单位，并在不同条件下比较归一化信号。\n时间序列代表了在每个体素上测量的信号，但这个信号来自哪里？在下一节，我们将简要回顾fMRI的历史，以及我们如何产生你在viewer中看到的信号。\n2.BOLD（血氧水平依赖，Blood Oxygen Level Dependent）信号发展历史 在整个20世纪80年代和90年代初，神经影像学研究人员将使用正电子发射断层扫描（PET）等方法测量大脑组织之间的对比度。这涉及到注射一种放射性的葡萄糖示踪剂(radioactive glucose tracer)，当神经元发射时被其吸收。通过在不同的实验条件下拍摄大脑图像，如看到一个闪烁的棋盘或做一个认知要求高的问题，研究人员可以看到哪些区域与其他区域相比更活跃。\n然而，这种方法是侵入性的，而且被注射放射性示踪剂的想法使许多人不敢成为这种实验的对象。到20世纪90年代初，一种被称为磁共振成像（MRI）的替代成像技术已经变得更快、更便宜，研究人员正在寻找一种方法，使其更广泛地用于临床。1990年，贝尔实验室的一位名叫Seiji Ogawa的研究人员发现，更多的脱氧血液会导致从一个大脑区域测得的信号减少。而另一方面，含氧血液的增加会增加信号\u0026ndash;这种含氧血液的增加后来被证明与神经发射的增加相关联。这种信号的变化被称为血氧水平依赖信号（或BOLD信号）。\n此后不久，在1992年，马萨诸塞州总医院(Massachusetts General Hospital)一位名叫Ken Kwong的研究人员证明，BOLD信号可被用作神经活动的间接测量。他的实验包括向受试者交替显示一个闪烁的棋盘和一个黑屏，每次一分钟。在每个条件下都记录了BOLD信号，如以下视频所示： 这个是一个重要的实验，成为许多功能神经成像实验的模板。Kwong找到了一种方法，利用体内的血液作为内源性示踪剂，对健康受试者的大脑活动进行成像，消除了对注射或辐射的需要。因此，fMRI实验变得更加流行，到2000年代初，fMRI已成为主流的神经影像学方法。\nBOLD信号作为神经发射的间接测量方法 尽管Ogawa和Kwong的发现对使用MRI的神经成像者来说是一个福音，但也有一个问题：这种新方法是对大脑活动的间接测量，与实际的神经发射相差了几步。每当有刺激出现时\u0026ndash;如闪光或突然的噪音\u0026ndash;该刺激被感觉器官转化为神经冲动，反过来刺激大脑中的神经元发射。发射的神经元需要氧气，而氧气是由血液输送的。这种含氧的血液反过来又增加了来自附近的氢气在你体内的信号，这就是扫描仪中所测量的。\n尽管如此，这也是用来推断大脑某一区域是否 \u0026ldquo;活跃 \u0026ldquo;的措施。而要做出这些推断，我们将需要仔细研究BOLD信号、实验设计，以及我们如何将两者与数学模型结合起来。\n3.血流动力学反应函数(HRF,Hemodynamic Response Function) 从BOLD反应到HRF 在上一小节中，我们读到了关于BOLD信号代表什么的一些假设；我们的另一个假设是BOLD反应是什么样子。这不仅对建立神经活动和血流之间的联系、从那里到观察信号的建模很重要，而且对我们如何定义一个模型来测试哪些脑区对给定刺激的BOLD反应有明显变化也很重要。\n在20世纪90年代，对BOLD信号的实证研究表明，在向受试者呈现一个刺激后，大脑的任何部分对该刺激有反应\u0026ndash;例如，视觉皮层对一个视觉刺激的反应\u0026ndash;显示出BOLD信号的增加。BOLD信号似乎也遵循一个一致的形状，在6秒左右达到峰值，然后在接下来的几秒钟内回落到基线。这种形状可以用一个叫做伽马分布（Gamma Distribution）的数学函数来模拟。当伽马分布被创建为最适合大多数经验研究观察到的BOLD反应的参数时，我们把它称为典型的血液动力学反应函数，或HRF。\n当应用于fMRI数据时，伽马分布被称为基础函数(baiss function)。我们称它为基础函数，因为它是我们将创建的模型的基本元素，或基础，并适合于数据的时间序列。此外，如果我们知道分布的形状在应对非常短暂的刺激时是什么样的，我们就可以预测它在应对不同持续时间的刺激时应该是什么样的，以及任何随时间呈现的刺激组合。现在我们来看看每种情况的说明。\n单一脉冲刺激的HRF 如果一个刺激的持续时间很短，如弹指一挥间，我们可以说它是一个脉冲刺激\u0026ndash;换句话说，它没有持续时间。正如你在下图中看到的，BOLD信号的形状看起来像一个典型的伽马分布，其峰值接近时间轴的起点（即X轴），并有一个长尾巴向右。 由单一脉冲刺激产生的HRF。在这个图中，刺激发生在X轴上的时间点0。 单个矩形刺激(boxcar stimulus)的HRF 尽管许多研究使用的刺激物只持续一秒钟或更短，但有些研究提出的刺激物持续时间更长。例如，想象一下，受试者看一个闪烁的棋盘15秒的时间。在这种情况下，HRF的形状将更加分散，其持续的峰值与刺激的持续时间成正比，只有在刺激结束后才回落到基线。这种刺激被称为矩形刺激(boxcar stimulus)，因为它看起来像火车上的箱车的形状。\n在这种情况下，伽马分布与矩形刺激进行卷积。卷积是两个函数在时间上的平均化；因此，当Gamma分布与矩形刺激平均化时，它就会扩大，而当刺激被移除时，它就会回到基线。\n在单脉冲情况下，Gamma分布也是与一个刺激进行卷积的。由于脉冲刺激是无限小的，它在时间轴上被表示为一条垂直线。这就是为什么它有时被称为棒状函数(stick function)。\n)\n由持续15秒的矩形刺激产生的HRF图示。请注意，BOLD信号在15秒左右开始下降到基线。 如果HRFs重叠了怎么办？ 我们已经看到了一个刺激呈现后的BOLD信号是什么样子，以及HRF是如何模拟该信号的形状的。但是，如果在前一个刺激的BOLD反应恢复到基线之前，又出现了另一个刺激，会发生什么？\n在这种情况下，各个HRFs被加在一起。这就产生了一个BOLD反应，它是单个HRFs的移动平均值，当更多的刺激接近时，BOLD信号的形状变得更加复杂。\n单个刺激的HRFs的卷积。整体的BOLD反应（蓝色）是用黑色、红色和绿色勾勒的单个HRFs的移动平均值。X轴上的垂直黑线代表脉冲刺激。图由AFNI的Bob Cox制作。 每个案例的动画 为了帮助理解刚刚阅读的内容，请多看几次下面的动画。它将显示上述每个案例是如何随着时间的推移而展开的，这将有助于我们的理解。\n动画最初由AFNI的Bob Cox制作。 练习 1.在本章中，术语 \u0026ldquo;血流动力学反应函数，HRF \u0026ldquo;和 \u0026ldquo;BOLD信号 \u0026ldquo;被用来代表类似但不同的概念。你将如何用你自己的话来定义这些术语？\n刚刚学到的概念可能比在本课程中以前学过的更难理解。即使觉得自己没有完全理解HRF和卷积，也要继续学习本模块的其他内容。在你读完其余章节并做完实际练习后，再来看看本章，然后看看是否有了新的理解和收获。\n4.广义线性模型(General Linear Model) 本章是对广义线性模型（GLM）的简要介绍，以及如何将其应用于fMRI数据。\n现在我们来看看广义线性模型，或称GLM。通过广义线性模型，我们可以使用一个或多个回归因子（regressors），或自变量（independent variables），将一个模型拟合到一些结果测量，或因变量(dependent variable)。要做到这一点，我们要计算称为β权重的数值，这是分配给每个回归因子的相对权重，用以最好的拟合数据。模型和数据之间的任何差异被称为残差（residuals）。\n代表这些术语的符号显示在下面的方程式中，可以根据模型中的回归因子数量缩短或扩大。 让我们看看如何将其应用于一个简单的例子。想象一下，我们想根据身高(Height)、智商(IQ)和每周喝酒的次数(Drinks per week)来预测GPA。我们可能会发现，智商与GPA有正相关，饮酒次数有负相关，而身高则完全没有相关；我们给这些回归因子分配β权重以最适合数据。例如，也许每增加一个IQ点就会使GPA增加0.05，而每周每增加一杯饮料就会使GPA减少0.07。在这种情况下，我们的模型和它的β权重会是这样的（其中星号代表β权重是有统计学意义的，或者不可能仅仅因为偶然而与结果测量相关）：\n这个GLM可以扩展到包括更多回归因子，但无论有多少回归因子，GLM都假设数据可以被建模为回归因子的线性组合\u0026ndash;因此被称为广义线性模型，GLM。我们将在下一节中看到如何将GLM应用于fMRI数据。\n5.创建Timing Files 理想时间序列和拟合时间序列 我们刚刚看到如何使用几个回归因子，或自变量，来估计一个结果测量，如GPA。从概念上讲，当我们使用几个回归因子来估计大脑活动时，我们也在做同样的事情，大脑活动是我们用fMRI数据衡量的结果：我们估计BOLD信号的平均振幅，以响应我们模型中的每个条件。\n在下面的动画中，BOLD反应的不同颜色代表不同的条件（如Congruent和Incongruent），灰线代表我们预处理数据的timecourse。这表明每个条件的振幅是如何被估计为最适合数据的；对于左边的条件，它相对较高，而对于右边的条件，它相对较低。也可以想象一个条件的BOLD信号与零没有显著差异，甚至是负数。\n代表HRFs的红线和绿线被称为理想时间序列（ideal time-series）。这是我们期望的时间序列，鉴于我们实验中每个刺激的时间。当我们估计β权重来拟合这个理想时间序列的数据时，其结果被称为拟合时间序列(fitted time-series)，在动画中显示为一条蓝线。\n由于每个体素都有自己的时间序列，我们对大脑中的每个体素进行上述程序。这被称为大规模单变量分析，因为我们为每个体素的时间序列估计β权重。由于在一个典型的fMRI数据集中有几万或几十万个体素，以后我们需要对我们所做的所有测试进行校正。这将在后面关于组分析的一章中涉及。\n创建理想的时间序列 我们的目标是创建拟合时间序列，这样我们就可以在组分析中使用估计的β权重。但是要做到这一点，我们首先需要创建我们理想时间序列。\n让我们看一下Flanker数据集。在每个被试的func目录下都有标记为events.tsv的文件。这些文件包含三个信息，我们需要这些信息来创建我们的计时文件(timing files)（也称为onset files）：\n条件的名称； 条件的每次试验发生的时间，以秒为单位，相对于扫描的开始时间； 每次试验的持续时间。 这些需要从events.tsv文件中提取出来，并以FSL软件可以读取的方式进行格式整理。在这种情况下，我们将为每个条件创建一个timing文件，然后根据条件的运行情况来分割该文件。那么，我们总共将创建四个timing文件：\n在第一次run中发生的不一致试验的计时（我们将称之为incongruent_run1.txt）； 第二次run中出现的不一致试验的时间（incongruent_run2.txt）； 第一次run时发生的一致性试验（Congruent trials）的时间（congruent_run1.txt）； 在第二次run中发生的一致性试验（Congruent trials）的时间（congruent_run2.txt）。 每个计时文件都有相同的格式，由三栏组成，顺序如下：\n开始时间，以秒为单位，相对于扫描的开始时间； 试验的持续时间，以秒计； 参量调制（Parameter modulation）。 我们将在未来的模块中讨论参数调制。现在，我们需要知道的是，这是一个必要的列，除非你有参数调制的试验（在这个Flanker数据集中没有），否则就把它设置为每个试验的值为 \u0026ldquo;1\u0026rdquo;。\nOpenNeuro.org上的Run-1_events.tsv文件（A）。当我们下载它并在终端中查看时，它看起来像窗口中的文本（B）。我们的目标是重新格式化这个events文件，创建一个有三列的计时文件：开始时间、持续时间和参量调制（C）。 要想自动格式化计时文件，请下载这个脚本。(1. 你可以通过点击Raw按钮下载，然后在新打开的窗口中点击右键，选择 \u0026ldquo;另存为\u0026rdquo;;2. 下述有完整的该make_FSL_Timings.sh脚本，直接粘贴使用即可。）。我们不会详细介绍它是如何工作的，但你所需要做的就是把它放在包含受试者的实验文件夹里，然后输入bash make_FSL_Timings.sh。这将为每个受试者的每次运行创建计时文件。要检查输出，输入cat sub-08/func/incongruent_run1.txt。你应该看到与上图类似的数字。\nsub-01_task-flanker_run-1_events.tsv incongruent_run1.txt make_FSL_Timings.sh onset duration trial_type response_time correctness StimVar Rsponse Stimulus cond 0 2 incongruent_correct 1.095 correct 2 1 incongruent cond003 10 2 incongruent_correct 0.988 correct 2 1 incongruent cond003 20 2 congruent_correct 0.591 correct 1 1 congruent cond001 30 2 congruent_correct 0.499 correct 1 1 congruent cond001 40 2 incongruent_correct 0.719 correct 2 1 incongruent cond003 52 2 congruent_correct 0.544 correct 1 1 congruent cond001 64 2 congruent_correct 0.436 correct 1 1 congruent cond001 76 2 incongruent_correct 0.47 correct 2 1 incongruent cond003 88 2 congruent_correct 0.409 correct 1 1 congruent cond001 102 2 incongruent_correct 0.563 correct 2 1 incongruent cond003 116 2 congruent_correct 0.493 correct 1 1 congruent cond001 130 2 congruent_correct 0.398 correct 1 1 congruent cond001 140 2 congruent_correct 0.466 correct 1 1 congruent cond001 150 2 incongruent_correct 0.518 correct 2 1 incongruent cond003 164 2 incongruent_correct 0.56 correct 2 1 incongruent cond003 174 2 incongruent_correct 0.533 correct 2 1 incongruent cond003 184 2 congruent_correct 0.439 correct 1 1 congruent cond001 196 2 congruent_correct 0.458 correct 1 1 congruent cond001 208 2 incongruent_correct 0.734 correct 2 1 incongruent cond003 220 2 incongruent_correct 0.479 correct 2 1 incongruent cond003 232 2 incongruent_correct 0.538 correct 2 1 incongruent cond003 246 2 congruent_correct 0.54 correct 1 1 congruent cond001 260 2 incongruent_correct 0.622 correct 2 1 incongruent cond003 274 2 congruent_correct 0.488 correct 1 1 congruent cond001 0\t2 1 10\t2 1 10\t2 1 40 2 1 76 2 1 150 2 1 164 2 1 174 2 1 208 2 1 220 2 1 232 2 1 260 2 1 #!/bin/bash #Check whether the file subjList.txt exists; if not, create it if [ ! -f subjList.txt ]; then ls -d sub-?? \u0026gt; subjList.txt fi #Loop over all subjects and format timing files into FSL format for subj in `cat subjList.txt` ; do cd $subj/func #Navigate to the subject\u0026#39;s func directory, which contains the timing files #Extract the onset times for the incongruent and congruent trials for each run. NOTE: This script only extracts the trials in which the subject made a correct response. Accuracy is nearly 100% for all subjects, but as an exercise the student can modify this to extract the incorrect trials as well. cat ${subj}_task-flanker_run-1_events.tsv | awk \u0026#39;{if ($3==\u0026#34;incongruent_correct\u0026#34;) {print $1, $2, \u0026#34;1\u0026#34;}}\u0026#39; \u0026gt; incongruent_run1.txt cat ${subj}_task-flanker_run-1_events.tsv | awk \u0026#39;{if ($3==\u0026#34;congruent_correct\u0026#34;) {print $1, $2, \u0026#34;1\u0026#34;}}\u0026#39; \u0026gt; congruent_run1.txt cat ${subj}_task-flanker_run-2_events.tsv | awk \u0026#39;{if ($3==\u0026#34;incongruent_correct\u0026#34;) {print $1, $2, \u0026#34;1\u0026#34;}}\u0026#39; \u0026gt; incongruent_run2.txt cat ${subj}_task-flanker_run-2_events.tsv | awk \u0026#39;{if ($3==\u0026#34;congruent_correct\u0026#34;) {print $1, $2, \u0026#34;1\u0026#34;}}\u0026#39; \u0026gt; congruent_run2.txt cd ../.. done 上述脚本是匹配生成所有被试的timing files，当然我们可以选择一个指定的events.tsv文件来生成，主要还是借鉴上述代码,其中$3表示第3列（trial_type），如果匹配上了对应的关键词，比如\u0026quot;incongruent_correct\u0026quot;，那么我们就输出其$1和$2,即分别为第1列（onset）和第2列（duration）：\n# cat \u0026lt;your_events.tsv\u0026gt; |awk \u0026#39;{if ($3==\u0026#34;incongruent_correct\u0026#34;){print $1,$2,\u0026#34;1\u0026#34;}}\u0026#39; $ cat sub-01_task-flanker_run-1_events.tsv |awk \u0026#39;{if ($3==\u0026#34;incongruent_correct\u0026#34;){print $1,$2,\u0026#34;1\u0026#34;}}\u0026#39; 0.0 2.0 1 10.0 2.0 1 40.0 2.0 1 76.0 2.0 1 102.0 2.0 1 150.0 2.0 1 164.0 2.0 1 174.0 2.0 1 208.0 2.0 1 220.0 2.0 1 232.0 2.0 1 260.0 2.0 1 一旦我们创建了计时文件，我们就可以用它们来为fMRI数据拟合一个模型。\n6.第一级分析(First-Level Analysis)操作实践 统计数据标签，Stats 导航到sub-08目录，在命令行中输入fsl。打开FEAT图形用户界面，在数据标签右上方的下拉菜单中，将 \u0026ldquo;Full Analysis\u0026quot;改为 \u0026ldquo;Statistics\u0026rdquo;。这将使\u0026quot;Pre-stats\u0026quot;和\u0026quot;Registration\u0026quot;标签变灰。我们还会看到一个新的按钮，叫做 \u0026ldquo;Input is a FEAT directory\u0026rdquo;。点击该按钮，并选择你在上一模块中创建的FEAT目录run1.feat。点击确定，忽略关于从design.fsf文件加载设计信息的警告。（因为我们还没有建立模型，所以没有什么会被覆盖。）\n接下来，点击 \u0026ldquo;Stats\u0026quot;选项卡。有许多选项，但我们将只关注其中的几个。点击 \u0026ldquo;Full model setup\u0026rdquo;，并将原始EV（Original EVs,或解释变量（Explanatory Variables），FSL对回归因子的称呼）的数量改为2。在回归因子1的EV名称栏中，输入 \u0026ldquo;incongruent\u0026rdquo;。点击基本形状旁边的下拉菜单，选择 \u0026ldquo;Custom (3 column format)\u0026quot;。这显示了一个名为\u0026quot;Filename\u0026quot;的字段；点击文件夹图标，选择时间文件incongruent_run1.txt。取消对 \u0026ldquo;Add temporal derivate\u0026quot;按钮的勾选。(这是为了让我们更容易理解设计矩阵；我们将在后面添加导数)。点击 \u0026ldquo;2 \u0026ldquo;标签，重复这些步骤，这次选择计时文件congruent_run1.txt。\n当我们完成了模型的设置，点击Contrasts \u0026amp; F-tests标签。在这里，可以指定在每个条件的β权重被估计后，你想创建哪些对比图（contrast maps）。在这个实验中，我们对三个对比感兴趣：\n与基线相比，不一致(incongruent)条件的平均β权重； 与基线相比，一致（congruent）条件的平均β权重； 不一致条件和一致条件之间的平均β权重的差异。 设置对比度的数量为3，并在每一行输入以下对比度名称，同时在EV1和EV2列输入以下对比度权重：\nincongruent [1 0]; congruent [0 1]; incongruent-congruent [1 -1]。 在FSL中，β权重被称为参数估计值（parameter estimates），或称pe\u0026rsquo;s，而β权重之间的对比被称为参数估计值的对比(contrast of parameter estimates)，或称cope\u0026rsquo;s。当我们检查输出数据时，你会看到两个参数估计文件（每个条件一个），以及三个参数估计对比文件（每个对比一个）。上面的对比号1和2将与参数估计文件相同；然后重新创建它们似乎是多余的，但我们将看到，FSL将要求这些文件被标记为cope\u0026rsquo;s，以便进行更高级别的分析（higher-level analysis）。\n点击 \u0026ldquo;Done\u0026quot;按钮，将打开一个设计矩阵窗口。最左边的一列代表高通滤波器，它去除任何长于红条长度的频率（也就是说，低频被去除，而高频被允许通过滤波器）。右边的两列代表两个回归因子的理想时间序列，它们与我们输入时间文件的顺序相对应；换句话说，第一列是incongruent条件的理想时间序列，第二列是congruent条件的理想时间序列。\n红线代表我们认为如果体素对该回归因子有反应，它的时间序列应该是什么样子。我们会注意到，白条代表的是与该条件下每次试验的开始时间相卷积的HRF。再看一下每个条件的时间文件，看看onset时间和设计矩阵之间的对应关系对你来说是否有意义。然后，点击 \u0026ldquo;Go\u0026quot;来运行模型。\n后期统计标签,Post-Stats FEAT图形用户界面的最后一个选项卡叫做Post-stats。同样，这里有很多选项，而唯一可能改变的是标有 \u0026ldquo;Z threshold \u0026ldquo;和 \u0026ldquo;Cluster P threshold\u0026quot;的选项，这些阈值决定了哪些体素对每个对比度具有统计学意义。我们现在先不考虑这些，等做组分析时再来考虑这些选项。\n理想的时间序列和GLM 在点击 \u0026ldquo;Go\u0026quot;之后，一系列的HTML页面将被打开，以跟踪模型拟合的进展，这将需要5-10分钟才能完成。在等待的时候，让我们看看刚刚创建的模型与GLM的关系。记住，每个体素都有一个BOLD时间序列（我们的结果测量），我们用Y表示。这些回归因子构成我们的设计矩阵，我们用一个大的X来表示。\n到目前为止，所有这些变量都是已知的\u0026ndash;Y是从数据中测得的，而x1和x2是通过对HRF和时间起始点(time onsets)进行卷积而成的。由于矩阵代数是用来设置设计矩阵和估计β权重的，所以方向要转九十度： 通常我们认为时间轴是由左至右，但它被描述为由上至下。换句话说，运行的开始是在时间轴的顶部。\nGLM方程的下一部分是β权重，我们用B1和B2表示。这些代表了我们对HRF需要对每个回归因子进行缩放以最好地匹配Y中的原始数据的估计，因此被称为 \u0026ldquo;β权重\u0026rdquo;。这个方程的最后一项是E，代表残差，或者说我们的理想时间序列模型和估计β权重后的数据之间的差异。如果模型拟合得好，残差就会减少，而且一个或多个β权重更有可能具有统计学意义。下面的动画显示了GLM与你创建的fMRI模型的对应关系。\n检查输出 当模型估计完成后，点击 \u0026ldquo;Stats\u0026quot;链接，查看设计矩阵。这与我们刚才审查的结果相同；下面还有一个标有 \u0026ldquo;Covariance matrix\u0026quot;的图。现在，要知道，如果检测每个对比度所需的信号变化百分比低于2%，那就是合理的。\n点击\u0026quot;Post-stats\u0026quot;链接可以看到每个对比度的阈值图(threshold map)。这显示了每个对比图中通过FEAT GUI的\u0026quot;Post-stats\u0026quot;标签中指定的显著性阈值的任何体素。\n理解模型拟合(model fitting)和第一级分析(first-level analysis)可能具有挑战性。如果在第一次阅读这些章节时没有理解所有的内容，也不要气馁；坚持下去，随着时间和实践的推移，这些概念会变得更加清晰。\n第二级分析，2nd-Level Analysis 学习前提：在学习本小节和下一小节内容时，建议提前先看fsl的脚本编写教程，便于提前准备好已预处理完的数据。\n一旦对Flanker数据集中的所有受试者的运行进行了预处理和分析，我们就可以运行第二级分析了。AFNI和SPM将第二级分析定义为组分析的同义词，而在FSL中，第二级分析是将每个受试者的参数估计和第一级分析的对比估计平均化。\n在Flanker目录下，通过输入Feat_gui从命令行打开FEAT GUI。然后从下拉菜单中选择Higher-Level Analysis。这就把输入栏改为Select FEAT directories。\nData标签上的下拉菜单允许你选择输入是Inputs are lower-level FEAT directories（默认），或者Inputs are 3D cope images from FEAT directories。选择FEAT目录可以让你选择分析哪些cope图像，尽管如果你没有用FSL的默认处理流来分析数据（即数据没有组织在FEAT目录中），直接选择cope图像可以给你更多的灵活性。\n选择FEAT目录 由于我们有26个受试者，每个受试者有2次run，我们总共有52个FEAT目录。将输入的数量改为52，然后点击选择FEAT目录的按钮。\n我们可以用手选择每一个FEAT目录，点击文件夹图标，逐个选择。但正如我们在编写分析脚本时看到的那样，这通常不是一个好主意\u0026ndash;对于大型数据集来说，这是不现实的，而且犯错误的几率会随着受试者数量的增加而增加。\n相反，我们将使用通配符来使其更快更容易。回到你启动FEAT图形用户界面的终端，导航到Flanker目录，输入ctrl+z，然后输入bg并按回车键。这将允许你在终端中输入命令，同时保持FEAT GUI的运行。在命令行中，输入以下内容： ls -d $PWD/sub-??/run* 这将打印出每个FEAT目录的绝对路径。选项-d意味着只列出目录，而$PWD则扩展为指向当前工作目录的绝对路径。在当前目录中，任何以子开头、以两位数结尾的目录（用?的通配符表示）都被添加到路径中。最后，在每个被试目录内，任何以字符串run开头的目录都将被附加到路径名中（例如，run1.feat和run2.feat）。\n这将创建一个有52个条目的列表，其中一个对应于研究中每个被试的每个run。突出显示整个列表，并按command+c复制它。这将把列表复制到您的剪贴板上。然后回到 \u0026ldquo;Select input data\u0026quot;窗口，点击 \u0026ldquo;Paste\u0026quot;按钮。在输入数据窗口中点击，然后按ctrl+y并点击确定。这将把目录列表粘贴到 \u0026ldquo;Select input data\u0026quot;窗口的相应行中。\n在终端中可以使用变量和通配符的组合生成FEAT目录列表（A）。点击（C）中的 \"Paste\"按钮将打开一个输入数据窗口，在这个窗口中可以粘贴目录列表（B）。 在Data选项卡中，你会看到现在有3个较低级别的cope，你可以选择进行分析。如果你把这三个框都选上，它将为每个框运行一个第2级分析，这对应于：\n1.不一致条件下的对比估计值； 2.一致条件下的对比度估计值； 3.不一致条件下的对比度估计值减去一致条件下的对比度估计值（即取参数估计值的差）。\n在Output directory中，输入Flanker_2ndLevel。这就是第二层分析结果的保存位置。\n创建GLM Stats选项卡的外观将与用于第一级分析时不同\u0026ndash;现在可以选择不同的推理类型，或者希望结果如何归纳到人群中。下拉菜单有以下选项：\nFixed Effects： 不从样本中归纳\u0026ndash;只取平均值； Mixed Effects: Simple OLS (Ordinary Least Squares)）： 简单OLS（普通最小二乘法）： 这将对为每个受试者计算的平均参数估计值进行t检验，而不考虑每个受试者的运行之间的差异性； Mixed Effects: FLAME 1）：通过对比估计的方差对每个受试者的参数估计进行加权。换句话说，方差相对较小的受试者将被加权，而方差相对较大的受试者将被减权； Mixed Effects：FLAME 1+2）： FLAME 1的一个更严格的版本。它需要更长的时间，而且只对分析小样本（例如，10个或更少的受试者）有帮助； Randomise：一种非参数检验（在后面的章节中讨论）。\n由于我们只是想在每个受试者中取得各次运行的参数估计值的平均值，我们将使用Fixed Effects选项。一旦你选择了这个选项，点击Full Model Setup。\n这将显示一个窗口，其行数代表单个参数估计值的数量\u0026ndash;在我们的例子中是52。对于Number of main EVs，将其改为26，这是我们数据集中的受试者数量。然后将每一列中的数字改为1，在这里你要对该被试的参数估计值取平均值。在我们的例子中，第1列的前两行将被改为1，第2列的后两行将被改为1，以此类推。\nGLM的部分截图。你将对所有26个受试者采取同样的模式。 当我们完成后，点击Contrasts \u0026amp; F-tests标签，并将Contrasts的数量改为26。将对角线上的所有数字改为1；这将为每个受试者创建一个单一的对比度估计，即该受试者参数估计的平均值。 当完成了GLM和对比度的设置并点击Done后，应该看到像这样的东西： 与第一级分析一样，我们现在将忽略Post-stats标签，因为我们没有进行群体推断(population inference)。\n第三级分析，3nd-Level Analysis 我们分析这个数据集的目的是将结果推广到样本所来自的人群。换句话说，如果我们在样本中看到大脑活动的变化，我们是否可以说这些变化也可能在人群中看到？\n为了测试这一点，我们将进行第三级的分析。在FSL中，第三级分析是一个组水平分析\u0026ndash;我们计算标准误差和对比估计值的平均值，然后测试平均估计值是否有统计学意义。\nFSL一次只能运行一个模型。在这个例子中，我们将对 \u0026ldquo;Incongruent-congruent\u0026quot;的对比进行第三级的分析（在第二级的分析中被标记为cope3，因为它是被指定的第三个对比）。\n加载数据 从Flanker目录中，打开FEAT图形用户界面(Feat_gui)。与第二级分析一样，选择更高级的分析(Higher-level analysis)。现在，不要选择FEAT目录，而是选择Inputs are 3D cope images from FEAT directories，并将输入的数量改为26。第二级分析产生了每个受试者的参数估计（或cope）的平均对比度，在我们的模型中指定的每个对比度。如同在第二层分析中选择FEAT目录一样，我们可以复制和粘贴cope图像的列表： 单击\u0026quot;Select cope images\u0026rdquo;，然后单击 \u0026ldquo;Paste\u0026quot;按钮。在终端中，导航到目录Flanker_2ndLevel.gfeat/cope3.feat/stats，并输入ls $PWD/cope* | sort -V。这将按数字顺序列出所有的cope图像，尽管它们没有被加零。通过键入ctrl+y将列表复制并粘贴到输入数据窗口。点击确定后，将输出目录标记为Flanker_Level3_inc-con。\n创建GLM 点击 \u0026ldquo;Stats\u0026quot;选项卡。对于第三级分析，我们将使用混合效应（Mixed Effects）。这是对方差的建模，这样我们的结果就可以推广到我们的样本人群中。FLAME 1（FSL的混合效应局部分析）通过使用被试内和被试间变异性的信息来提供准确的参数估计；FLAME1+2被认为更准确，但额外的好处通常是最小的，而且过程要长得多。\n最后一个选项，Randomise，使用非参数方法，当关于正态性的假设不成立时，它是有效的。稍后，我们将讨论为什么在某些情况下这是合适的。\n由于我们使用的是一个简单的设计，我们可以使用模型设置向导按钮(Model setup wizard)快速创建一个GLM。我们已经提取了每个被试的对比度，所以我们可以选择单组平均（single group average）。当你点击处理(Process)时，应该看到一个模型表示，看起来像这样：\nPost-Stats标签栏 现在我们终于要讨论Post-Stats标签了。我们可能要考虑改变的唯一默认值是阈值（Thresholding）处理选项。None将不做任何阈值处理（即显示每个体素的参数估计值，无论其显著性如何）；Uncorrected将允许任何单个体素通过Z-阈值中指定的阈值（例如、 这里我们只显示数值大于3.1的体素；Voxel将执行一种基于高斯随机场理论的最大高度阈值，它比Bonferroni检验更保守；最后是Cluster，它使用一个簇定义阈值（CDT,cluster-defining threshold）来确定一个体素簇是否有意义。这种方法背后的逻辑是，相邻的体素不是相互独立的，在估计显著性时要考虑到这种减少的自由度。\n例如，如果我们把Z-阈值保持在3.1，而我们的集群p-阈值为0.05，我们将寻找由每个单独通过3.1的Z-阈值的体素组成的集群。FSL运行模拟，看看我们会有多大的集群，其每个组成体素都通过该z-阈值，并为该CDT创建一个集群大小的分布（类似于我们根据自由度计算t分布时的情况）。然后，在该CDT的模拟中出现少于5%的聚类大小被确定为显著。\n对于大多数分析，默认的聚类校正分析，CDT为z=3.1，聚类阈值为p=0.05是合适的。关于不同软件包和不同聚类校正设置之间的假阳性率的详细比较，见Eklund等人2016年的原始论文；关于聚类校正的一些潜在问题的视频概述，请点击这里。\n现在点击Go。这将需要大约5-10分钟，取决于你的电脑有多强大。\n审查输出结果\n在FEAT的HTML输出中，你会看到阈值化的Z-统计学图像覆盖在MNI大脑模板上。这些是轴向切片，它们可以让你快速了解显著性簇的位置。 要仔细看一下结果，打开fsleyes并加载一个标准模板，比如MNI152_T1_1mm_brain（操作方法：点击标题栏的File \u0026gt; Add standard）。然后加载位于Flanker_3rdLevel_inc-con.gfeat/cope1.feat的thresh_zstat1.nii.gz图像。这个图像只显示那些根据你在Post-stats标签中指定的标准被确定为显著性簇。\n为了使结果看起来更干净，把颜色方案改为 \u0026ldquo;Red-Yellow\u0026rdquo;，并把 \u0026ldquo;Min.\u0026ldquo;值改为3.1。你也可以点击齿轮图标，改变插值，使结果看起来更平滑。最后，点击背内侧前额叶皮层区域(dorsal medial prefrontal cortex area)的一个簇，并通过点击十字线图标关闭十字线。（这些都是外观上的选择，你可以随心所欲地改变它们。）然后可以用相机图标对这个蒙太奇进行快照，并在你的手稿中使用。\n最终的结果是：显示了分析中的一张重要聚类图片。 参考资料 https://andysbrainbook.readthedocs.io/en/latest/fMRI_Short_Course/fMRI_05_1stLevelAnalysis.html https://andysbrainbook.readthedocs.io/en/latest/fMRI_Short_Course/fMRI_07_2ndLevelAnalysis.html https://andysbrainbook.readthedocs.io/en/latest/fMRI_Short_Course/fMRI_08_3rdLevelAnalysis.html "
},
{
	"uri": "https://LiaoPan.github.io/fsl/roi_analysis/",
	"title": "FSL系列教程 #4. ROI分析 ",
	"tags": [],
	"description": "",
	"content": " 简介 使用脑图谱 使用结构像掩膜抽取数据 使用球体抽取数据 练习实践 简介 我们刚刚完成了一个组分析，并确定了大脑的哪些区域在实验的不一致（\u0026ldquo;Incongruent\u0026rdquo;）和一致（\u0026ldquo;congruent\u0026rdquo;）条件下显示出明显的差异。对于一些研究人员来说，这可能是他们想要做的全部。\n这种分析被称为全脑(whole-brain)或探索性分析(exploratory)。当实验者对差异的位置没有假设时，这些类型的分析很有用；这个结果将作为未来研究的基础。\n然而，当对一个特定的被试进行了大量的研究后，我们可以开始对我们应该在大脑图像中找到的结果做出更具体的假设。例如，认知控制已经被研究了很多年，许多关于它的fMRI研究已经发表，使用不同的范式，将认知要求较高的任务与认知要求较低的任务进行比较。通常情况下，在认知要求高的条件下，BOLD信号的明显增加出现在大脑的一个区域，即背内侧前额叶皮层（dosal medial prefrontal cortex），或简称为dmPFC。那么，对于Flanker研究，我们可以将我们的分析限制在这个区域，只从该区域的体素中提取数据。这就是所谓的兴趣区域（ROI,region of interest）分析。在看全脑结果之前，选择分析一个选定的区域，这种分析的一般名称叫做确认性分析(confirmatory analysis)。\n全脑图(Whole-brain maps)可以隐藏我们正在研究的效果的重要细节。我们可能会发现incongruent-congruent的显着效应，但效应显着的原因可能是incongruent大于congruent，或者是incongruent比congruent的消极得多，或者是两者的某种组合。确定是什么在驱动这种效应的唯一方法是ROI分析，这在处理交互作用和更复杂的设计时尤其重要。\n使用脑图谱 为我们的ROI分析创建一个区域(region)的方法是使用图谱(atlas)，或将大脑划分为解剖学上的不同区域的地图。\nFSL已经安装了许多图谱(atlas)，我们可以通过FSL viwer访问这些图谱。如果点击 \u0026ldquo;Settings\u0026rdquo;-\u0026gt;\u0026ldquo;Ortho View 1\u0026rdquo;-\u0026gt;\u0026ldquo;Atlas Panel\u0026rdquo;，就会打开一个名为Atlases的新窗口。默认情况下，将加载哈佛-牛津大学皮质和皮质下图谱（Harvard-Oxford Cortical and Subcortical Atlases）。我们可以通过点击图谱名称旁边的Show/Hide链接看到图集是如何分割大脑的。观察窗口中十字线中心的体素将被分配一个属于大脑结构的概率。\n哈佛-牛津大学皮质图谱，显示在MNI模板大脑上。图谱窗口显示体素位于某个解剖区域的概率。 要将这些区域之一保存为提取数据的文件，也称为掩膜(mask)，点击想用作mask的区域旁边的Show/Hide链接\u0026ndash;在我们的例子中，假设我们想用副扣带回(Paracingulate Gyrus)作为mask。点击该链接将显示该区域叠加在大脑上，并在 \u0026ldquo;Overlay list\u0026quot;叠加列表窗口中将其加载为叠加。点击图像旁边的磁盘图标，将其保存为一个mask。把它保存到Flanker目录下，称为PCG.nii。\n我们的结果将具有与我们用于归一化的模板相同的分辨率。FSL中默认的是MNI_152_T1_2mm_brain，它的分辨率为2x2x2mm。当我们创建一个mask时，它的分辨率将与它所覆盖的模板相同。当我们从mask中提取数据时，数据和mask需要有相同的分辨率。为了避免因图像分辨率不同而导致的任何错误，请使用与我们用于归一化数据的相同模板来创建mask。\n使用结构像掩膜抽取数据 一旦创建了掩膜，我们就可以从中提取每个受试者的对比度估计值（contrast estimates）。虽然你可能认为我们会提取第三级分析的结果，但实际上我们想要的是第二级分析的结果；第三级分析是一个单一的图像，每个体素都有一个数字，而在ROI分析中，我们的目标是单独提取每个受试者的对比度估计。\n以Incongruent-Congruent对比度估计为例，我们可以在Flanker_2ndLevel.gfeat/cope3.feat/stats目录下找到每个受试者的数据图(data maps)。这些数据图有几种不同的计算方式，包括t统计图、cope图和方差图。我更倾向于从z-统计图中提取数据，因为这些数据已经被转换为正态分布的形式，在我看来，更容易绘制和解释。\n为了使我们的ROI分析更容易，我们将把所有的z-统计图合并成一个数据集。为了做到这一点，我们将使用FSL命令和Unix命令的组合。导航到Flanker_2ndLevel.gfeat/cope3.feat/stats目录，然后输入以下内容：\nfslmerge -t allZstats.nii.gz `ls zstat* | sort -V` 这将沿着时间维度（用-t选项指定）把所有的Z-statistic图像合并成一个数据集；这只是意味着把各volume数据串联起来，成为一个更大的数据集。第一个参数是输出数据集的名称（allZstats.nii.gz），后面的代码使用星号通配符列出每个以 \u0026ldquo;zstat\u0026quot;开头的文件，然后用-V选项从小到大对它们进行数字排序。\n将allZstats.nii.gz文件上移三层，使其位于Flanker主目录中（即输入mv allZstats.nii.gz .../../...）。然后使用fslmeants命令从PCG掩码中提取数据：\nfslmeants -i allZstats.nii.gz -m PCG.nii.gz 这将打印26个数字，每个被试一个。每个数字是该被试的对比度估计值，是mask中所有体素的平均数。 这个命令输出的每个数字都对应于进入分析的对比度估计值。例如，第一个数字对应的是sub-01的Incongruent-Congruent的平均对比度估计值，第二个数字是sub-02的平均对比度估计值，以此类推。这些数字可以复制并粘贴到你选择的统计软件包（如R）中，然后你可以对它们进行t检验。 使用球体抽取数据 我们可能已经注意到，使用解剖学掩膜的ROI分析结果并不显著。这可能是因为PCG掩膜覆盖了一个非常大的区域；虽然PCG被标记为一个单一的解剖区域，但我们可能是从几个不同的功能区域提取数据。因此，这可能不是最好的ROI方法。\n另一种技术被称为球形ROI方法（spherical ROI）。在这种情况下，一个给定直径的球体以指定的X、Y和Z坐标的三组为中心。这些坐标通常是基于另一项研究的峰值激活，该研究使用与我们所使用的相同或相似的实验设计。这被认为是一个独立的分析，因为ROI的定义是基于一个单独的研究。\n下面的动画显示了解剖学和球形ROI的区别： 为了创建这个ROI，我们需要从另一项研究中找到峰值坐标；让我们随机挑选一篇论文，如Jahn等人，2016。在结果部分，我们发现Stroop任务存在冲突效应\u0026ndash;这是一个不同但相关的实验设计，也是为了挖掘认知控制\u0026ndash;在MNI坐标0、20、40处有一个峰值t统计。\n接下来的几个步骤很复杂，所以要密切注意每一个步骤：\n打开fsleyes，并加载一个MNI模板。在Location窗口的\u0026quot;Coordinates:MNI152\u0026quot;\u0026ldquo;下的字段中，输入0 20 44。就在这些字段的右边，注意体素位置下的字段中的数字的相应变化。在这种情况下，它们是45 73 58。写下这些数字。\n在终端中，导航到Flanker目录并输入以下内容：\nfslmaths $FSLDIR/data/standard/MNI152_T1_2mm.nii.gz -mul 0 -add 1 -roi 45 1 73 1 58 1 0 1 Jahn_ROI_dmPFC_0_20_44.nii.gz -odt float 这是一条长而密集的命令，但现在只需注意我们在哪里插入了数字45、73和58。当我们根据不同的坐标创建另一个球形ROI时，这些是我们唯一要改变的数字。(当你创建一个新的ROI时，你也应该改变输出文件的标签)。这个命令的输出是一个单一的体素，标志着上述指定坐标的中心。\n接下来，键入 fslmaths Jahn_ROI_dmPFC_0_20_44.nii.gz -kernel sphere 5 -fmean Jahn_Sphere_dmPFC_0_20_44.nii.gz -odt float 这就把单个体素扩展成一个半径为5毫米的球体，并调用输出\u0026quot;Jahn_Sphere.nii.gz\u0026rdquo;。例如，如果想把球体的大小改为10毫米，你可以把这部分代码改为-kernel sphere 10。\n现在，输入 fslmaths Jahn_Sphere_dmPFC_0_20_44.nii.gz -bin Jahn_Sphere_bin_dmPFC_0_20_44.nii.gz 这将对球体进行二进制化处理，从而使其能够被FSL命令所读取。\n在刚才列出的步骤中，注意到每个命令的输出是如何作为下一个命令的输入的。如果你决定创建一个ROI，你将为你自己的ROI改变这一点。\n最后，我们将从这个ROI提取数据，键入： fslmeants -i allZstats.nii.gz -m Jahn_Sphere_bin_dmPFC_0_20_44.nii.gz 你从这个分析中得到的数字应该与你用解剖掩码创建的数字大不相同。将这些命令复制并粘贴到你选择的统计软件包中，并对其进行单样本t检验。它们有意义吗？如果你要在手稿中写出这些结果，你会如何描述它们？\n练习实践 fslmeants使用的掩码是二进制的，这意味着任何含有大于0的数值的体素将被转换成 \u0026ldquo;1\u0026rdquo;，然后只从那些标有 \u0026ldquo;1 \u0026ldquo;的体素中提取数据。你会记得，用fsleyes创建的掩码是概率性的。如果你想用概率权重对提取的对比度估计值进行加权，你可以通过使用fslmeants的-w选项来实现。试着输入 fslmeants -i allZstats.nii.gz -m PCG.nii.gz -w 并观察数字与之前使用二进制掩码的方法有什么不同。差异小吗？大吗？这是你所期望的吗？\n使用球状ROI分析部分给出的代码，创建一个半径为7毫米的球体，位于MNI坐标36, -2, 48。 使用哈佛-牛津大学皮层下图谱创建一个右杏仁核的解剖掩膜。按你想要的方式给它贴上标签。然后，从应付1中提取z统计数字（即与基线相比，Incongruent的对比估计）。 "
},
{
	"uri": "https://LiaoPan.github.io/mrtrix/tissue_boundary/",
	"title": "MRtrix3教程 #4 大脑组织边界",
	"tags": [],
	"description": "",
	"content": " 简介 转换结构像数据 配准扩散图像和解剖图像 参考资料 简介 我们几乎已经准备好开始我们的纤维束流线分析(streamline analysis)，我们将在灰质和白质边界的随机位置放置种子（seeds）。一条流线将从每个种子生长出来，并从该种子区域追踪路径，直到它在另一个区域终止。一些流线会在一些没有意义的地方终止\u0026ndash;例如，流线可能终止于脑室的边界。我们将剔除这些 \u0026ldquo;错误 \u0026ldquo;的流线，剩下的大部分流线似乎是连接遥远的灰质区域。\n要做到这一点，我们首先需要在灰质和白质之间建立一个边界。MRtrix命令5ttgen(5tt就是表示生成了5种类型的组织，five-tissue-type)将使用FSL的FAST，连同其他命令，将解剖图像分割成五种组织类型(注意顺序)：\n灰质(Grey Matter, GM)； 白质(White Matter, WM)； 脑脊液(Cerebrospinal Fluid, CSF)； 皮质下灰质（如杏仁核和基底神经节）(Subcortical Grey Matter,such as amygdala and basal ganglia)； 病理组织(Pathological Tissue)。 一旦我们将大脑分割成这些组织类别，我们就可以使用边界作为掩码来限制我们放置种子的位置。\n转换结构像数据 我们使用mrconvert命令将结构像转换为MRtrix格式。如果你在dwi目录下，你可以输入以下命令：\n# 备注：..表示当前目录下的上一层目录 $ mrconvert ../anat/sub-CON02_ses-preop_T1w.nii.gz T1.mif mrconvert: [100%] uncompressing image \u0026#34;sub-CON02_ses-preop_T1w.nii.gz\u0026#34; mrconvert: [100%] copying from \u0026#34;sub-CON02_ses-preop_T1w.nii.gz\u0026#34; to \u0026#34;T1.mif\u0026#34; 之后，我们现在将使用命令5ttgen将解剖图像分割成上面列出的组织类型：\n$ 5ttgen -h MRtrix 3.0.4 5ttgen 5ttgen: part of the MRtrix3 package SYNOPSIS Generate a 5TT image suitable for ACT USAGE 5ttgen algorithm [ options ] ... algorithm Select the algorithm to be used to complete the script operation; additional details and options become available once an algorithm is nominated. Options are: freesurfer, fsl, gif, hsvs DESCRIPTION 5ttgen acts as a \u0026#39;master\u0026#39; script for generating a five-tissue-type (5TT) segmented tissue image suitable for use in Anatomically-Constrained Tractography (ACT). A range of different algorithms are available for completing this task. When using this script, the name of the algorithm to be used must appear as the first argument on the command-line after ... $ 5ttgen fsl -h MRtrix 3.0.4 5ttgen fsl 5ttgen fsl: part of the MRtrix3 package SYNOPSIS Use FSL commands to generate the 5TT image based on a T1-weighted image USAGE 5ttgen fsl [ options ] input output input The input T1-weighted image output The output 5TT image Options specific to the \u0026#39;fsl\u0026#39; algorithm -t2 \u0026lt;T2 image\u0026gt; Provide a T2-weighted image in addition to the default T1-weighted image; this will be used as a second input to FSL FAST -mask MASK Manually provide a brain mask, rather than deriving one in the script $ 5ttgen fsl T1.mif 5tt_nocoreg.mif 5ttgen: 5ttgen: Note that this script makes use of commands / algorithms that have relevant articles for citation; INCLUDING FROM EXTERNAL SOFTWARE PACKAGES. Please consult the help page (-help option) for more information. 5ttgen: 5ttgen: Generated scratch directory: /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/anat/5ttgen-tmp-OOBLVX/ Command: mrconvert /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/anat/T1.mif /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/anat/5ttgen-tmp-OOBLVX/input.mif 5ttgen: Changing to scratch directory (/Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/anat/5ttgen-tmp-OOBLVX/) Command: mrconvert input.mif T1.nii -strides -1,+2,+3 Command: maskfilter /Applications/fsl/data/standard/MNI152_T1_1mm_brain_mask_dil.nii.gz dilate mni_mask.nii -npass 4 Command: standard_space_roi T1.nii T1_preBET.nii.gz -maskMASK mni_mask.nii -roiFOV Command: bet T1_preBET.nii.gz T1_BET.nii.gz -f 0.15 -R Command: fast T1_BET.nii.gz Command: run_first_all -m none -s L_Accu,R_Accu,L_Caud,R_Caud,L_Pall,R_Pall,L_Puta,R_Puta,L_Thal,R_Thal -i T1.nii -o first 5ttgen: [100%] Generating partial volume images for SGM structures Command: mrmath [mesh2voxel_*.mif (10 items)] sum - | mrcalc - 1.0 -min all_sgms.mif Command: mrthreshold T1_BET_pve_2.nii.gz - -abs 0.001 | maskfilter - connect - -connectivity | mrcalc 1 - 1 -gt -sub remove_unconnected_wm_mask.mif -datatype bit Command: mrcalc T1_BET_pve_0.nii.gz remove_unconnected_wm_mask.mif -mult csf.mif Command: mrcalc 1.0 csf.mif -sub all_sgms.mif -min sgm.mif Command: mrcalc 1.0 csf.mif sgm.mif -add -sub T1_BET_pve_1.nii.gz T1_BET_pve_2.nii.gz -add -div multiplier.mif Command: mrcalc multiplier.mif -finite multiplier.mif 0.0 -if multiplier_noNAN.mif Command: mrcalc T1_BET_pve_1.nii.gz multiplier_noNAN.mif -mult remove_unconnected_wm_mask.mif -mult cgm.mif Command: mrcalc T1_BET_pve_2.nii.gz multiplier_noNAN.mif -mult remove_unconnected_wm_mask.mif -mult wm.mif Command: mrcalc 0 wm.mif -min path.mif Command: mrcat cgm.mif sgm.mif wm.mif csf.mif path.mif - -axis 3 | mrconvert - combined_precrop.mif -strides +2,+3,+4,+1 Command: mrmath combined_precrop.mif sum - -axis 3 | mrthreshold - - -abs 0.5 | mrgrid combined_precrop.mif crop result.mif -mask - Command: mrconvert result.mif /Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/anat/5tt_nocoreg.mif Command: 5ttcheck result.mif 5ttgen: Changing back to original directory (/Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/anat) 5ttgen: Deleting scratch directory (/Volumes/Touch/Datasets/DTI/ds001226-download/sub-CON02/ses-preop/anat/5ttgen-tmp-OOBLVX/) 这个命令将需要大约10-15分钟(性能好的电脑，不到5分钟就可以完成)。如果分割成功完成，当你输入mrview 5tt_nocoreg.mif时，你应该看到以下图像（按左右方向键可滚动浏览不同的组织类型）： `5ttgen fsl T1.mif 5tt_nocoreg.mif`的输出将是一个有5个Volume的单一数据集，每个组织类型一个。用`mrview`检查这个图像，用左右方向键在组织类型之间切换。这些组织类型是 GM、WM、CSF、皮质下GM和病理组织。如果没有检测到病理组织，则该体积为空白。 如果分割步骤失败，这可能是由于组织类型之间的对比度不够；例如，一些解剖图像的灰质和白质都很暗，或者两种组织类型都很亮。我们可以用AFNI的3dUnifize等命令增加组织间的强度对比（也称为强度归一化），来帮助分割过程，例如： \\$ 3dUnifize -input anat.nii -prefix anat_unifize.nii,前后图像之间的差异可能很细微，但可以防止抛出分割错误。\n配准扩散图像和解剖图像 如果分割已经完成，没有任何错误，我们的下一步是将解剖学图像（T1结构像）和扩散加权图像（DWI）进行配准。这可以确保组织类型的边界与扩散加权图像的边界相一致。因为即使两个扫描的位置有微小的差异，也都会影响到纤维束成像的结果。\n我们将首先使用命令dwiextract和mrmath将扩散数据中的B0图像平均化。这些图像看起来最像T2加权的功能扫描，因为在采集过程中没有应用扩散梯度\u0026ndash;换句话说，它们是在B值为0时采集的。要看这是如何工作的，请回到dwi目录，输入以下命令：\n# 使用dwiextract首先提取出Bvalue为0的多个volumes，然后再使用mrmath函数在时间轴上对bvalue为0的数据进行平均。（即对提取出来的多个volumes平均） $ dwiextract sub-02_den_preproc_unbiased.mif - -bzero | mrmath - mean mean_b0.mif -axis 3 dwiextract: [100%] extracting volumes mrmath: [100%] preloading data for \u0026#34;/var/folders/39/93zn2fy95cd9b_b38zvmvgjc0000gn/T/mrtrix-tmp-CDi8x9.mif\u0026#34; mrmath: [100%] computing mean along axis 3... 为了在扩散图像和解剖图像之间进行配准，因为MRtrix软件包的库中没有配准命令，所以我们需要使用另一个软件包FSL的命令flirt。(同理，其实我们也可以使用ANTs包中的配准算法)\nshell # 第一步是将分割后的解剖图像和我们刚刚提取的B0图像进行转换 # 移动5tt_nocoreg.mif到当前的dwi目录下 mv ../anat/5tt_nocoreg.mif . # mif转换为nifti mrconvert mean_b0.mif mean_b0.nii.gz mrconvert 5tt_nocoreg.mif 5tt_nocoreg.nii.gz # [fslroi](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils) # 由于 flirt 只能处理单个 3D 图像（不是 4D 数据集），我们将使用 fslroi 提取分割数据集的第一个Volume，这对应于灰质。 # fslroi \u0026lt;input\u0026gt; \u0026lt;output\u0026gt; \u0026lt;tmin\u0026gt; \u0026lt;tsize\u0026gt; # 同理，我们可以从在时间维度上抽取出WM、CSF等组织类型，形成单个Volume # fslroi 5tt_nocoreg.nii.gz 5tt_vol1.nii.gz 1 1 # WM # fslroi 5tt_nocoreg.nii.gz 5tt_vol2.nii.gz 2 1 # CSF fslroi 5tt_nocoreg.nii.gz 5tt_vol0.nii.gz 0 1 # GM # 然后我们使用flirt命令来配准这两个数据： # 注意，查看flirt的帮助文档为flirt -help # 该命令使用灰质分割图（即 \u0026#34;5tt_vol0.nii.gz\u0026#34;）作为参考图像，也就是说，它保持静止状态。然后移动平均的B0图像，以找到与灰质分割的最佳匹配。这个命令的输出，\u0026#34;diff2struct_fsl.mat\u0026#34;，包含了用于在灰质分割上叠加扩散图像的变换矩阵。 flirt -in mean_b0.nii.gz -ref 5tt_vol0.nii.gz -interp nearestneighbour -dof 6 -omat diff2struct_fsl.mat # 现在我们已经生成了我们的变换矩阵，我们将需要把它转换成可以被MRtrix读取的格式。也就是说，我们现在已经准备好在短暂离开MRtrix之后回到MRtrix中。transformconvert命令可以做到这一点： transformconvert diff2struct_fsl.mat mean_b0.nii.gz 5tt_nocoreg.nii.gz flirt_import diff2struct_mrtrix.txt # 请注意，上述步骤使用了解剖学分割图作为参考图像。我们这样做是因为通常情况下，如果参考图像具有更高的空间分辨率和更清晰的组织类型区分，那么配准会更准确。然而，我们也希望在预处理过程中尽可能少地引入对功能数据的编辑和插值。因此，既然我们已经有了将弥散图像转化为解剖图像的步骤，我们就可以采取转化矩阵的逆运算来做相反的事情--即将解剖图像配准到弥散图像： mrtransform 5tt_nocoreg.mif -linear diff2struct_mrtrix.txt -inverse 5tt_coreg.mif 生成的文件“5tt_coreg.mif”可以加载到 mrview 中以检查配准的质量\nmrview sub-02_den_preproc_unbiased.mif -overlay.load 5tt_nocoreg.mif -overlay.colourmap 2 -overlay.load 5tt_coreg.mif -overlay.colourmap 1 \u0026ldquo;overlay.colormap\u0026quot;选项为每张被加载的图像指定不同的颜色代码。在这种情况下，配准前的边界将被描述为蓝色，配准后的边界将被显示为红色。\n配准前后边界的变化可能非常轻微，但它们会对我们所做的后续其他步骤产生很大影响。请确保检查所有三个视图中的边界；你也可以使用`Tool -\u003e Overlay`菜单来显示或隐藏不同的覆盖。 创建 \u0026ldquo;种子\u0026quot;边界的最后一步\u0026ndash;分离灰质和白质的边界，我们将用它来创建流线的种子\u0026ndash;是用5tt2gmwmi（代表 \u0026ldquo;5组织类型（分割）到灰质/白质界面\u0026rdquo;）命令创建的。\n$ 5tt2gmwmi -h MRtrix 3.0.4 5tt2gmwmi Dec 14 2022 5tt2gmwmi: part of the MRtrix3 package SYNOPSIS Generate a mask image appropriate for seeding streamlines on the grey matter-white matter interface USAGE 5tt2gmwmi [ options ] 5tt_in mask_out 5tt_in the input 5TT segmented anatomical image mask_out the output mask image OPTIONS -mask_in image Filter an input mask image according to those voxels that lie upon the grey matter - white matter boundary. If no input mask is provided, the output will be a whole-brain mask image calculated using the anatomical image only. ... $ 5tt2gmwmi 5tt_coreg.mif gmwmSeed_coreg.mif 5tt2gmwmi: [100%] Generating GMWMI seed mask 同样，我们将使用mrview检查结果，以确Interface在我们认为应该的位置\nmrview sub-02_den_preproc_unbiased.mif -overlay.load gmwmSeed_coreg.mif 参考资料 https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Course/MRtrix_06_TissueBoundary.html "
},
{
	"uri": "https://LiaoPan.github.io/fsl/scripts/",
	"title": "FSL系列教程 #5. FSL脚本编写",
	"tags": [],
	"description": "",
	"content": "简介 在对单个受试者的单次run进行预处理并建立模型之后，我们就需要对数据集中所有受试者的所有run进行相同的处理。这看似繁琐，但也是可行的\u0026ndash;我们只有26个受试者，每个受试者有两次run。我们可能认为这可以在一周左右的时间内完成；而且也可以随时将这项任务分配给几名研究助理。\n然而，在某些时候，您会遇到两个问题：\n我们会发现，手动分析每次运行不仅乏味，而且容易出错，随着要分析的运行数量增加，出错的概率也会显著增加； 对于较大的数据集（例如，80个受试者，每个受试者有5次run），这种方法很快就会变得不切实际。 另一种方法是编写分析脚本。就像演员有一个脚本，告诉他说什么、站在哪里、在哪里移动一样，我们也可以编写一个脚本，告诉计算机如何分析数据集。这样做有双重好处，既可以实现分析自动化，又可以分析任何规模的数据集\u0026ndash;分析两个受试者或两百个受试者的代码几乎完全相同。\n首先，我们将创建一个模板，其中包含分析单次run所需的代码，然后我们将使用for-loop自动分析所有运行。这个想法很简单；尽管代码一开始可能难以理解，但一旦我们对其更加熟悉，我们就会发现如何将其应用于任何数据集。\n理解下述代码脚本需要Linux的shell脚本基础，推荐掌握了基础的shell脚本语法后，再来继续阅读下述内容。\n创建脚本模版 当分析sub-08被试的第一个run时，会创建一个名为run1.feat的目录。在该目录下有几个文件和子目录。其中一个文件design.fsf包含了从FEAT图形用户界面转录到文本文件中的所有代码。这是FSL运行来完成每个预处理和建模步骤的代码。如果在文本编辑器中打开design.fsff文件和用来创建design.fsf文件的FEAT图形用户界面并排比较，我们可以看到输入到FEAT图形用户界面的数据在哪里被写入design.fsf文件。\n如果我们打开了FEAT图形用户界面，点击屏幕底部的Load按钮，并选择run1.feat目录下的design.fsf文件，它将把所有设置更改为您保存脚本时在图形用户界面中输入的设置。\n在前面的教程中，我们分别运行了FEAT的预处理和模型拟合。现在我们将从FEAT GUI的下拉菜单中选择 \u0026ldquo;Full Analysis（全分析）\u0026quot;，创建一个将这两个步骤结合在一起的模板。\n首先，输入rm -r run1.feat删除当前run1.feat目录。然后在命令行输入Feat_gui打开FEAT图形用户界面。我们将在下拉菜单中选择 \u0026ldquo;Full Analysis（全面分析）\u0026ldquo;选项，而不是将其作为两个单独的会话来运行。以前面的教程为指导，填写预处理和模型拟合的所有必填项。\n填写完所有字段后，不要点击Go按钮，而是点击Save并标注文件为design_run1。这将保存多个扩展名为 \u0026ldquo;con\u0026rdquo;、\u0026ldquo;mat \u0026ldquo;和 \u0026ldquo;png \u0026ldquo;的文件，但我们的脚本将使用文件design_run1.fsf。\n现在对run 2执行相同的步骤，加载相应的功能数据和时序文件。将文件保存为design_run2.fsf。\n在代码编辑器(或者文本编辑器)中打开design_run1.fsf，查看所有已填写的选项。我们的目标是使该模板可用于任何被试，只需在for-loop中稍作改动即可。在本例中，我们唯一需要更改的是被试名称，其余选项对每个被试都是相同的。\n运行脚本 将design_run1.fsf和design_run2.fsf文件移到包含被试的目录下（即mv design*.fsf ..，然后cd ..）。然后下载脚本 run_1stLevel_Analysis.sh(如下述代码所示)，并将其移动到Flanker目录中：\nrun_1stLevel_Analysis.sh #!/bin/bash # Generate the subject list to make modifying this script # to run just a subset of subjects easier. # 依次遍历26个被试数据 for id in `seq -w 1 26` ; do subj=\u0026#34;sub-$id\u0026#34; echo \u0026#34;===\u0026gt; Starting processing of $subj\u0026#34; echo cd $subj # 颅骨去除 # If the brain mask doesn’t exist, create it if [ ! -f anat/${subj}_T1w_brain_f02.nii.gz ]; then echo \u0026#34;Skull-stripped brain not found, using bet with a fractional intensity threshold of 0.2\u0026#34; # Note: This fractional intensity appears to work well for most of the subjects in the # Flanker dataset. You may want to change it if you modify this script for your own study. bet2 anat/${subj}_T1w.nii.gz \\ anat/${subj}_T1w_brain_f02.nii.gz -f 0.2 fi # Copy the design files into the subject directory, and then # change “sub-08” to the current subject number cp ../design_run1.fsf . cp ../design_run2.fsf . # 替换*.fsf中的\u0026#34;sub-08\u0026#34;为当前需要处理的被试名称 # Note that we are using the | character to delimit the patterns # instead of the usual / character because there are / characters # in the pattern. sed -i \u0026#39;\u0026#39; \u0026#34;s|sub-08|${subj}|g\u0026#34; \\ design_run1.fsf sed -i \u0026#39;\u0026#39; \u0026#34;s|sub-08|${subj}|g\u0026#34; \\ design_run2.fsf # 直接使用feat执行*.fsf脚本 # Usage: feat \u0026lt;design.fsf\u0026gt; # Now everything is set up to run feat echo \u0026#34;===\u0026gt; Starting feat for run 1\u0026#34; feat design_run1.fsf echo \u0026#34;===\u0026gt; Starting feat for run 2\u0026#34; feat design_run2.fsf echo # Go back to the directory containing all of the subjects, and repeat the loop cd .. done echo 脚本的开头是一个shebang和一些注释，描述了脚本的具体操作；然后使用反引号来扩展seq -w 1 26，以创建一个循环，在所有被试上运行代码的主体。该脚本使用一个条件来检查是否存在颅骨剥离后的结构像数据，如果不存在，则生成。然后编辑模板design*.fsf文件，将字符串sub-08替换为当前受试者的姓名。*.fsf文件使用命令feat运行，就像从命令行运行FEAT图形用户界面一样。整个脚本中都使用了echo命令，让用户知道何时运行新的步骤。\n只需在Flanker目录下输入bash run_1stLevel_Analysis.sh即可运行脚本。当运行一个新步骤时，echo命令将向终端打印文本，HTML页面将跟踪预处理和统计的进度。\n更多的脚本模板参考\n该脚本将循环处理Flanker数据集中的所有受试者，并为每次运行做预处理和统计分析。这需要的时间取决于你的机器有多快，但应该需要2-4小时左右。请确保对每个被试进行质量检查，就像在预处理教程中做的那样。\n"
},
{
	"uri": "https://LiaoPan.github.io/afni/",
	"title": "AFNI系列教程",
	"tags": [],
	"description": "",
	"content": " 在fMRI相关分析软件中，AFNI是最难学习的，如果第一次没学懂，咱多看看、多实践，不用害怕去尝试它。\n介绍 AFNI (Analysis of Functional NeuroImages)是一个领先的功能神经图像分析软件套件，包含 C、Python、R 程序和 shell 脚本，主要开发用于分析和显示多种 MRI 模态：解剖、功能 MRI (FMRI) 和扩散加权 (DWI) 数据。它是免费提供的（作为开源代码和预编译的二进制文件）用于研究目的。该软件几乎可以在任何带有 X11 和 Motif 显示的 Unix 系统上运行。为 MacOS 和 Linux 系统提供二进制包，例如 Fedora、CentOS/Red Hat 和 Ubuntu（包括用于 Linux 的 Windows 子系统）。\nAFNI能解决什么问题？ APQC: afni_proc.py质量控制 帮助研究者检查已处理过的数据。\ngraph LR a(AFNI基本操作)--\u0026gt;b(数据预处理) a(AFNI基本操作)--\u0026gt;d(时间校正) a(AFNI基本操作)--\u0026gt;c(头动校正) a--\u0026gt;f(空间配准) a--\u0026gt;e(空间平滑和时间序列的标注化) a--\u0026gt;g(一般线性模型) a--\u0026gt;h(组分析) AFNI安装 进入官网，参考安装手册，安装对应系统的AFNI软件。\n时间校正 在MRI扫描过程中，有两种方法：\n顺序切片采集 按照顺序从上到下、从下到上进行采集。\n交错切片采集 每采集一张切片后隔一张再采集，然后第二遍进行间隙填充。\n即从扫描开始的第一个切片到最后一个切片之间存在一定的时间差，导致采集到的数据并不是同一个时间点。\n脚本：3dTshift\n配准与标准化 每个人的大脑存在差异，在进行组分析时，需要将个体的大脑体素都对应到相同的大脑模板上再进行分析。\n脚本：align_epi_anat.py\n对准和运动校正 在MRI扫描过程中，被试头部可能存在轻微扰动，对于成像结果造成干扰，故我们需要对头动进行校正。\n刚体变换：采用刚体变换来解决头动问题，如果我们设定一个参考点，然后检测到受试者的头部向哪个方向移动了，那么我们只需要将图像的切片向相反的方向移动同样的距离即可，当然，不只是平移，包括旋转等。\n脚本：volreg\n平滑 平滑就是用周围体素的平均值代替当前体素，这对使得图像变得模糊，分辨率降低。但是平滑对与fMRI来说是非常有效的，因为fMRI的噪音较大，平滑后可以显著降噪，同时增强信号。平滑核函数一般包括两个：4mm和10mm，越大的核函数平滑程度更大，当然图像分辨率也越低。\n脚本：blur\nmask和体素缩放 mask 设置一个掩膜(mask)只把头部纳入进来，其余部分都去掉。去结构像的mask，然后应用到功能像上。\n体素缩放 不同受试者的图像之间像素强度可能存在差异，这样的分析结果不会有任何意义，所我我们将每个体素的时间序列缩放为100的平均值（范围0-200）。\n脚本：3dAutomask\n数据准备： https://openneuro.org/datasets/ds000102/versions/00001\n参考资料 AFNI官网文档 https://www.cnblogs.com/kongmaster/p/16635637.html "
},
{
	"uri": "https://LiaoPan.github.io/mrtrix/connectome/",
	"title": "MRtrix3教程 #6 Connectome",
	"tags": [],
	"description": "",
	"content": " 简介 创建脑连接组（Connectome） 可视化脑连接组 参考 简介 现在我们已经创建了一个流线图，我们就可以创建一个连接组，代表连接大脑不同部分的流线数量。为了做到这一点，我们必须首先将大脑分割成不同的区域，或节点。做到这一点的一个方法是是使用脑图谱（atlas），将大脑中的每个体素分配给特定的ROI。\n你可以使用你想要的任何脑图谱，但在本教程中，我们将使用FreeSurfer附带的脑图谱。因此，我们的第一步将是通过recon-all来处理被试的解剖图像。\n# 如果想更换数据生成的目录，可以设置SUBJECTS_DIR环境变量到自己想要的目录路径 $ export SUBJECTS_DIR=\u0026lt;your_custom_path\u0026gt; # 耗时很长，需要慢慢等。 $ recon-all -i sub-CON02_ses-preop_T1w.nii.gz -s sub-CON02_recon -all 创建脑连接组（Connectome） 当recon-al完成后，我们将需要把FreeSurfer解析的标签转换为MRtrix能理解的格式。labelconvert命令将使用FreeSurfer的注解（parcellation）和分割输出来创建一个新的.mif格式的注解（parcellation）文件：\n$ labelconvert -help MRtrix 3.0.4 labelconvert Dec 14 2022 labelconvert: part of the MRtrix3 package SYNOPSIS Convert a connectome node image from one lookup table to another USAGE labelconvert [ options ] path_in lut_in lut_out image_out path_in the input image lut_in the connectome lookup table corresponding to the input image lut_out the target connectome lookup table for the output image image_out the output image $ labelconvert sub-CON02_recon/mri/aparc+aseg.mgz $FREESURFER_HOME/FreeSurferColorLUT.txt /usr/local/mrtrix3/share/mrtrix3/labelconvert/fs_default.txt sub-CON02_parcels.mif 然后，我们需要创建一个全脑连接组，代表图谱中每个注解对之间的流线（本例中为84x84）。\u0026ldquo;symmetric\u0026rdquo; 选项将使下对角线与上对角线相同，而 \u0026ldquo;scale_invnodevol\u0026quot;选项将以节点大小的倒数来缩放连接组：\n$ tck2connectome -h MRtrix 3.0.4 tck2connectome Dec 14 2022 tck2connectome: part of the MRtrix3 package SYNOPSIS Generate a connectome matrix from a streamlines file and a node parcellation image USAGE tck2connectome [ options ] tracks_in nodes_in connectome_out tracks_in the input track file nodes_in the input node parcellation image connectome_out the output .csv file containing edge weights ... Options for outputting connectome matrices -symmetric Make matrices symmetric on output -zero_diagonal Set matrix diagonal to zero on output ... -out_assignments path output the node assignments of each streamline to a file; this can be used subsequently e.g. by the command connectome2tck ... $ tck2connectome -symmetric -zero_diagonal -scale_invnodevol -tck_weights_in sift_1M.txt tracks_10M.tck sub-CON02_parcels.mif sub-CON02_parcels.csv -out_assignment assignments_sub-CON02_parcels.csv 可视化脑连接组 创建parcels.csv文件后，我们可以在Matlab中将其视为矩阵。首先，需要导入它：\nconnectome = importdata(\u0026#39;sub-CON02_parcels.csv\u0026#39;) % 更高的结构连接对更亮 imagesc(connectome) % 为了使这些关联更加明显，您可以更改颜色图的缩放比例 imagesc(connectome,[0,1]) 最明显的特征是将图分成两个不同的\"盒子\"，代表每个半球内的结构连接性增加。你还会观察到一条沿对角线描画的相对较亮的线，代表附近节点之间更高的结构连接。在对立的左下角和右上角更亮的方框代表了同源区域(homologous regions)之间结构连接的增加。 调整缩放比例后的脑连接图 参考 https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Course/MRtrix_08_Connectome.html "
},
{
	"uri": "https://LiaoPan.github.io/eeglab/",
	"title": "EEGLAB系列教程",
	"tags": [],
	"description": "",
	"content": "测试一下\n"
},
{
	"uri": "https://LiaoPan.github.io/fieldtrip/",
	"title": "FieldTrip系列教程",
	"tags": [],
	"description": "",
	"content": "测试一下\n"
},
{
	"uri": "https://LiaoPan.github.io/freesurfer/",
	"title": "FreeSurfer系列教程",
	"tags": [],
	"description": "",
	"content": "介绍 FreeSurfer是一款免费开源的用于分析和可视化来自横断面和纵向研究的神经影像数据软件包。它由 Martinos 生物医学成像中心的计算神经成像实验室开发。\nFreeSurfer 为结构像和功能像提供完整的处理流，包括提供线性和非线性配准、皮质和皮质下分割、皮质表面重建、组形态测量统计分析、扩散像、PET分析等的工具。它也是 Human Connectome Project 的首选结构像分析软件。\n有关使用和理解 FreeSurfer 工具的扩展文档，请访问FS Wiki。\nFreeSurfer能解决什么问题？ MRI的图像分割、配准 颅骨剥离，B1偏场校正，灰白色质分割 个体皮质表面与立体定向图谱的非线性配准 皮质表面重建 计算皮质厚度、曲率、灰质体积等 皮层表面区域以及皮层下的大脑结构的标记 组间差异分析以及可视化 参考资料 官网 Freesurfer使用手册 "
},
{
	"uri": "https://LiaoPan.github.io/fsl/",
	"title": "FSL系列教程",
	"tags": [],
	"description": "",
	"content": " 简介 简介 FSL是用于fMRI、MRI和DTI脑成像数据的综合分析工具库。它可以在Apple和PC（Linux和Windows）上运行，并且非常易于安装。大多数工具既可以从命令行运行，也可以作为GUI（“点击式”图形用户界面）运行。\n2019年 FSL 北京培训 FSL 官方在线课程 "
},
{
	"uri": "https://LiaoPan.github.io/spm/",
	"title": "SPM系列教程",
	"tags": [],
	"description": "",
	"content": "SPM介绍 SPM(Statistical Parametric Mapping)分析功能成像数据主流的一个开源软件包，可以分析多种脑成像数据，包括fMRI，PET，SPECT，EEG和MEG。 SPM软件包专为分析脑成像数据序列而设计，这些序列包括不同队列（cohorts）的一系列图像或者同一个被试的时间序列。\n中文版SPM初学者教程 原版SPM12 Starter\u0026rsquo;s GUIDE\nhttps://jsheunis.github.io/2018-06-28-spm12-matlab-scripting-tutorial-4/ 汇总\n"
},
{
	"uri": "https://LiaoPan.github.io/ants/",
	"title": "ANTs系列教程",
	"tags": [],
	"description": "",
	"content": " 下载ANTs工具箱 安装ANTs工具箱 设置环境变量PATH、ANTSPATH 下载ANTs工具箱 点击下载链接，选择想要的版本进行下载。 Mac环境下，等待下载完成后，解压到特定文件下/opt/ants-\u0026lt;version\u0026gt;/[bin,lib]，\n安装ANTs工具箱 设置环境变量PATH、ANTSPATH 在Mac环境下，打开~/.bash_profile文件,写入下述内容：\n# ANTs export ANTSPATH=/opt/ants-2.4.4/bin/ export PATH=${ANTSPATH}:$PATH 然后，source ~/.bash_profile来激活环境变量。 最后，我们来检查安装是否成功。\n# 在终端输入以下命令，会输出antsRegistration的对应路径 $ which antsRegistration /opt/ants-2.4.4/bin//antsRegistration # 在终端输入以下命令，会输出antsRegistrationSyN.sh的使用方法 $ antsRegistrationSyN.sh Usage: antsRegistrationSyN.sh -d ImageDimension -f FixedImage -m MovingImage -o OutputPrefix Example Case: antsRegistrationSyN.sh -d 3 -f fixedImage.nii.gz -m movingImage.nii.gz -o output Compulsory arguments: -d: ImageDimension: 2 or 3 (for 2 or 3 dimensional registration of single volume) -f: Fixed image(s) or source image(s) or reference image(s) ... 若在mac环境下，使用ANTs命令时，出现以下问题，我们就需要给所有相关二进制文件授权。 授权方式如下：\n$ xattr -r -d com.apple.quarantine \u0026lt;指定授权文件夹\u0026gt; $ xattr -r -d com.apple.quarantine /opt/ants-2.4.4/ https://github.com/ANTsX/ANTsPy https://github.com/ANTsX/ANTs\nhttps://github.com/ANTsX/ANTs/wiki/Installing-ANTs-release-binaries https://andysbrainbook.readthedocs.io/en/latest/ANTs/ANTs_Overview.html?highlight=ants\n"
},
{
	"uri": "https://LiaoPan.github.io/mne/",
	"title": "MNE系列教程",
	"tags": [],
	"description": "",
	"content": "更多的MNE使用技巧参考\n"
},
{
	"uri": "https://LiaoPan.github.io/freesurfer/practice/",
	"title": "FreeSurfer教程 #N. 实践教程之CookBook",
	"tags": [],
	"description": "",
	"content": " 实践#1:如何将一个个体subject映射到fsaverage？ 实践2:如何提取stats文件夹内的统计信息？ 实践#3:如何提取感兴趣ROI区域的结构信息？ 实践#4:如果构建一个surface ROI重采样到体积（Volume）？ 实践#5:如何使用FreeSurfer去除颅骨(skull-stripping)? 实践#1:如何将一个个体subject映射到fsaverage？ 如何按自定义模板，重建皮层，并提取皮层信息？\n实践2:如何提取stats文件夹内的统计信息？ 方法: 使用asegstats2table和aparcstats2table命令来提取 $ asegstats2table --subject \u0026lt;\u0026gt; --common-segs --meas \u0026lt;volume,mean,std\u0026gt; --stats=\u0026lt;stats file\u0026gt; --table=\u0026lt;extracted measurement to a text file\u0026gt; $ asegstats2table --subjects sub-101 sub-103 --common-segs --meas volume --stats=aseg.stats --table=segstats.txt --subjects选项指定了一个被试名称的列表。 --common-segs表示输出所有被试共有的分段，换句话说，如果一个受试者的分段数与其他受试者不同，不要以错误退出命令。 --meas表示要从表中提取哪种结构测量值（\u0026ldquo;volume \u0026ldquo;是默认值；替代值是 \u0026ldquo;mean \u0026ldquo;和 \u0026ldquo;std\u0026rdquo;）。 --stats指的是将从分段数据中提取的统计文件； --table将提取的测量数据写入一个文本文件，按被试名称组织。\n同理，aparcstats2table也类似，\n$ aparcstats2table --subjects sub-101 sub-103 --hemi lh --meas thickness --parc=aparc --tablefile=aparc.txt --hemi,指定要分析的半球 --meas,要提取的测量值,选项有\u0026quot;thickness\u0026rdquo;, \u0026ldquo;volume\u0026rdquo;, \u0026ldquo;area\u0026rdquo;, \u0026ldquo;meancurv\u0026rdquo; --parc,指定图谱，选项有Desikan-Killinay图谱(\u0026ldquo;aparc\u0026rdquo;)和Destrieux图谱(\u0026ldquo;aparc.a2009s\u0026rdquo;)\n实践#3:如何提取感兴趣ROI区域的结构信息？ 如何将一个Volumetric ROI重采样到表面，然后从该ROI中提取结构测量值。 如何将ROI区域映射到皮层上 shell #!/bin/tcsh setenv SUBJECTS_DIR `pwd` # 使用AFNI的3dUndump创建5mm的ROI球体;ROI_file.txt 包含球心的 x、y 和 z 坐标 # https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dUndump.html 3dUndump -srad 5 -prefix S2.nii -master MNI_caez*+tlrc.HEAD -orient LPI -xyz ROI_file.txt # 使用tkmedit查看 # https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/TkmeditGeneralUsage tkmedit -f MNI_caez_N27.nii -overlay S2.nii -fthresh 0.5 # 将结构像模板配准到fsaverage fslregister --s fsaverage --mov MNI_caez_N27.nii --reg tmp.dat # 在fsaverage上查看ROI tkmedit fsaverage T1.mgz -overlay S2.nii -overlay-reg tmp.dat -fthresh 0.5 -surface lh.white -aux-surface rh.white #将ROI映射到fsaverage皮层; #https://surfer.nmr.mgh.harvard.edu/fswiki/mri_vol2surf mri_vol2surf --mov S2.nii \\ --reg tmp.dat \\ --projdist-max 0 1 0.1 \\ --interp nearest \\ --hemi lh \\ --out lh.fsaverage.S2.mgh \\ --noreshape # 检查ROI映射到膨胀皮层的情况 # https://surfer.nmr.mgh.harvard.edu/fswiki/tksurfer tksurfer fsaverage lh inflated -overlay lh.fsaverage.S2.mgh -fthresh 0.5 实践#4:如果构建一个surface ROI重采样到体积（Volume）？ 将一个由FreeSurfer创建的ROI投射到个体体积空间。\n根据label信息，生成ROI Volume。 shell # 手动创建registration file（register.dat） # https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/ManualRegistration # 去掉--noedit参数，可以弹出GUI界面来手动调整；“beta_0001.nii” is a beta map created in the subject’s native space tkregister2 --mov beta_0001.nii --s subject --noedit --regheader --reg register.dat # 使用mri_label2vol命令将surface ROI转到体积空间。 # mri_label2vol: creates mgz volume from a label or set of labels # --temp: Template volume # --fillthresh: Relative threshold which the number hits in a voxel must exceed for the voxel to be considered a candidate for membership in the label. (See mri_label2vol --help for more information) # --proj: Project the label along the surface normal # https://surfer.nmr.mgh.harvard.edu/fswiki/mri_label2vol mri_label2vol --label lh.superiortemporal.label --temp beta_0001.nii --subject subject --hemi lh --fillthresh .9 --proj frac 0 1 .1 --reg register.dat --o $PWD/stgnew.nii mri_label2vol运行完成之后，我们得到一个新文件stgnew.ni，它是转换为体积空间的表面ROI。\n实践#5:如何使用FreeSurfer去除颅骨(skull-stripping)? shell # 通过设置较低的分水岭阈值（例如 5）来去除更多的头骨,会生成颅骨去除的掩码文件brainmask.mgz。 recon-all -skullstrip -wsthresh 5 -clean-bm -s sub-117_ses-BL_T1w # 即使分水岭阈值较低，仍有一些头骨(skull)和硬脑膜(dura)的碎片残留。你可以使用-gcut选项来删除后者 recon-all -skullstrip -clean-bm -gcut -subjid sub-117_ses-BL_T1w 在你使用watershed的gcut选项后，需要用以下代码重新生成皮层表面。 recon-all -autorecon2-pial -subjid \u0026lt;subject name\u0026gt;\n参数解析：\n-subjid subjid:the subject data upon which to operate autorecon2-pial:process stages 21-23 https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all 扩展 可以使用FSL下的bet2工具来完成颅骨去除(很常用)。\n参考教程\n"
},
{
	"uri": "https://LiaoPan.github.io/",
	"title": "主页",
	"tags": [],
	"description": "",
	"content": "教程\u0026amp;学习内容 本博客是博主边学习相关知识边记录的相关教程实践，以作备忘和分享。 博主在学习过程中，难免会出现错漏或者理解不对的地方，请大家辩证看待、谨慎使用。\n因为在国内访问github网站时偶尔会出现访问缓慢或者无法访问情况，所以我在gitee也搭建了相同博客网站，供大家访问。 https://panliao.gitee.io/ （国内访问，更加稳定）\n基础知识 脑相关数据集 DIPY系列教程 快速入门 纤维束追踪入门 MRtrix3系列教程 MRtrix3教程 #1 快速入门 MRtrix3教程 #2 预处理 MRtrix3教程 #4 大脑组织边界 MRtrix3教程 #6 Connectome AFNI系列教程 AFNI 系列教程 #1.Preprocessing AFNI 系列教程 #2.统计与建模 EEGLAB系列教程 FieldTrip系列教程 FreeSurfer系列教程 FreeSurfer教程 #1. 安装 FreeSurfer教程 #2. FreeSurfer输出结果与FreeView可视化 FreeSurfer教程 #N. 实践教程之CookBook FSL系列教程 FSL系列教程 #1.FSL安装 FSL系列教程 #2. 预处理 FSL系列教程 #3. 统计与建模 FSL系列教程 #4. ROI分析 FSL系列教程 #5. FSL脚本编写 SPM系列教程 ANTs系列教程 MNE系列教程 如果我们想深入了解MRI相关知识，推荐查看 Functional Magnetic Resonance Imaging, by Huettel, Song, \u0026amp; McCarthy (3rd Edition)\n或者访问https://mriquestions.com/index.html网站了解\n"
},
{
	"uri": "https://LiaoPan.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://LiaoPan.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]